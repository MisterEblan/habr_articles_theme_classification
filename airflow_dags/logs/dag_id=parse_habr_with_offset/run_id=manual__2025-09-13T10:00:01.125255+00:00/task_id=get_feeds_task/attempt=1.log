{"timestamp":"2025-09-13T10:00:02.241277","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-13T10:00:02.241836","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/parse_habr_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-13T10:00:03.076697","level":"info","event":"Парсим 5 со смещением 16","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:03.076775","level":"info","event":"Попадаем в цикл","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:03.076812","level":"info","event":"В цикле: 16","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:03.076849","level":"info","event":"URL: https://habr.com/ru/articles/page16","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:03.968267","level":"info","event":"Result: <Response [200]>","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:17.397297","level":"info","event":"Feed: pages=[Page(id='945390', title='Как я спустя 15 лет решил проблему распределённых очередей', content='Когда я работал в Reddit и отвечал там за инфраструктуру, самой важной поддерживаемой системой для меня была Postgres, а на втором месте стоял брокер сообщений RabbitMQ. Он был необходим для работы Reddit — перед сохранением в базу данных все данные поступали в распределённую очередь. Например, если пользователь лайкал пост, то это записывалось в очередь и кэш, а затем пользователю передавалось сообщение об успешном выполнении. Затем программа обработки очереди брала этот элемент и пыталась записать его в базу данных, а также создать новую рабочую операцию для пересчёта всех списков, на которые влияет этот лайк. Мы использовали эту архитектуру очередей задач, потому что она была простой, масштабируемой и обладала мощными возможностями: Горизонтальной масштабируемостью . Очереди задач позволяют параллельно выполнять множество задач, используя ресурсы множества серверов. Масштабировать систему было довольно просто\\xa0— достаточно было добавлять новых воркеров. Управление потоками . Работая с очередями задач, мы могли управлять частотой потребления воркерами задач из различных очередей. Например, если задача требовала больших ресурсов, мы могли ограничивать количество таких конкурентно выполняемых задач в одном воркере. Если задача получала доступ к API с ограничением частоты использования, то мы могли ограничивать количество выполняемых в секунду задач, чтобы не перегружать API.\\xa0 Планирование . Очереди задач позволяют определять, когда и как часто выполняется задача. Например, мы можем запускать задачи в планировщике cron или планировать исполнение задач в какой-то момент в будущем. Такая система хорошо масштабировалась, но могла ломаться разными хитрыми способами. Если базы данных голосования за посты и комментарии были недоступны, элемент возвращался обратно в очередь. Если кэш списков был недоступен, списки невозможно было пересчитать. Если обработчик очередей вылетал после получения элемента, но до выполнения действий с ним, то данные просто терялись. А если была недоступна сама очередь, мы могли терять голоса или комментарии или посты (У вас на Reddit когда-нибудь были мысли «я же точно голосовал здесь, но теперь голоса нет!»? Теперь вы знаете причину). Для обеспечения надёжности распределённых очередей задач нам нужны были устойчивые очереди (durable queue), заносящие статус помещённых в очереди задач в надёжное хранилище наподобие Postgres. При наличии устойчивых очередей мы могли бы продолжать окончившиеся сбоем задачи с последнего завершённого этапа, не теряя при этом данные в случае вылета программ. Когда я работал в Reddit, устойчивые очереди были редкостью, но сегодня они всё больше набирают популярность. По сути, они комбинируют очереди задач с устойчивыми рабочими процессами, позволяя надёжным образом  управлять рабочими процессами множества параллельных задач . Архитектурно устойчивые очереди очень похожи на обычные очереди, но используют постоянное хранилище (обычно реляционную базу данных) в качестве и брокера сообщений, и бэкенда: Базовая абстракция устойчивых очередей — это  рабочий процесс  ( workflow) \\xa0множества задач. Например, можно передать задачу обработки документа, которая разбивает документ на страницы, обрабатывает каждую страницу параллельно в отдельных задачах, а затем выполняет постобработку и возвращает результаты: @workflow()\\ndef process_tasks(tasks):\\n  task_handles = []\\n  # Заносим каждую задачу в очередь, чтобы все задачи обрабатывались конкурентно.\\n  for task in tasks:\\n    handle = queue.enqueue(process_task, task) task_handles.append(handle)\\n  # Ждём, пока каждая задача выполнится и получит результат.\\n  # Возвращаем результаты всех задач.\\n  return [handle.get_result() for handle in task_handles] Устойчивые очереди создают  чек-поинты  рабочих процессов в своём постоянном хранилище. Когда клиент передаёт задачу, задача и входные данные записываются. Когда эта задача вызывает другую задачу, эта подзадача и её входные данные записываются, как  дочерний элемент  вызвавшей их задачи. Таким образом, система очередей имеет полное постоянное хранилище всех задач и их взаимосвязей. Эти рабочие процессы важнее всего при восстановлении после сбоев. В случае, когда при выполнении задачи работа неустойчивого воркера прерывается, очередь в лучшем случае перезапускает его с начала, а в худшем теряет задачу. Это не подходит для длительно выполняемых рабочих процессов и задач с критичными данными. Когда устойчивая система очередей восстанавливает рабочий процесс, она проверяет его чек-поинты, чтобы восстановиться из последнего завершённого этапа, избегая таким образом повторной передачи завершённой работы.\\u200d Устойчивые очереди и наблюдаемость Ещё одно преимущество устойчивых очередей —  встроенная наблюдаемость . Так как эти очереди сохраняют подробные записи о каждом переданном рабочем процессе и задаче, они упрощают мониторинг того, что делают эти очереди и рабочие процессы в любой момент времени. Например, для изучения текущего содержимого очереди (или содержимого в прошлом) достаточно лишь SQL-запроса. Аналогично, для изучения  текущего состояния рабочего процесса тоже нужен ещё один SQL-запрос .\\u200d Минусы устойчивых очередей Когда же использовать устойчивые очереди? Как всегда, это зависит от  компромиссов . Для устойчивых очередей главный компромисс — это  производительность брокера сообщений . Большинство распределённых очередей задач для брокеринга сообщений и хранения выходных данных задач использует хранилище ключей и значений в памяти наподобие Redis. Однако устойчивым очередям нужно использовать в качестве брокера сообщений и бэкенда устойчивое хранилище; часто это реляционная база данных наподобие Postgres. Последняя обеспечивает более надёжные гарантии, но ценой снижения пропускной способности. Таким образом, устойчивые очереди следует выбирать в случае обработки малых объёмов крупных, критичных для бизнеса задач, а распределённые очереди задач — при обработке очень большого объёма мелких задач.\\u200d Дополнительные источники Dosu \\xa0— миграция очередей с Celery на DBOS Bristol Myers Squibb \\xa0— устойчивое горизонтальное масштабирование конвейеров геномных данных при помощи DBOS cStructure \\xa0— миграция очередей с Celery на DBOS DOCS:\\xa0DBOS\\xa0durable queuing', hub='базы данных'), Page(id='945386', title='Курсы по Unity для детей: чему учат, как устроено обучение, какие есть результаты', content='Курсы Unity для детей – отличная возможность научиться разрабатывать игры и писать код на Си Шарпе. Обучение в таком формате, когда сложные инструменты – игровой движок «Юнити» и язык C# – осваиваются через game-разработку, мы в  Pixel  считаем достойным внимания и единственно верным, особенно когда речь об уроках для младших школьников и подростков. Рассказываем, что такое Unity, для чего предназначен игровой движок и как устроены курсы по «Юнити». Статья содержит элементы рекламы. Для чего предназначен движок Unity и что можно сделать с его помощью Если вам уже знаком игровой движок «Юнити», данный раздел можно пропустить: он содержит общие сведения для наших читателей, не разбирающихся в Unity. Итак, к сути. «Юнити» – функциональный движок, предназначенный специально для создания 2Д- и 3Д-игр. Это разработка американской компании Unity Technologies, характеризующаяся следующими особенностями: Возможность разработки игр для различных платформ: консолей, персональных компьютеров, мобильных устройств и не только; Наличие инструментов, предназначенных для создания игр с 2D- и 3D-графикой, с элементами дополненной и виртуальной реальности (AR и VR); Возможность использовать виртуальный редактор сцен для сборки игровых локаций и их наполнения в режиме реального времени; Поддержка программирования на языке C#, который необходим для скриптинга выполняемых игровых проектов. Об особенностях движка можно говорить долго, поэтому ограничимся представленными сведениями и дополнительно отметим, что на «Юнити» созданы десятки известных игр. Это Pokemon GO, Genshin Impact, Как достать соседа, Call of Duty: Mobile и т. д. Видно, что представлен комплексный инструмент: он подойдет для разработки игр различных жанров с элементами 2Д, 3Д, AR и VR. Но для полноценного использования всех возможностей движка необходимо знать и уверенно применять C#, заложенный во множество продвинутых курсов разработки на Unity для детей и подростков. С помощью данного языка предстоит программировать логику в игровых проектах. Если опустить контекст разработки, то C# активно используется и в других направлениях. Это, скажем, Big Data, нейросетевые технологии, создание софта для Windows, веб-приложений и т. д. Теперь хотим перейти к вопросам по поводу курсов игр на Unity для детей и рассказать, что они могут дать ребенку и как устроен учебный процесс. Как устроены курсы Unity и чему на них можно научиться Курсы «Юнити» с нуля для детей и подростков проводятся в онлайне и очно: можно выбрать формат по нраву. В обыкновенной ситуации учебный процесс строится вокруг теории и практики: сначала преподаватель рассказывает детям о конкретной теме, а затем вместе с ребятами приступает к активной практике. Плюсом станет проектная деятельность: если в курс разработчика игр на Unity заложены соответствующие работы, то есть проекты, знания и навыки, которые ребенок вынесет из учебы, станут прочными. Освоить «Юнити» с нуля на курсах – значит научиться: Создавать игры; Писать код на языке C#; Оптимизировать и адаптировать разрабатываемые приложения к использованию на различных устройствах; Создавать дизайн игр и т. д. Прочие важные моменты зависят от конкретного курса Unity с нуля: на нашем примере рассказываем, о чем речь. Курс по «Юнити» для детей от школы Pixel: краткие сведения, какие проекты удастся выполнить\\xa0 Наш  онлайн-курс  программирования на Unity характеризуется всеми отмеченными аспектами: полезной теорией и насыщенной практикой, возможностью освоить разработку с нуля и научиться как создавать игры, так и писать код на языке C#. Дополнительно предусмотрели упор на проектную деятельность и геймификацию: первая помогает ребятам лучше осваивать программирование на Unity, вторая же предназначена для повышения интереса к занятиям и увеличения целеустремленности детей. Речь о том, что за успехи в учебе ребята поощряются баллами, которые впоследствии можно обменивать на подарки. Дополнительные особенности курса: Формат:  удаленные уроки в ZOOM индивидуально или в группе, альтернатива – видеокурс; Структура:  предусмотрели три модуля с 12 занятиями, одно длится 1,5 часа; Продолжительность:  курс разработки на Unity занимает до девяти месяцев и предполагает занятия раз в неделю; Возраст:  методический план и образовательная программа подойдут ребятам от 10 до 14 лет; Цена:  от 800 рублей за урок; Скидки и акции:  минус 10 % для новичков, вычет, оплата материнским капиталом. Найти больше информации о курсе Unity с нуля для детей и подростков или записаться на уроки вы можете на  странице направления . Вот наглядные примеры проектов для понимания, что удастся научиться делать после онлайн-уроков:\\xa0 Резюме Unity – мощный игровой движок с колоссальными возможностями. Владение им предполагает использование языка программирования C#. Благодаря «Юнити» можно создавать 2Д- и 3Д-игры с элементами VR и AR для различных платформ: компьютеров, консолей и телефонов. Научиться этому можно на курсах игр на Unity для детей и подростков. Если интересно, еще раз приглашаем на учебу. FAQ Как записаться на курс разработчика на Unity для детей? Для этого перейдите на  страницу направления  и кликните на кнопке «Запись» или нажмите на иконку чата рядом с надписью «Появился вопрос?». Во втором случае станет доступна связь с нами в WhatsApp и Telegram, а также заказ обратного звонка. Где найти курсы Unity 3D для детей? Представленное нами направление, реализуемое в онлайне, и есть курс Unity 3D для детей и подростков 10–14 лет. Приглашаем на занятия. Как происходит обучение разработке игр на Unity на курсе? Курс разработки игр на Unity основан на нескучной теории и практике, а также на проектной деятельности и геймификации. Что это такое и в чем плюсы, рассказали в статье, рекомендуем ознакомиться. \\xa0 \\xa0', hub='учебный процесс в it'), Page(id='945384', title='Инструменты бережливого производства', content='Мой канал Бережливое производство (Lean Production) – это подход к управлению, нацеленный на максимизацию ценности для клиента при одновременном устранении потерь. Его корни лежат в производственной системе Toyota, где были разработаны многие из инструментов, о которых пойдет речь.  Кайдзен (Kaizen) Суть и цель: \\xa0Кайдзен – это философия непрерывного, постоянного улучшения процессов с участием всех сотрудников. Термин переводится с японского как «улучшение» – и в контексте бизнеса означает культуру, где каждый день ищутся мелкие шаги к улучшению работы.  Цель кайдзена – вовлечь весь персонал в систематическое повышение эффективности и качества, увеличивая ценность и снижая потери (муда). В отличие от разовых реформ, кайдзен фокусируется на постоянных небольших изменениях, которые со временем дают большие результаты. 5С (5S) Суть и цель: \\xa0Методика 5С – система организации рабочего места, основанная на визуальном контроле и порядке. Название происходит от пяти японских слов, начинающихся с «S»:\\xa0 Сеири \\xa0(сортировка) Сейтон \\xa0(упорядочение) Сейсо \\xa0(содержание в чистоте) Сейкецу \\xa0(стандартизация) Сицуке \\xa0(дисциплина поддержания порядка) Проще говоря, 5С призвана обеспечить, чтобы на рабочем месте был идеальный порядок: оставлено только нужное, всё лежит на своих местах, чистота поддерживается, введены стандарты уборки, а сотрудники приучены соблюдать эти стандарты постоянно.  Цель внедрения 5С – повысить эффективность труда за счёт устранения потерь времени (поиск инструментов, бардак), улучшить безопасность и качество работы.  Принципы 5S направлены не только на наведение порядка, но и на повышение безопасности, качества работы и производительности. Карта потока создания ценности (Value Stream Mapping) Суть и цель: \\xa0Картирование потока создания ценности (Value Stream Mapping, VSM) – это инструмент, позволяющий визуально изобразить весь процесс производства услуги или продукта, от сырья до поставки клиенту. На карте потока отмечаются все шаги процесса, материальные и информационные потоки, время выполнения операций, ожидания, запасы, перемещение и т.д.  Цель VSM – выявить\\xa0 узкие места \\xa0и\\xa0 потери \\xa0в цепочке: излишние запасы, лишние шаги, задержки между стадиями. Проанализировав текущую карту, команда разрабатывает карту будущего состояния – оптимизированного процесса с устранением выявленных проблем. Таким образом, Value Stream Mapping задает направление для конкретных улучшений, влияющих на весь поток, а не только на отдельные участки. Система вытягивания (Pull system) Суть и цель: \\xa0Вытягивающая система производства – это подход, при котором каждая последующая стадия процесса\\xa0 вытягивает \\xa0ровно столько продукции с предыдущей, сколько ей нужно в данный момент. Иначе говоря, ни один участок не начинает работу, пока не получит сигнал от следующего этапа о потребности. Это противопоставляется традиционному «толкающему» (push) подходу, где производство идёт по плану независимо от фактического спроса последующих операций или клиентов. Цель системы Pull – устранить перепроизводство и избыточные запасы, сделать поток гибким и реагирующим на реальный спрос. Когда внедрена вытягивающая система, проблемы всплывают быстрее (невозможно спрятать их за складскими буферами) – а значит, их приходится решать, что в итоге повышает эффективность всей цепочки. Канбан (Kanban) Суть и цель: \\xa0Канбан – один из наиболее известных инструментов Lean, тесно связанный с системой вытягивания. Термин\\xa0 канбан \\xa0переводится с японского как «карточка» или «сигнал». Классический канбан в производстве – это карточки или другие носители информации, которые перемещаются вместе с контейнерами деталей между операциями. Когда следующему участку нужны детали, он возвращает карточку предыдущему – сигнал произвести или подвезти новую партию. Таким образом достигается описанное выше вытягивание:\\xa0 ничего лишнего и преждевременного \\xa0– только по требованию. Цель канбана – визуализировать и контролировать поток работ или материалов, ограничить объем одновременно выполняемой работы и не допустить перепроизводства. Сейчас канбан-методы применяются не только на фабриках, но и в офисных процессах (например, канбан-доски для задач в проектах), однако суть одна – прозрачное управление потоком и нагрузкой. Производство точно-в-срок (Just-in-Time) Суть и цель: \\xa0Производство точно-в-срок (Just-in-Time, JIT) – один из базовых столпов бережливого подхода. Его суть – делать\\xa0 то, что нужно, только когда нужно, и в нужном количестве . Детали, материалы или товары поступают на линию производства строго к моменту, когда они требуются, за счёт чего практически отсутствуют промежуточные склады и ожидание. Компания, внедряющая принцип JIT, стремится устранить простои и минимизировать запасы вплоть до нуля.  Цель – максимально снизить издержки на хранение, ускорить оборачиваемость и быстро выявлять проблемы (например, брак или сбои поставок сразу видны, ведь нет буфера запасов). В идеале JIT обеспечивает высокую гибкость: производство мгновенно подстраивается под колебания спроса. Однако это требует высокой дисциплины и надежности от всех участников цепочки. Покайоке (Poka-Yoke) Суть и цель: \\xa0Покайоке, или «защита от дурака», – это метод предотвращения ошибок и дефектов в процессе с помощью специальных приспособлений или организационных мер. Идея покайоке проста:\\xa0 лучше предупредить ошибку, чем потом исправлять последствия . Часто покайоке реализуется физическими средствами – например, приспособление, не позволяющее вставить деталь неправильной стороной, или датчик, блокирующий запуск станка, если деталь установлена неправильно. По сути, это “умное” инженерное решение, из-за которого дефекты просто не могут возникнуть.  Цель – повысить качество и избежать затрат времени и денег на переделки брака, а также сделать процессы более надежными за счет исключения человеческого фактора в критических местах. Быстрая переналадка (SMED) Суть и цель: \\xa0SMED (Single Minute Exchange of Dies) – методика быстрой переналадки оборудования, разработанная японским инженером Сигео Синго. Её цель –\\xa0 сократить время смены оборудования до одной минуты .  Исторически SMED возник на производстве пресс-форм, где переналадка могла занимать часы. Синго предложил подход, позволивший уложиться менее чем в 10 минут, а в идеале – в 1 минуту (так называемая «настройка одним касанием»). Смысл SMED – перевести производство на быстрые переключения между разными продуктами без потери времени, чтобы стало выгодно делать маленькие партии.  Таким образом, SMED служит основой для гибкого производства по требованию (JIT): когда переналадка занимает не часы, а минуты, пропадает стимул гнать продукцию впрок. Кроме того, сокращение настроечных простоев напрямую повышает полезное время работы оборудования. Заключение Внедрение инструментов бережливого производства требует не только знания технологий, но и управленческого мастерства. Бережливое производство – это путь, а не разовая акция. Не ожидайте мгновенных чудес. Закладывайте горизонт в\\xa0 годы , а не недели: сначала небольшие улучшения, затем нарастающий эффект. Культура изменения приживется не сразу, но долгосрочные результаты стоят терпения. Руководство играет ключевую роль: если топ-менеджеры не вовлечены, lean останется на бумаге.  Бережливое производство – это не набор модных терминов, а действенный подход, подтверждённый опытом мировых лидеров. Инструменты, описанные выше – проверенные «кирпичики» Lean. Используя их разумно и последовательно, вы не только устраните потери и повысите эффективность, но и вовлечёте вашу команду в процесс постоянного совершенствования.', hub='управление персоналом'), Page(id='943914', title='Социократия 3.0: быстрые и безопасные решения без права вето', content='Привет, Хабр!  Частенько тимлидов беспокоит одна ситуация: команда из\\xa0кросс‑функциональных специалистов собирается решить важный вопрос, а\\xa0процесс превращается в\\xa0бесконечный спор. Каждый тянет одеяло на\\xa0себя, вето любого участника способно затормозить прогресс, и в\\xa0итоге решение\\xa0либо принимается слишком долго,\\xa0либо вообще откладывается. В\\xa0поисках способа ускорить принятие решений и при\\xa0этом учитывать мнение каждого, естьподход под\\xa0названием  Sociocracy 3.0\\xa0(S3) . Сегодня я расскажу, что\\xa0это за\\xa0методика, как\\xa0она помогает командам принимать решения  на\\xa0основе согласия  без\\xa0бесконечных обсуждений и вето, и как\\xa0её можно пилотно опробовать в\\xa0проекте. Кратко об истоках Начну с\\xa0небольшого экскурса. Термин «социократия» придумал ещё в\\xa0XIX веке философ Огюст Конт, но\\xa0в\\xa0управлении организаций эти идеи по‑настоящему воплотил в 1970-х голландский инженер  Герард Энденбург . Ему хотелось управлять своей компанией по‑человечески, без\\xa0жёсткой иерархии, но  без\\xa0потери эффективности . Энденбург разработал метод управления на\\xa0основе кругов и согласия\\xa0— так родилась современная социократия, или  динамическое управление . С\\xa0годами метод прижился в\\xa0различных организациях, а\\xa0в 2015\\xa0году консультанты Бернхард Бокельбринк и Джеймс Прист на\\xa0основе этих идей и опыта Agile/Lean‑среды представили открытую методику  Социократия 3.0 . Это уже не\\xa0жёсткая система, а\\xa0гибкий фреймворк с\\xa0десятками паттернов, которыми команда может воспользоваться по\\xa0своему усмотрению. S3\\xa0впитала в\\xa0себя лучшие принципы Agile, Lean, холакратии и других подходов, сохранив философию социократии:  самоорганизация, вовлечение людей и коллективный разум вместо директивного менеджмента . Звучит здорово, но\\xa0давайте разбираться по\\xa0порядку. Принятие решений по согласию вместо консенсуса Центральная идея Социократии 3.0\\xa0— принятие решений  по\\xa0принципу согласия (consent) . В\\xa0традиционных подходах часто стремятся к\\xa0консенсусу, когда  решение принимается только если все с\\xa0ним активно согласны . Казалось\\xa0бы, здорово\\xa0— полное единодушие!\\xa0— но\\xa0на\\xa0практике достичь консенсуса сложно и долго: стоит одному человеку возразить, и решение стопорится до\\xa0бесконечности. К\\xa0сожалению, в\\xa0жизни команд это выливается\\xa0либо в\\xa0компромиссы по\\xa0минимальному общему знаменателю,\\xa0либо в\\xa0скрытое недовольство тех, чьё мнение проигнорировали ради мнимого согласия. Consent‑подход  снимает эту проблему.  Решение считается принятым, когда никто из\\xa0участников не\\xa0выдвинул существенного возражения . Не\\xa0нужно, чтобы все обожали план\\xa0— важно, чтобы не\\xa0было  серьёзных причин против . Если возражения нет, команда движется дальше. Если возражение появляется, его не\\xa0воспринимают как\\xa0провокацию или\\xa0право вето, а\\xa0рассматривают как\\xa0ценную информацию: повод доработать предложение так, чтобы устранить риск или\\xa0проблему, которая беспокоит участника. В\\xa0социократии говорят:  «Достаточно хорошо, чтобы попробовать, и безопасно в\\xa0достаточной степени, чтобы не\\xa0навредить» . То есть решение не\\xa0обязано\\xa0быть идеальным и вечным\\xa0— достаточно, чтобы оно работало  сейчас  и не\\xa0несло явной угрозы целям команды. Его всегда можно пересмотреть, когда появятся новые данные или\\xa0изменятся условия. Допустим, команда обсуждает, внедрять\\xa0ли новый фреймворк в\\xa0проекте. По\\xa0консенсусу им пришлось\\xa0бы убеждать каждого скептика, тратить часы на\\xa0споры, пока последний участник не\\xa0скажет заветное «ну ладно, пусть будет». В\\xa0формате согласия процесс другой: один из\\xa0разработчиков делает  предложение : «Давайте в\\xa0следующем сервисе используем Framework X». Далее  раунд вопросов  для\\xa0прояснения\\xa0— коллеги уточняют детали, оценивают влияние. Затем  раунд реакций \\xa0— коротко делятся мнениями, но\\xa0решение ещё не\\xa0принимается. После этого фасилитатор встречи спрашивает: « Есть\\xa0ли возражения? ». Если никто не\\xa0возражает\\xa0— решение принимается за\\xa0несколько минут! Если\\xa0же, скажем, тимлид возражает: « Я против, потому что\\xa0у\\xa0нас не\\xa0хватает опыта, есть риск сорвать сроки »,\\xa0— группа не\\xa0голосует «за» или «против», а\\xa0совместно обсуждает это возражение. Возможно, дорабатывают предложение: например, провести обучение или\\xa0сначала сделать небольшой прототип на\\xa0новом фреймворке. Потом снова спрашивают про\\xa0возражения. Процесс идёт по\\xa0кругу, пока  возражения не\\xa0исчезнут , и тогда обновлённое решение принимается. Конечно\\xa0же возражение должно\\xa0быть аргументированным, указывающим на\\xa0риск или\\xa0несоответствие целям. Просто сказать « мне не\\xa0нравится » недостаточно. Такой подход экономит время\\xa0— не\\xa0нужно стремиться к\\xa0идеалу или\\xa0всеобщей любви, достаточно убрать критичные проблемы и можно действовать. В\\xa0итоге  решения принимаются\\xa0быстрее , а\\xa0команда чувствует себя в\\xa0безопасности: никто не\\xa0продавил решение силой, все могли высказать опасения и\\xa0быть услышанными. Круги и домены Помимо принципа согласия, S3\\xa0предлагает пересмотреть структуру команды или\\xa0организации. Вместо классической пирамиды с\\xa0начальниками и подчинёнными используется система  кругов .  Круг \\xa0— это группа людей, которая отвечает за\\xa0определённый  домен . Домен\\xa0— по\\xa0сути, область ответственности, где этот круг имеет полномочия принимать решения и реализовывать их. Например, в\\xa0компании может\\xa0быть круг разработки продукта, круг маркетинга, круг поддержки пользователей\\xa0— каждый со своим чётким фокусом. В\\xa0контексте одной кросс‑функциональной команды можно представить круг, ответственный за\\xa0качество и процессы, или\\xa0круг технического развития продукта, и\\xa0т.\\xa0д. Главное, чтобы у\\xa0круга\\xa0была  общая цель и зона ответственности , понятная всем участникам. Как\\xa0же связаны разные круги между собой, чтобы не\\xa0получилась разрозненная анархия? Здесь работает принцип  двойной связи . Если круги выстроены по\\xa0уровню (например, команда → отдел → весь отдел → компания), то связь между «верхним» и «нижним» уровнями осуществляется в\\xa0обоих направлениях. Обычно это выглядит так: руководитель круга (скажем, руководитель отдела) входит в\\xa0состав вышестоящего круга  как\\xa0лидер , донося видение и цели сверху. А\\xa0кто‑то из\\xa0членов круга (делегат)  представляет интересы своего круга  на\\xa0уровне выше, донося обратную связь, проблемы и предложения снизу вверх.  Двойная связь  дает циркуляцию информации и влияние решений в\\xa0обе стороны: верх получает правдивую картину снизу, а\\xa0нижний круг\\xa0— стратегическую информацию и поддержку сверху. Причём делегат выбран самими членами круга (обычно как\\xa0раз через обсуждение по\\xa0согласия, без\\xa0выдвижения кандидатур формально) и имеет равные права в\\xa0дискуссиях на\\xa0верхнем уровне. Так исключается искажение информации и одностороннее диктование\\xa0—  обратная связь пронизывает всю систему . В\\xa0маленькой команде, конечно, всё проще: может\\xa0быть один круг, который сам себе и начальник, он\\xa0же и исполнитель. Но\\xa0даже там идея кружной структуры полезна: распределение ролей внутри команды можно рассматривать как\\xa0микро‑круги. Например, роль тимлида, роль ответственного за\\xa0качество, за\\xa0деплой и\\xa0т.\\xa0д.\\xa0— каждая роль имеет свой «домен». Sociocracy 3.0\\xa0рекомендует чётко оговорить  обязанности и области полномочий  каждой роли, чтобы все понимали, кто чем владеет. Это устраняет дублирование и серые зоны ответственности. Кстати,  выбор людей на\\xa0роли \\xa0— отдельный интересный паттерн S3. Вместо назначения «сверху» или\\xa0стандартного волеизъявления «кто хочет\\xa0быть скрам‑мастером?» проводится  выбор без\\xa0кандидатов . Все члены круга открыто обсуждают, кто из\\xa0коллег лучше всего подходит на\\xa0роль, и формируют решение по\\xa0согласованию. Никто заранее не\\xa0выдвигает свою кандидатуру, поэтому и  проигравших нет \\xa0— решение коллективное, обоснованное и, как\\xa0правило, охотно принимается назначенным человеком (ведь группа доверила ему эту ответственность, аргументированно объяснив почему).  Паттерны S3 Социократия 3.0\\xa0интересна тем, что\\xa0не\\xa0навязывает строгий процесс. Вместо этого она предлагает  набор из\\xa0десятков паттернов \\xa0— проверенных практик и правил, которые помогают решать типичные проблемы самоорганизации. Фактически, это библиотека рецептов на\\xa0разные случаи: как\\xa0проводить встречи, как\\xa0распределять задачи, как\\xa0улучшать взаимодействие в\\xa0команде и пр. На\\xa0сегодняшний день паттернов уже порядка 70–80, и они открыто опубликованы (есть даже подробный гайд в\\xa0открытом доступе\\xa0— для\\xa0желающих углубиться). Приведу несколько примеров, которые показались мне полезными: Обсуждение предложений (Proposal Forming):  структура для\\xa0группового обсуждения проблемы и совместной выработки решения. Например, перед тем как\\xa0принять решение по\\xa0consent‑процессу, команда может сначала соборно накидать варианты решения, улучшить их, объединить лучшие части\\xa0— чтобы итоговое предложение учитывало максимум точек зрения. Ведение реестра напряжений:  в\\xa0S3\\xa0используется понятие «напряжение»\\xa0— это разрыв между тем, как\\xa0есть, и как\\xa0могло\\xa0бы\\xa0быть лучше. Грубо говоря, любая проблема, неудобство или\\xa0возможность улучшения\\xa0— это напряжение. Паттерн предлагает фиксировать такие напряжения (например, отдельный бэклог улучшений) и регулярно их рассматривать на\\xa0встречах круга Чёткие договорённости (Agreement):  любое принятое по\\xa0согласию решение фиксируется как\\xa0соглашение\\xa0— будь то правило, процесс, структура ролей. S3\\xa0рекомендует явно записывать  кто, за\\xa0что\\xa0отвечает, какие правила действуют , и самое главное\\xa0— пересматривать эти договорённости по\\xa0мере необходимости.  Регулярные обзоры и ретроспективы:  в\\xa0социократии ценится эмпирический подход, поэтому есть паттерны, напоминающие Scrum: проводить ретроспективы, проверять, достигли\\xa0ли решения\\xa0желаемого эффекта. Например, когда команда принимает решение, сразу можно назначить дату или\\xa0условие  ревью , чтобы вернуться и оценить: работает\\xa0ли решение, или\\xa0нужны корректировки. Роли и бэклоги:  часть паттернов вам покажется знакомой. То\\xa0же понятие бэклога, итеративного планирования, Daily Scrum\\xa0— всё это уже давно применяется в\\xa0Agile и органично вписывается в\\xa0Sociocracy 3.0. S3\\xa0вообще не\\xa0стремится всё выдумать с\\xa0нуля\\xa0— половина практик позаимствована или\\xa0вдохновлена существующими методологиями. Зато другая половина дополняет наш набор инструментов управления проектами. Например, паттерны на\\xa0определение домена круга, на\\xa0согласование ожиданий с\\xa0внешними стейкхолдерами, на\\xa0масштабирование количества кругов в\\xa0организации и\\xa0т.\\xa0д. Паттерны S3\\xa0— модульные и гибкие . Их не\\xa0нужно внедрять разом или\\xa0полностью. Выберите ту практику, которая решит вашу текущую проблему. Допустим, у\\xa0вас слишком долгие планёрки\\xa0— можно начать с\\xa0паттерна регламента встречи (таймбоксы, четкая повестка, роли фасилитатора и протоколиста). Или, например, в\\xa0команде неясно, кто за\\xa0что\\xa0отвечает\\xa0— попробуйте паттерн определения доменов и ролей, пропишите зоны ответственности. Каждое нововведение\\xa0— это тоже эксперимент. Если не\\xa0приживётся, можно откатить безболезненно.  Когда пригодится Социократия\\xa03.0 и как стартовать пилотно Вы, возможно, думаете: «Звучит неплохо, но\\xa0подходит\\xa0ли это для\\xa0моей команды или\\xa0компании?». Элементы S3\\xa0полезны, когда: Команда кросс‑функциональная, много стейкхолдеров.  Когда за\\xa0столом собираются разработчики, тестировщики, аналитики, дизайнеры, представитель бизнеса\\xa0— велика опасность, что\\xa0решение утонет в\\xa0разношёрстных мнениях. Метод согласия позволяет учесть разные перспективы без\\xa0бесконечного холивара.  Нужно больше автономности и скорости.  В\\xa0классических иерархиях каждый чих нужно согласовывать через три уровня начальства, что\\xa0убивает инициативу.  Есть проблемы с\\xa0вовлечённостью команды.  Если сотрудники пассивны, молчат на\\xa0собрании, боятся брать ответственность\\xa0— социократия может оживить культуру. Компания выросла и старые процессы не\\xa0тянут. \\xa0Бывает, стартап вырастает, а\\xa0хаотичный стиль управления начинает буксовать. S3\\xa0предоставляет каркас, чтобы встроить самоорганизацию и не\\xa0скатиться в\\xa0бюрократию.  Хорошо, вы решились попробовать. С\\xa0чего начать? Рекомендую не\\xa0бросаться сразу перестраивать всю организацию, а\\xa0провести  пилот в\\xa0одном домене . Пусть это будет небольшой  рабочий круг  с\\xa0понятной зоной ответственности. Например, выберите проблемную область, где нужны улучшения: качество выпуска релизов, взаимодействие с\\xa0другими отделами или, скажем, процесс найма разработчиков. Сформируйте круг из\\xa0заинтересованных людей (это могут\\xa0быть представители разных ролей, кого касается этот вопрос). Объясните им принципы S3\\xa0— хотя\\xa0бы базово: про\\xa0согласие, про\\xa0роли, про\\xa0фиксацию решений. Затем в\\xa0течение  нескольких спринтов (2-3\\xa0месяца)  позвольте этому кругу работать по‑новому: проводить встречи в\\xa0формате согласия, экспериментировать с\\xa0паттернами.  Во\\xa0время пилота много внимания уделяйте  обратной связи и обучению . Возможно, понадобится фасилитатор, знакомый с\\xa0социократией, который мягко направит команду, чтобы та не\\xa0скатилась обратно в\\xa0старые привычки (например, молчаливое несогласие вместо явных возражений). Запланируйте регулярные ретроспективы: что\\xa0получается, что\\xa0буксует? Например, через каждый спринт собирайте участников круга и спрашивайте: «Мы приняли 5\\xa0решений по\\xa0consent‑принципу. Как\\xa0они сработали? Все\\xa0ли понимали процесс? Возникали\\xa0ли скрытые возражения, которые не\\xa0озвучили?» Такой мета‑анализ поможет вовремя скорректировать применение методики. По\\xa0завершении пилотного периода оцените результаты. Улучшилось\\xa0ли качество и скорость решений в\\xa0выбранном домене? Стали\\xa0ли участники активнее предлагать идеи, брать ответственность? Как\\xa0отнеслись внешние стейкхолдеры к\\xa0решениям круга? Если есть ощутимая польза, у\\xa0вас будет кейс, с\\xa0которым легче масштабировать практики S3\\xa0на\\xa0другие команды или\\xa0всю компанию. Если\\xa0же эффекта нет\\xa0— по\\xa0крайней мере, вы попробовали с\\xa0малой кровью и поняли ограничения. Проблемы Как\\xa0и любой подход, Sociocracy 3.0\\xa0— не\\xa0серебряная пуля. В\\xa0завершение отмечу несколько важных моментов, чтобы вы шли в\\xa0это осознанно: Нужны знания и тренировка.  Методологии не\\xa0работают сами по\\xa0себе, их должны применять люди. Придётся потратить время на\\xa0обучение команды принципам согласия, ролям, новым терминам. Поначалу процессы (особенно собрания по\\xa0новым правилам) могут идти медленнее, пока все не\\xa0притрутся. Это нормально\\xa0— закладывайте время на\\xa0обучающий период. Без\\xa0поддержки сверху не\\xa0взлетит.  Если верхушка компании не\\xa0готова доверять командам и  делегировать решения , социократия столкнётся с\\xa0сопротивлением. Представьте: ваш круг договорился по\\xa0согласованию запустить новый подход, а\\xa0директор сказал «Нет, будет по‑моему». Вся мотивация тут\\xa0же рухнет. Поэтому важно, чтобы хотя\\xa0бы в\\xa0рамках пилота руководство дало «зеленый свет» и не\\xa0вмешивалось без\\xa0крайней нужды. Лучше, если топ‑менеджеры сами заинтересованы в\\xa0успехе такого эксперимента. Не\\xa0для\\xa0экстремальных ситуаций.  Социократическое принятие решений отлично работает в  проектных и управленческих вопросах , когда ценна проработка разных мнений. Но\\xa0в\\xa0кризисных случаях (инцидент в\\xa0продакшене, пожар на\\xa0сервере)\\xa0— не\\xa0время собирать круг и обсуждать возражения, тут нужен\\xa0быстрый  единоначальный  экшен. Впрочем, это скорее вопрос здравого смысла: S3\\xa0не\\xa0требует применять согласие абсолютно везде и всегда. Определите границы: где мы работаем по‑новому, а\\xa0где действуем по\\xa0старой схеме. Культура открытости\\xa0— обязательна.  Принцип прозрачности гласит: все важные договорённости и информация должны\\xa0быть доступны. Если в\\xa0компании привыкли многое решать кулуарно, не\\xa0документировать решения, скрывать проблемы\\xa0— придётся менять культуру. Начните с\\xa0себя и своего круга: публикуйте протоколы встреч, фиксируйте принятые правила, держите видимым список задач и напряжений. Постепенно люди оценят, что\\xa0открытость экономит время и строит доверие. Постоянное улучшение.  S3\\xa0основана на\\xa0идее эмпирического подхода: пробуем\\xa0— учимся\\xa0— улучшаем. Даже сами принципы и паттерны можно адаптировать. Если чувствуете, что\\xa0какой‑то инструмент не\\xa0заходит, обсудите командой, в\\xa0чём причина. Может, стоит его модифицировать под\\xa0ваш контекст. Социократия 3.0\\xa0не\\xa0догма, а\\xa0конструктор для  развития вашей собственной системы управления . Лично меня S3\\xa0привлекла своей здоровой прагматичностью. Просто логичные принципы, призванные  ускорить решения и вовлечь людей , плюс большая подборка практик, многие из\\xa0которых знакомы любому знакомому Agile. Да, название «социократия» звучит непривычно и даже слегка пугающе, но\\xa0суть довольно приземлённая: сделать так, чтобы  каждый в\\xa0команде мог влиять на\\xa0решения, и при\\xa0этом никто не\\xa0тормозил общий прогресс по\\xa0пустякам . Возможно, именно этого не\\xa0хватало вашей команде для\\xa0нового витка продуктивности и взаимопонимания. Удачи! Если в спринтах стабильно всплывают «узкие места» — по коду, DevOps-процессам, аналитике или управлению — их проще закрывать точечно. В OTUS есть  корпоративные треки  под опытные команды: живые вечерние занятия и практические задачи по вашим кейсам, контроль прогресса в кабинете тимлида и гибкая сборка программы — от открытых групп до кастомного курса под домен. Встраивается в рабочий ритм без лишней бюрократии — чтобы команда быстрее решала боевые задачи. А\\xa0чтобы оставаться в\\xa0курсе актуальных трендов управления в\\xa0IT и первыми узнавать новости о\\xa0бесплатных мероприятиях, подписывайтесь на\\xa0 Telegram‑канал OTUS4Business.', hub='agile'), Page(id='945336', title='4 фреймворка апокалипсиса: LangChain, LlamaIndex, CrewAI и Semantic Kernel в действии', content='Мало просто иметь доступ к мощным нейросетям и уметь ими пользоваться — важно правильно подключить их к своим сервисам, комбинировать с внутренними данными и выстраивать удобные сценарии работы. В нашей команде мы постоянно экспериментируем с новыми AI-технологиям, поэтому сегодня расскажу вам, как же просто можно внедрить нейронку в свой проект (например, на сайт).  Для этого воспользуемся сервисом  Evolution Foundation Models  и рассмотрим фреймворки LangChain, LlamaIndex, CrewAI и Semantic Kernel. Сервис предоставляет доступ к open source моделям по open AI Compatible API. Касаемо фреймворков — каждый из них по-своему упрощает разработку, но имеет уникальные паттерны подключения. В статье я покажу готовые примеры и поясню ключевые части кода. А все ссылки на мои полные решения даю в конце статьи.   Подготовка: доступ к Foundation Models На платформе Cloud.ru Evolution вам нужно зайти в раздел Пользователи > Сервисные аккаунты > Создать сервисный аккаунт. Затем заполните все требуемые поля и нажмите  Создать  —  подробная инструкция . Зайдите в созданный аккаунт, перейдите во вкладку API-ключи, нажмите Создать API-ключи, заполните все поля и нажмите Создать —  создание API-ключа . BASE_URL для подключения к API будет таким:  https://foundation-models.api.cloud.ru/v1 Сохраните параметры:\\xa0API_KEY\\xa0и\\xa0BASE_URL. Давайте поговорим про выбор модели, ведь взять первую попавшуюся не получится. Мой выбор для каждой задачи Для чат-бота на LangChain и RAG-системы на LlamaIndex лучше выбрать модель с небольшим контекстным окном, с высокой скоростью генерации и сравнительно небольшим количеством токенов. В первом случае нам не придется хранить длинную историю диалога, чтобы модель понимала контекст, а во втором — модель нужна только для генерации ответа, сам поиск делает эмбеддинг-модель. Поэтому для этих задач я взял RuadaptQwen2.5-7B-Lite-Beta — компактная, быстрая и отзывчивая модель, хорошо подходящая для такой задачи. Для мультиагентных систем на CrewAI и Semantic Kernel важна модель с хорошими возможностями рассуждения и планирования, а также способностью работать с большим контекстом, чтобы сохранять состояние и координировать агентов. Оптимальный выбор здесь — RuadaptQwen2.5-32B-Pro-BetaRefalMachine, она сбалансирована по мощности, позволяет работать с большим контекстом и хорошо справляется с многошаговыми задачами. Выбрав модель, нажимаем на значок сверху справа, копируем корректное название для работы через API. Теперь создайте файл окружения .env в директории вашего проекта, вставьте туда эти три параметра под соответствующими переменными. В будущем будем подключать их оттуда. Так и код красивее, и безопаснее (если планируете выгружать его на гитхаб). Так же добавим туда и используемые параметры (temperature, max_tokens). LangChain: модульная архитектура и память диалога LangChain — это такой универсальный «конструктор», который помогает собирать умные пайплайны на основе больших языковых моделей. В основе его философии лежит идея цепочек (chains): каждый шаг — генерация текста, анализ или извлечение данных — можно соединить в логичный процесс, где результат одного этапа становится входом для следующего. Это как выстроить маршрут, по которому идет твой запрос, пока не превратится в полезный и осмысленный ответ. Помимо этого, у LangChain есть готовые инструменты для «памяти»: он умеет хранить историю диалога, помнить, о чем говорилось раньше, и использовать это для более естественной беседы. Например, модули ConversationBufferMemory или SummaryMemory позволяют разным способами учитывать контекст — от простого хранения последних сообщений до умного создания краткого резюме. Забавно, что мой первый эксперимент с LangChain был простым: я решил собрать чат-бота с пониманием контекста. Оказалось, что это действительно элементарно, потому что все уже предусмотрено в самом фреймворке: от встроенной памяти до интеграции с моделями и инструментами. Обзор решения Разберу первый фреймворк довольно подробно, чтобы были понятны общие моменты по использованию стороннего API. Затем же буду разбирать только самое важное. Код пишем на питоне, тут ничего нового. Велосипед не изобретаем, пишем на чем нам удобно. Управление конфигурацией через переменные окружения: load_dotenv()\\n\\nAPI_KEY = os.getenv(\"API_KEY\")\\n\\nBASE_URL = os.getenv(\"BASE_URL\")\\xa0\\n\\nMODEL_NAME = os.getenv(\"MODEL_NAME\")\\n\\nTEMPERATURE=os.getenv(“TEMPERATURE”)\\n\\nMAX_TOKENS=os.getenv(“MAX_TOKENS”) Сначала подгружаются наши sensitive-переменные из окружения .env. llm = ChatOpenAI(\\n\\n\\xa0\\xa0\\xa0\\xa0openai_api_key=API_KEY,\\n\\n\\xa0\\xa0\\xa0\\xa0model_name=MODEL_NAME,\\n\\n\\xa0\\xa0\\xa0\\xa0openai_api_base=BASE_URL,\\n\\n\\xa0\\xa0\\xa0\\xa0temperature=TEMPERATURE,\\n\\n\\xa0\\xa0\\xa0\\xa0max_tokens=MAX_TOKENS\\n\\n) Затем происходит инициализация языковой модели через LangChain с указанием этих параметров и других дополнительных\\xa0 (температура, штрафы за повторения, штрафы за использование распространенных слов и другие). Инициализируем LLM через ChatOpenAI(), чтобы была возможность использовать встроенный в langchain функционал (промпты, память, цепочки).\\xa0 Системный промпт – ключевой элемент работы нейросети: правильно сформулированная инструкция обеспечивает надежное взаимодействие и позволяет достичь максимальной эффективности и комфорта в совместной работе. “Вы — надежный и точный AI-ассистент, который опирается исключительно на информацию из пользовательского ввода и диалоговой памяти, не добавляя ничего лишнего. Ваши ответы должны основываться на известных фактах, быть лаконичными и правдивыми: при недостатке контекста запрашивайте уточнения, но ни в коем случае не придумывайте цитаты, данные или источники. Структурируйте текст понятно и логично, используя маркированные списки для перечислений и выделяя основные идеи при подведении итогов. Соблюдайте конфиденциальность и безопасность: никогда не раскрывайте приватные данные из памяти и отказывайтесь от запросов, нарушающих правила.” ConversationBufferWindowMemory memory = ConversationBufferWindowMemory( \\xa0\\xa0\\xa0\\xa0k=8, \\xa0\\xa0\\xa0\\xa0memory_key=\"chat_history\",\\xa0 \\xa0\\xa0\\xa0\\xa0return_messages=True ) Этот компонент реализует sliding window подход к управлению памятью: k=8: Хранит только последние 8 сообщений (4 пары вопрос-ответ) memory_key: Определяет ключ для передачи истории в промпт-шаблон return_messages=True: Возвращает структурированные объекты сообщений с ролями Такая схема позволяет поддерживать контекст разговора без превышения лимита по токенам. ChatPromptTemplate prompt_template = ChatPromptTemplate.from_messages([ \\xa0\\xa0\\xa0\\xa0SystemMessagePromptTemplate.from_template(system_prompt), \\xa0\\xa0\\xa0\\xa0MessagesPlaceholder(variable_name=\"chat_history\"), \\xa0\\xa0\\xa0\\xa0HumanMessagePromptTemplate.from_template(\"{user_input}\") ]) Шаблон промпта состоит из трех компонентов: SystemMessagePromptTemplate: Системные инструкции для модели MessagesPlaceholder: Динамически подставляемая история сообщений HumanMessagePromptTemplate: Шаблон для пользовательского ввода Такая структура обеспечивает правильное форматирование контекста для современных чат-моделей. ConversationChain conversation = ConversationChain( \\xa0\\xa0\\xa0\\xa0llm=llm, \\xa0\\xa0\\xa0\\xa0memory=memory, \\xa0\\xa0\\xa0\\xa0prompt=prompt_template, \\xa0\\xa0\\xa0\\xa0input_key=\"user_input\", \\xa0\\xa0\\xa0\\xa0verbose=False ) ConversationChain объединяет все компоненты в единый исполняемый граф: Принимает пользовательский ввод. Загружает контекст из памяти. Форматирует промпт согласно шаблону. Выполняет запрос к модели. Сохраняет результат в память. Параметр input_key обеспечивает корректное сопоставление переменных в шаблоне. Демонстрация работы чат-бота LlamaIndex: индексирование и семантический поиск LlamaIndex решает задачу организации Retrieval-Augmented Generation — другими словами, учит языковые модели работать не «в вакууме», а в связке с инструментами поиска по большим массивам документов. В основе фреймворка лежит механизм создания векторных индексов практически из любых источников: текстовых файлов, баз данных, PDF-документов и многого другого. Система автоматически делит данные на удобные фрагменты, строит индекс и затем предоставляет простой интерфейс для семантического поиска. Когда пользователь задает вопрос, запрос дополняется релевантными кусками документов, и LLM формирует ответ уже на основе проверенного контента. Такой подход отлично подходит для корпоративных вики, юридических архивов и любых сценариев, где важно не просто «ответить красиво», а дать максимально точный ответ на основе реальных знаний компании. Инициализация клиента самая обычная: client = OpenAI( \\xa0\\xa0\\xa0\\xa0api_key=API_KEY,     base_url=BASE_URL ) Итак, у нас есть несколько функций, и вместе они собираются в типичный RAG-процесс. Вот такой план действий: загрузить документы; превратить их в вектора (чтобы компьютер мог их сравнивать); искать подходящие куски текста под вопрос; и скормить это языковой модели для ответа. Теперь давайте разберем каждую функцию. У нас определена папка data, откуда берутся текстовые файлы. Функция  load_files_from_dir  просто пробегает по этой папке, читает все .txt и возвращает их содержимое списком. def load_files_from_dir(dir_path=DATA_DIR):\\n\\n\\xa0\\xa0\\xa0\\xa0texts = []\\n\\n\\xa0\\xa0\\xa0\\xa0for file_path in Path(dir_path).glob(\"*.txt\"):\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0with open(file_path, encoding=\"utf-8\", errors=”replace”) as f:\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0texts.append(f.read())\\n\\n\\xa0\\xa0\\xa0\\xa0return texts Стоит отметить разве что параметр  errors=\"replace\"  — он нужен, чтобы программа не падала на «битых» символах, просто заменяет их безопасным вариантом. В итоге имеем список документов. def create_faiss_index(documents):\\n\\n\\xa0\\xa0\\xa0\\xa0print(\"Создаем эмбеддинги...\")\\n\\n\\xa0\\xa0\\xa0\\xa0embeddings = embedding_model.encode(documents, convert_to_numpy=True)\\n\\n\\xa0\\xa0\\xa0\\xa0embeddings = embeddings.astype(\"float32\")\\n\\n\\xa0\\xa0\\xa0\\xa0print(\"Создаем FAISS индекс...\")\\n\\n\\xa0\\xa0\\xa0\\xa0dim = embeddings.shape[1]\\n\\n\\xa0\\xa0\\xa0\\xa0index = faiss.IndexFlatL2(dim)\\n\\n\\xa0\\xa0\\xa0\\xa0index.add(embeddings)\\n\\n\\xa0\\xa0\\xa0\\xa0return index Ключевой момент тут — превращение текста в векторы через  embedding_model.encode . Каждый документ становится точкой в многомерном пространстве. faiss.IndexFlatL2(dim)  — это простой индекс, который считает евклидово расстояние между векторами (то самое «чем ближе, тем похожее»). def search_documents(query, index, documents, top_k=3):\\n\\n\\xa0\\xa0\\xa0\\xa0query_emb = embedding_model.encode([query], convert_to_numpy=True).astype(\"float32\")\\n\\n\\xa0\\xa0\\xa0\\xa0distances, indices = index.search(query_emb, top_k)\\n\\n\\xa0\\xa0\\xa0\\xa0return [documents[i] for i in indices[0] if i < len(documents)]\\n\\ndef generate_answer(query, context_docs):\\n\\n\\xa0\\xa0\\xa0\\xa0context_text = \"\\\\n\\\\n\".join(context_docs)\\n\\n\\xa0\\xa0\\xa0\\xa0prompt = (\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"Контекст:\\\\n\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0f\"{context_text}\\\\n\\\\n\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0f\"Вопрос: {query}\\\\n\\\\n\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"Отвечай только на основе контекста.\"\\n\\n\\xa0\\xa0\\xa0\\xa0) Запрос мы кодируем тем же способом, что и документы  (embedding_model.encode([query])) , иначе сравнивать смыслы не получится. index.search (query_emb, top_k)  вернет ближайшие документы, и мы вытаскиваем их из исходного списка. И наконец, вызов метода API: response = client.chat.completions.create(\\n\\n\\xa0\\xa0\\xa0\\xa0model=MODEL_NAME,\\n\\n\\xa0\\xa0\\xa0\\xa0messages=[\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0{\"role\": \"system\", \"content\": \"Ты помощник, который отвечает по данным из контекста.\"},\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0{\"role\": \"user\", \"content\": prompt}\\n\\n\\xa0\\xa0\\xa0\\xa0],\\n\\n\\xa0\\xa0\\xa0\\xa0max_tokens=MAX_TOKENS,\\n\\n\\xa0\\xa0\\xa0\\xa0temperature=TEMPERATURE,\\n\\n) И в ответ получаем наиболее подходящий фрагмент текста. Это и есть наша «умная выдача». Действительно, точь-в-точь все взято из контекста, ничего не придумано. Если хотите, можете поиграться с системным промптом. Например, можно указать, чтобы модель сама генерировала ответ на основе данных из базы знаний. Это будет полезно, если хотите получить нормально сформулированный ответ на свой вопрос, без подтягивания лишнего контекста. CrewAI vs Semantic Kernel: мультиагентные системы В моем случае оба фреймворка решают\\xa0схожую задачу\\xa0— организацию взаимодействия нескольких агентов, но делают это по-разному. CrewAI: простота и декларативность CrewAI делает ставку на ясность и структурность. Здесь мультиагентный сценарий описывается декларативно: каждому агенту задается роль, цель и предыстория (backstory), а дальше задачи распределяются внутри «экипажа» (crew). Фреймворк сам управляет порядком их выполнения и передачей контекста между агентами. Получается модель, где, например, один агент «Исследователь» копается в данных, второй — «Технический писатель» готовит на основе анализа отчет, а третий проверяет все на ошибки. Такой способ отлично работает для имитации бизнес‑процессов с четким разделением обязанностей. llm = LLM( \\xa0\\xa0\\xa0\\xa0model=f\"openai/{MODEL}\",\\xa0 \\xa0\\xa0\\xa0\\xa0api_key=API_KEY, \\xa0\\xa0\\xa0\\xa0base_url=BASE_URL, \\xa0\\xa0\\xa0\\xa0temperature=TEMPERATURE, \\xa0\\xa0\\xa0\\xa0max_tokens=MAX_TOKENS \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0) Инициализация отличается от других фреймворков. Используем встроенный LLM-класс, при этом название передаем с префиксом провайдера (openai/), так требует CrewAI. researcher = Agent(\\n\\n\\xa0\\xa0\\xa0\\xa0role=\"Исследователь\",\\n\\n\\xa0\\xa0\\xa0\\xa0goal=\"Провести структурированный анализ применения технологий искусственного интеллекта в российском бизнесе за период 2023–2025 года.\",\\n\\n\\xa0\\xa0\\xa0\\xa0backstory=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0Эксперт-аналитик с опытом работы в сфере корпоративных инноваций и ИИ. Отличается глубоким пониманием рынков, умеет критически оценивать тренды и проверять источники. Всегда выделяет главное и избегает предположений без фактов.\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\",\\n\\n\\xa0\\xa0\\xa0\\xa0llm=llm,\\n\\n\\xa0\\xa0\\xa0\\xa0verbose=True\\n\\n) writer = Agent(\\n\\n\\xa0\\xa0\\xa0\\xa0role=\"Технический писатель\",\\n\\n\\xa0\\xa0\\xa0\\xa0goal=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0Создать краткий, структурированный и деловой отчет на основе полученного анализа;\\n\\n\\xa0\\xa0\\xa0\\xa0акцент на ясность, практические рекомендации и бизнес-ориентированность.\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\",\\n\\n\\xa0\\xa0\\xa0\\xa0backstory=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0Профессиональный технический писатель с опытом подготовки деловых обзоров и рекомендаций для руководителей.\\n\\n\\xa0\\xa0\\xa0\\xa0Отличается умением переводить сложные выводы на простой, понятный для бизнес-аудитории язык без потери точности.\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\",\\n\\n\\xa0\\xa0\\xa0\\xa0llm=llm,\\n\\n\\xa0\\xa0\\xa0\\xa0verbose=True\\n\\n) Здесь инициализируются агенты, каждому выдается role и goal. В backstory описывается, кто они такие и для чего они предназначены. Параметр verboose включает вывод в консоль подробного отчета о работе агентов (увидите это на скринах). research_task = Task(\\n\\n\\xa0\\xa0\\xa0\\xa0description=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0Собери актуальный аналитический обзор по теме: «Применение ИИ в российском бизнесе в 2023–2025».\\n\\n\\xa0\\xa0\\xa0\\xa0Требуется описать:\\n\\n\\xa0\\xa0\\xa0\\xa0— главные направления использования (3-4);\\n\\n\\xa0\\xa0\\xa0\\xa0— ключевые компании и конкретные решения (3-4);\\n\\n\\xa0\\xa0\\xa0\\xa0— основные тренды и вызовы (3-4).\\n\\n\\xa0\\xa0\\xa0\\xa0Оформи анализ как структурированный список с пояснениями. Ответ до 400 слов\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\",\\n\\n\\xa0\\xa0\\xa0\\xa0agent=researcher,\\n\\n\\xa0\\xa0\\xa0\\xa0expected_output=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0Аналитический отчет, включающий список направлений применения, перечень компаний с их решениями и описание\\n\\n\\xa0\\xa0\\xa0\\xa03–5 актуальных трендов, с четкими ссылками на факты или источники.\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\"\\n\\n) writing_task = Task(\\n\\n\\xa0\\xa0\\xa0\\xa0description=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0На основе аналитического обзора подготовь краткий бизнес-отчет:\\n\\n\\xa0\\xa0\\xa0\\xa0— резюме (2–3 предложения);\\n\\n\\xa0\\xa0\\xa0\\xa0— 3–4 основных вывода (маркированный список);\\n\\n\\xa0\\xa0\\xa0\\xa0— 2–3 рекомендации для бизнеса (маркированный список).\\n\\n\\xa0\\xa0\\xa0\\xa0Должен быть структурирован, лаконичен (150–200 слов), без лишних деталей.\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\",\\n\\n\\xa0\\xa0\\xa0\\xa0agent=writer,\\n\\n\\xa0\\xa0\\xa0\\xa0expected_output=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0Компактный, структурированный отчет для бизнес-аудитории: резюме темы, основные выводы по анализу, практические рекомендации.\\n\\n\\xa0\\xa0\\xa0\\xa0\"\"\",\\n\\n\\xa0\\xa0\\xa0\\xa0context=[research_task]\\n\\n) С постановкой задач думаю все понятно, долго останавливаться тут не будем. Хочется только отметить, что помимо всего в переменную  context  второго агента дополнительно передается результат работы первого агента. По его проделанной работе\\xa0 тех. писатель будет составлять итоговый отчет. team = Crew( \\xa0\\xa0\\xa0\\xa0agents=[researcher, writer], \\xa0\\xa0\\xa0\\xa0tasks=[research_task, writing_task], \\xa0\\xa0\\xa0\\xa0verbose=True ) Crew объединяет агентов и задачи и координирует их выполнение, передавая контекст между задачами. Результат второго агента Результат работы первого агента тоже выводится, но слишком он уж громоздкий. Кому интересно, все материалы будут выложены на гитхаб (ссылка в конце статьи). Semantic Kernel: гибкость и расширяемость Semantic Kernel от Microsoft — это уже больше про инженерный фундамент. Он объединяет функционал для чат-ботов, RAG‑систем и мультиагентных сценариев, предлагая ядро (Kernel), в котором можно регистрировать сервисы и создавать агентов через ChatCompletionAgent. Важное отличие — он сразу проектировался под асинхронный мир: операции выполняются неблокирующе, с поддержкой телеметрии и хорошей интеграцией в экосистемы .NET и Python. Если нужно сохранять историю диалога, делать семантический поиск, строить сложные последовательности действий — все это можно собрать прямо внутри. Агентов тут можно объединять в рамках одного асинхронного процесса, что делает платформу гибкой и удобной для прототипирования и параллельных задач. Сначала все так же: переменные окружения и класс-обертка. Для чего же обертка? В Semantic Kernel немного иначе устроена работа с моделями — там все проходит через специальные «переводчики» (адаптеры), которые помогают связать внутренние данные с нужным API. Поэтому нельзя просто взять и подать клиент OpenAI напрямую, нужна небольшая обертка. Это делается для удобства и чтобы модель всегда правильно понимала, что ей говорить и как вести себя в разговоре. В других фреймворках вроде langchain или llamaindex все проще — они сразу общаются с клиентом без таких «переводчиков». class AgentService(ChatCompletionClientBase):\\n\\n\\xa0\\xa0\\xa0\\xa0def init(self, service_id: str):\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0super().__init__(service_id=service_id, ai_model_id=MODEL)\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0self._client = OpenAI(\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0api_key=API_KEY,\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0base_url=BASE_URL\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0)\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0self._model = MODEL Наследуется ChatCompletionClientBase, передавая service_id и идентификатор модели. Создается экземпляр OpenAI-клиента с ключом и URL.\\xa0 async def get_chat_message_contents(self, chat_history: ChatHistory, settings: PromptExecutionSettings, **_):\\n\\n        messages = [{\"role\": m.role.value, \"content\": str(m.content)} for m in chat_history.messages]\\n\\n        response = await asyncio.to_thread(\\n\\n            self._client.chat.completions.create,\\n\\n            model=self._model,\\n\\n            messages=messages,\\n\\n            temperature=TEMPERATURE,\\n\\n            max_tokens=MAX_TOKENS\\n\\n        )\\n\\n        return [ChatMessageContent(role=\"assistant\", content=response.choices[0].message.content)]\\n В semantic kernel используем асинхронный метод отправки и получения сообщений. История чата преобразуется в список словарей с полями role и content.\\xa0 Вызывается синхронный метод self._ client.chat .completions.create. Чтобы не блокировать асинхронный цикл asyncio во время длительного сетевого запроса, этот метод запускается в отдельном потоке через await  asyncio.to _thread(...). Это позволяет интегрировать синхронную функцию в асинхронный код, не замедляя выполнение других задач. И последний блок main. Здесь создается ядро Kernel и регистрируется сервис.\\xa0 async def main(): \\xa0\\xa0\\xa0\\xa0kernel = Kernel() \\xa0\\xa0\\xa0\\xa0svc = AgentService(\"cloudru\") \\xa0\\xa0\\xa0\\xa0kernel.add_service(svc)     researcher = ChatCompletionAgent(\\n\\n        service=svc,\\n\\n        kernel=kernel,\\n\\n        name=\"researcher\",\\n\\n        instructions=\"\"\"\\n\\n        Роль: Исследователь.\\n\\n        Цель: Провести структурированный анализ применения ИИ в российском бизнесе (2023–2025).\\n\\n        Стиль: Кратко, с фактами и ссылками, в виде списка направлений, компаний и трендов.\\n\\n        \"\"\"\\n    ) \\xa0\\xa0\\xa0\\xa0writer = ChatCompletionAgent(\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0service=svc,\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0kernel=kernel,\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0name=\"writer\",\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0instructions=\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Роль: Технический писатель.\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Цель: На основе анализа подготовить деловой отчет (150–200 слов):\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa01) резюме (2–3 предложения);\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa02) 3–4 вывода;\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa03) 2–3 рекомендации.\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Стиль: Лаконично, понятно для руководителей.\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0) \\xa0\\xa0\\xa0\\xa0print(\"Исследователь начал работу...\")\\n\\n\\xa0\\xa0\\xa0\\xa0research = \"\"\\n\\n\\xa0\\xa0\\xa0\\xa0async for step in researcher.invoke(\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Собери актуальный аналитический обзор по теме: «Применение ИИ в российском бизнесе в 2023–2025».\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Требуется описать:\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0— главные направления использования (3-4);\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0— ключевые компании и конкретные решения (3-4);\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0— основные тренды и вызовы (3-4).\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Оформи анализ как структурированный список с пояснениями. Ответ до 400 слов\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0):\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0research = step.message.content\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0print(\"\\\\nОтвет исследователя:\\\\n\", research) \\xa0\\xa0\\xa0print(\"\\\\nПисатель начал работу...\")\\n\\n\\xa0\\xa0\\xa0\\xa0report = \"\"\\n\\n\\xa0\\xa0\\xa0\\xa0async for step in writer.invoke(\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0f\\'Используя этот текст:\\\\n{research}\\\\n\\'\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Подготовь краткий бизнес-отчет:\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0— резюме (2–3 предложения);\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0— 3–4 основных вывода (маркированный список);\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0— 2–3 рекомендации для бизнеса (маркированный список).\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Должен быть структурирован, лаконичен (150–200 слов), без лишних деталей.\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\"\"\"\\n\\n\\xa0\\xa0\\xa0\\xa0):\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0report = step.message.content\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0print(\"\\\\n Отчет:\\\\n\", report) Определяются два агента: «researcher» и «writer» с инструкциями (роли, цели и стиль). С помощью асинхронных итераторов invoke каждый агент последовательно выполняет свою задачу и печатает результаты. Что лучше Оба решения ведут к одной цели — распределенному управлению процессом анализа и генерации текста силами нескольких агентов, — но философия у них разная. CrewAI ближе к объектно‑ориентированному стилю: агенты, задачи и «экипаж» описаны как классы с четким разделением ролей и синхронными вызовами через метод call. Такой подход помогает структурировать проект и легко масштабировать его на большие команды агентов. Semantic Kernel, наоборот, держится асинхронного и скорее функционального подхода: взаимодействия организуются через корутины и неблокирующие вызовы, агенты общаются прямо в теле основной асинхронной функции, а результат может передаваться «ручным» способом — как часть очередного запроса. Это делает платформу более гибкой для быстрых экспериментов. Итог: CrewAI — это про простоту, декларативность и «правильное» ООП‑структурирование, а Semantic Kernel — про асинхронный масштаб, расширяемость и скорость прототипирования. В зависимости от задачи можно выбрать подход, который больше подходит: строгую модель управления «экипажем» или свободную архитектуру асинхронных агентов. Все обещанные скриншоты с результатами  на гитхабе .  Выводы и рекомендации После тестирования всех четырех фреймворков я получил четкое понимание их сильных и слабых сторон. LangChain оказался самым универсальным решением для быстрого прототипирования. Его модульная архитектура позволяет легко экспериментировать с различными подходами: от простых чат-ботов до сложных цепочек рассуждений и RAG-сценариев с подключением внешних источников данных. Богатая экосистема интеграций и активное сообщество делают его идеальным выбором для стартапов и MVP‑проектов, где важна скорость разработки и гибкость архитектуры. LlamaIndex показал себя как безусловный лидер в области RAG‑систем. Фреймворк берет на себя всю сложность индексирования документов, векторного поиска и оптимизации контекста. Это критически важно для корпоративных сценариев, где нужно работать с большими объемами документации, базами знаний или техническими спецификациями. Простота API позволяет буквально за несколько строк кода создать полноценную систему поиска по корпоративным данным. Могу предложить вариант еще проще. Так, если вам нужна rag-система по определенной базе знаний, то лучше воспользуйтесь сервисами Cloud.ru Evolution Managed Rag и Object Storage для хранения данных различных форматов. Там это все можно настроить буквально за несколько минут (инструкции прикреплю ниже). CrewAI продемонстрировал уникальный подход к мультиагентным системам через декларативное описание ролей и задач. Фреймворк особенно эффективен для моделирования реальных бизнес‑процессов, где разные «специалисты-агенты» последовательно работают над задачей. Автоматическое управление контекстом между агентами существенно упрощает разработку сложных пайплайнов обработки информации. Semantic Kernel оправдал звание корпоративного решения от Microsoft. Его важная особенность — тесная интеграция с экосистемой .NET, что логично с учетом происхождения проекта и ориентации на инфраструктуру Microsoft. Архитектура с централизованным ядром, асинхронной обработкой и расширяемостью через skills делает его оптимальным выбором для интеграции с enterprise‑системами. Возможность объединить функциональность чат-ботов, RAG‑поиска и мультиагентных систем в едином фреймворке снижает архитектурную сложность и помогает строить масштабные проекты. Опыт работы с Cloud.ru Evolution Могу сказать, что интеграция действительно получается довольно гладкой. OpenAI-совместимый интерфейс позволяет большинство существующих решений подключать практически без изменений — меняются только endpoint и ключи аутентификации. Это экономит время на адаптацию кода. Что касаемо реализации: кодить конечно круто, но зачем это нужно, когда есть готовые сервисы, которые предназначены для решения таких задач, причем позволяют сделать это намного быстрее.\\xa0 Важное замечание о коде: все представленные примеры кода являются POC-решениями и не претендуют на production-готовность. Их цель — продемонстрировать базовые паттерны интеграции Cloud.ru Evolution с различными фреймворками. В реальных проектах необходимо добавить обработку ошибок, логирование, валидацию входных данных, ограничения по rate limiting и другие механизмы, обеспечивающие надежность и безопасность приложения. Интеграция  Evolution Foundation Models  с современными фреймворками оказалась простой в реализации. Выбирайте инструмент под конкретную задачу и тогда получите максимальную эффективность от AI в ваших проектах. А еще, прямо сейчас и до конца октября все модели бесплатные, можно попробовать их в деле. ', hub='машинное обучение'), Page(id='945382', title='Почему революция в CRM-системах никак не происходит?', content='Я в сфере разработки CRM-систем больше 20 лет, и все эти годы было интересно не только разрабатывать, но и наблюдать за этой специфической нишей в контексте бурного, местами скачкообразного развития технологий в целом. Если говорить образно, сфера CRM - остров стабильного, поступательного развития и безветрия на фоне ревущей стихии вокруг. При этом никто для этого ничего специально не делал: просто так сложились факторы.\\xa0 Так ждать ли революции CRM сегодня, когда, кажется, мир технологий абсолютно бескомпромиссно меняет искусственный интеллект? Поспешай медленно CRM меняются, но это эволюция За последние полтора десятилетия CRM-системы пережили несколько очень интересных трансформаций. Первая и главная, конечно, переход в облака. Сперва это казалось очень крутым решением: не нужно покупать железные сервера, платить за электричество, нанимать сисадминов, думать о безопасности - вся эта лихая магия происходила в облаке, которое нередко и для пользователей, и для руководства компании оказывалось чёрным ящиком. Потом, конечно, выяснилось «чудное»: для работы в облаках лучше иметь своего неплохого админа, в них всё далеко не безопасно, можно накатить обновления, отключить от облака, продать бэкапы в случае форс-мажора. А ещё хостинг-провайдер может сломаться, сгореть, обанкротиться или прилечь на несколько дней. На сегодняшний день набито немало шишек, но облака остаются популярной формой существования приложений для бизнеса. Слияние разных типов CRM-систем ознаменовалось почти полным прекращением деления на операционные, аналитические и гибридные CRM-системы. Деление изначально казалось странноватым (например, для нас, разработчиков универсальной  RegionSoft CRM ): зачем вообще отделять аналитику от операционки, ведь это крутые, дополняющие друг друга сферы одной сущности — надёжной и умной CRM-системы.\\xa0 Мобильный first в CRM тоже не совершил революцию. Да, здорово, когда с мобильного можно исполнять некоторые функции, вносить данные и контакты, но в целом работа в CRM-системе ведётся именно на рабочих стационарных ПК и ноутбуках, многие вещи делать с мобильного просто нецелесообразно. Так что мобильные CRM стали дополнением, но никак не полноценным многофункциональным решением. Омниканальность тоже стала логичным продолжением наращивания функциональности, фактически она ответила вызовам времени: пользователи хотят контактировать с компаниями откуда заблагорассудится, и задача CRM-системы — «поймать» все обращения и лиды, идентифицировать и разместить в нужной карточке.\\xa0 Искусственный интеллект начал пробираться в CRM-системы ещё в середине 2010-х, но за это время не вот чтобы обосновался, особенно в секторе малого и среднего бизнеса. Безусловно, какие-то отдельные функции уже отдаются и будут отдаваться на откуп обученным алгоритмам или ботам, но это такая маленькая доля функциональности CRM, что пока рано анализировать её как серьёзную революцию и даже как поворот в какую-то новую реальность автоматизации. Посмотрим, что будет через 2-3 года. Какие технологии обошли CRM стороной? Блокчейн — обещавший стать гарантией безопасности сделок и всего на свете, он так и не вошёл в программное обеспечение для автоматизации бизнеса. Интерес к блокчейну падает и, с увеличением роли ИИ, скорее всего, останется зоной интереса майнеров криптовалют (а вместе с ними, разных скамеров и интернет-мошенников). Метавселенные обошли CRM-системы стороной точно так же, как почти всё, связанное с бизнесом. Это совершенно ненужный бантик. Нейросети как суррогат человека тоже не особо приживаются, хотя некоторые компании и пытаются заставлять роботов общаться с клиентами. Вообще, общение человека с ботом, намеренно «косящим» под человека, противоречит самому духу концепции CRM. Лучше, если клиент всегда точно будет знать, общается он с роботом или с живым человеком.\\xa0 А ещё интересный факт: CRM-системы пережили массу передовых и интересных технологий, а некоторые — так даже языки программирования, на которых были изначально созданы (точнее, последние уже сильно сдали позиции, а CRM, написанные на них, до сих пор отлично работают и обновляются уже на другом стеке). Такая стабильность не случайна. Почему революция отменяется? Пользователи CRM-систем — компании. Причём, обычно, если компания встала на путь автоматизации и самостоятельно выбрала систему в которой работает, она уже поняла, что такое ИТ для бизнеса и почему с ним лучше, чем без него. Среди таких редко находятся фрики, которые увольняют всех сотрудников и заменяют их на ИИ или внезапно решают ставить на оперативной работе эксперименты и менять софт по каждому чиху модных технологий.\\xa0 Риски Первое, что все делают, это оценивают риски: риски сбоя, потери данных, компрометации данных, внесения некорректной информации. Поскольку за каждой записью в CRM, будь то сделка или карточка клиента, стоят инвестиции в привлечение, удержание, отстройку от конкурентов, поддержку, то бишь, говоря проще, деньги, перечисленные риски являются высокими. Риски переноса данных, миграции и «доверия» искусственному интеллекту пока точно перевешивают потенциальные выгоды новых технологий.\\xa0\\xa0 ИТ-инфраструктура У многих компаний (даже весьма небольших) крупная для их масштаба и устойчивая ИТ-инфраструктура. Встроить в неё ИИ не так просто, это потребует анализа, оценки, сбора требований, а самое главное, людей для внедрения и поддержки этой новой зоны инфраструктуры. При этом ландшафт может поменяться и, что особенно неприятно в сфере информационной безопасности. Безопасность ИИ для бизнеса вообще пока чёрный ящик, тут с обычной бы разобраться, а внедрение ИИ гарантирует то, что придётся доверять совершенно сторонним организациям, непонятным массивам данных, различным прослойкам между алгоритмом и конечным решением. Пока такое допустимо реализовать максимум на корпоративном хакатоне «по приколу».\\xa0 Процессы Если гипотетически представить набор самых искусственно-интеллектуальных ботов, умеющих продавать, продвигать, проводить пресейл и проч, у них точно будет особенное требование: жёсткая формализация процессов и коммуникаций.  Внедрение CRM  упирается в процессы, работает с процессами и нередко зависит от процессов, но ни разу не было такого, чтобы в компании были идеальные, формализованные процессы, которые бы неукоснительно исполнялись. У процессов много «синдромов»: лоскутность (частичная автоматизация), слабая формализация, высокий уровень ветвления в рамках задач и т. д. Всё это можно обработать и скорректировать с помощью человеческого разума, но нельзя с помощью ИИ. Он просто не поймёт, почему на третьем этапе «договорились» и провели поставку без документов, на другой адрес и вообще не того товара 🙂\\xa0\\xa0 CRM самодостаточны Существующие развитые CRM полностью удовлетворяют базовые потребности пользователей, поскольку дорабатываются и обновляются на основании запросов и требований. Фактически стимулов для радикальных изменений нет. И это очень приятная особенность рынка: мы добавляем в функциональность то, с чем работает бизнес — и в итоге они избегают переплаты за ненужный тюнинг, мы рационально разбираем бэклог. Мы — это большинство серьёзных CRM-разработчиков, не один только  РегионСофт . Такая ситуация в том числе комфортна для пользователей: они не получают обновления, придуманные «визионером» при температуре 39,5, а имеют под рукой то, что нужно здесь и сейчас для успешной работы. Безусловно, рынок ждёт какие-то решения на базе ИИ (обработка звонков, расшифровка, информирование и т. д.) — конечно, в скором времени он это получит.\\xa0 Путь CRM-систем — поступательное развитие: инновации (чат-боты на GPT, автоматизация холодных писем) добавляются как модули, а не меняют ядро и логику систем. А как меняются CRM? Если коротко — вместе с пользователями! Мне нравится разнообразие, которое есть на рынке российских CRM-систем: от микросистем для микробизнеса с упрощённым интерфейсом и мгновенным стартом до серьёзных отраслевых и узкоотраслевых решений (например, для медицины или строительства). Но есть кое-что, что всё-таки может если не сделать революцию, то как минимум вывести CRM на новый уровень развития и использования.\\xa0 Например, крупные системы для очень больших компаний способны изменить квантовые вычисления, которые обеспечат обработку больших данных в реалтайме с построением сверхточных прогнозов. Впрочем, многое реализуемо уже сегодня, без квантов, но я думаю, что это всё-таки придёт с ростом доступности таких вычислений — уж больно красивый маркетинг получается ;-)\\xa0 Пожалуй, ещё остаётся какой-то призрачный шанс для децентрализованных CRM на блокчейне, но кажется, что это слишком серьёзная переработка логики и существующие вендоры смогут создать что-то подобное только под хорошего инвестора — того, кто гарантированно купит, внедрит и будет развивать такое решение. А вот в упрощение интерфейсов я не верю. Сейчас на разных конференциях менеджеры продуктов рассказывают про необходимость новых простых интерфейсов для зумеров и альфа, которые выросли на ТикТоке. По мне, это тоже чистый маркетинг и отчасти троллинг: вроде клиенты всех возрастов справляются со сложными и функциональными интерфейсами. Хотя, конечно, кнопку «запустить продажи и сделать выручку» хотели бы все… Ну и ещё момент, о котором важно сказать. Компании рассматривают CRM-системы как инструмент учёта (клиентов, сделок, лидов и т. д.), но не как платформу для интенсивного роста. Между тем, практически все топовые системы уже сейчас готовы выполнять эту функцию — и здесь как раз может произойти революция, но опять же — со стороны пользователей и по их запросу. Разработчики к такому прорыву готовы. Но так ли он нужен? Алексей Суриков Главный разработчик\\xa0 RegionSoft  ', hub='искусственный интеллект'), Page(id='945376', title='Pioneer LaserActive: редчайшая гибридная консоль на лазердисках из 90-х и ее цифровое возрождение в наше время', content='В мире ретрогейминга есть устройства, ставшие легендами не из-за массовой популярности, а благодаря своей уникальности и смелости идей. Пример — гибрид плеера и игровой приставки Pioneer LaserActive, выпущенный в 1993 году. Он позиционировался как универсальная мультимедийная система, объединяющая кино, музыку и видеоигры в одном устройстве. Идея была классной. Но из-за высокой цены в сотни долларов США LaserActive так и осталась нишевой системой. Спустя более трех десятилетий интерес к LaserActive вернулся: энтузиасты создали первый эмулятор для ПК, и теперь эта уникальная страница истории снова доступна игрокам и исследователям. LaserActive: мечта о мультимедийном будущем В начале 1990-х игровая индустрия переживала переход от картриджей к оптическим носителям. CD-ROM стали появляться в консолях вроде Sega CD и TurboGrafx-16/PC Engine. Pioneer пошла дальше,  представив  LaserActive на лазердисках. Эти 12-дюймовые носители,  появившиеся  еще в 1978 году, хранили до 60 минут аналогового видео стандартного качества на каждой стороне.  Вот так выглядел этот убердевайс.  Источник Базовая модель, Pioneer CLD-A100, стоила 970 долларов. Модули для поддержки игр Sega Genesis/Mega Drive или NEC TurboGrafx-16/PC Engine обходились в дополнительные 600 баксов каждый. Игры на лазердисках, известные как Mega-LD (для Sega) и LD-ROM² (PC Engine), стоили около 120 долларов за штуку.  Для сравнения, в 1993 году Sega Genesis с модулем Sega CD можно было купить за 200–300 $, а TurboDuo от NEC — около 400 $. То есть за 2\\xa0100 долларов США (столько стоил лазердисковый убердевайс со всеми модулями) можно было купить  вообще все популярные модели консолей  и игры к ним. И, наверное, еще осталось бы.  Система представляла собой массивный металлический блок размером 420×390×145 мм и весом почти 8 кг. Она оснащалась оптическим приводом с длиной волны 780 нм, воспроизводившим стандартные лазердиски, CD-аудио, CD-Video и CD+G (для караоке). Игровые возможности открывались при подключении модулей PAC, упомянутых выше. Они добавляли совместимость с картриджами и CD-играми Sega или NEC, а также с эксклюзивными лазердисковыми игрушками. Так, Mega-LD PAC позволял запускать картриджи Sega Genesis, диски Sega CD и специальные Mega-LD игры, а LD-ROM² PAC поддерживал HuCard и CD-ROM² для PC Engine. LaserActive с модулем Sega PAC.  Источник ы LaserActive выделялась модульной архитектурой. Модули PAC вставлялись в специальный отсек, причем их функциональность зависела от встроенного процессора и программного обеспечения. Например, Sega PAC (PAC-S10) включал чипы, аналогичные тем, что использовались в Genesis. Благодаря этому была полная совместимость с играми этой платформы. Ну а NEC PAC (PAC-N10) воспроизводил архитектуру TurboGrafx-16. То есть LaserActive действительно была универсальной платформой, как и обещали разработчики.  Но это удовольствие стоило кучу денег. Высокая цена сделала LaserActive игрушкой для энтузиастов и коллекционеров, общие продажи в Японии и США оцениваются всего в 10\\xa0000 единиц. Как работала система: техническая магия лазердисков Чтобы понять и оценить уникальность LaserActive, давайте попробуем разобраться в ее устройстве. В основе системы лежал лазердисковый привод, который считывал аналоговое видео и аудио, а также цифровые данные, закодированные в  LD-ROM . Этот формат, основанный на стандарте LV-ROM, позволял хранить до 540 Мб данных на диске для Mega-LD, в то время как LD-ROM² использовал схожий подход, но с небольшими различиями в структуре, ориентированными на архитектуру PC Engine. Это было огромным объемом на момент 1993 года. Для сравнения, стандартный CD-ROM вмещал около 650 Мб, но не мог хранить аналоговое видео, что делало лазердиски уникальными. LaserActive с дисками и аксессуарами.  Источник Игры на Mega-LD и LD-ROM²  комбинировали  цифровые данные (графику, код, звук) с аналоговыми видеороликами. Например, игра могла использовать 2D-спрайты, наложенные на полноэкранное видео, создавая иллюзию интерактивного фильма. Лазердиск обеспечивал высококачественные кинематографические сцены, которые синхронизировались с действиями игрока через модуль PAC. Правда, это требовало комплексной работы с данными: для доступа к нужным видеофрагментам использовалась информация из «таблицы содержимого» (TOC), которая определяла, где на диске находятся те или иные сцены. С технической стороны эмуляция LaserActive оказалась очень сложной. Видео на лазердисках  записывалось  в виде композитного аналогового сигнала, а управляющая информация пряталась в области VBI (вертикальный гашенный интервал) — ее обычно не фиксировали стандартные платы захвата. Поэтому для оцифровки дисков пришлось использовать специализированное оборудование, которое могло одновременно считывать и аналоговую картинку, и цифровые данные. К тому же полученные файлы занимали колоссальный объем: один диск в формате без потерь весил до 28 Гб, что делало хранение и обработку еще более трудоемкими. Игровой процесс зависел от модулей PAC, они превращали LaserActive в полноценную консоль Sega или NEC. Так, Mega-LD игры задействовали процессор Motorola 68000 из Genesis для обработки спрайтовой графики и логики, а лазердиск в это время обеспечивал фоновое видео и звук. Такое сочетание давало возможность создавать проекты с по-настоящему кинематографическим размахом. Но одновременно оно требовало идеальной синхронизации цифровых и аналоговых потоков: малейший сбой приводил к задержкам или показу не той сцены. Из-за этого разработка игр для LaserActive была намного сложнее и рискованнее, чем для традиционных консолей. Тем не менее библиотека LaserActive насчитывала 34 игры в формате LD-ROM: 23 для Mega-LD и 15 для LD-ROM², причем некоторые проекты выходили для обоих модулей. Эти игры были уникальны тем, что сочетали традиционные игровые механики с кинематографическими видеороликами, что в 1993 году выглядело как шаг в будущее. Источник Среди Mega-LD игр выделялись такие проекты, как  Pyramid Patrol  и  Space Berserker .  Pyramid Patrol  предлагала игроку исследовать древнеегипетские локации, используя лазердиск для отображения анимационных сцен и фонов.  Space Berserker  был динамичным шутером, где спрайты космического корабля накладывались на видеоролики с шикарными пейзажами. Обе игры использовали возможности Sega Genesis для обработки игровой логики, но их визуальная составляющая была на голову выше того, что предлагали стандартные картриджи или CD. Кроме эксклюзивных LD-ROM игр, LaserActive поддерживала картриджи и CD от Sega Genesis и TurboGrafx-16, что делало ее универсальной платформой. Однако высокая стоимость дисков и их редкость ограничивали популярность. Например, в США найти LD-ROM²-игры было почти невозможно из-за низкой востребованности TurboGrafx-16 на этом рынке. Эмуляция LaserActive: подвиг энтузиастов В 2025 году LaserActive получила вторую жизнь  благодаря эмулятору Ares v146 , созданному разработчиком под псевдонимом Nemesis. Этот проект стал кульминацией 15 лет работы, начавшейся еще в 2009 году. Nemesis, страстный поклонник ретрогейминга, посвятил годы изучению архитектуры LaserActive и оцифровке ее лазердисков. Его усилия привели к тому, что игры формата Mega-LD впервые стали доступны на ПК без необходимости искать редкое оборудование. Рабочее место хакера, который создал эмулятор приставки. Работал он несколько лет подряд.  Источник Создать эмулятор было непросто главным образом из-за необходимости перевести аналоговое видео с лазердисков в «цифру». Обычные платы захвата с этим не справлялись: они игнорировали специальные сигналы (VBI), в которых хранились команды для игр. Поэтому Nemesis применил проект Domesday Duplicator и написал собственную программу ld-decode, которая позволяла сохранять видео без потерь. В результате один диск занимал до 28 Гб, и работа с ним требовала много ресурсов. Для захвата данных Nemesis модифицировал свой Sega PAC-S10, припаивая провода к модулю и используя логический анализатор Saleae для считывания сигналов. Это позволило ему извлечь «таблицу содержимого» и синхронизировать цифровые и аналоговые компоненты. Удивительно, но после успешной оцифровки дисков эмуляция оказалась относительно простой: большинство игр, таких как  Space Berserker , запускалось без проблем, так как Nemesis воспроизвел все особенности оригинального «железа». А это — стартовое окошко самого эмулятора.  Источник Но все не напрасно. Усилия Nemesis привели не только к созданию рабочего эмулятора, но и к сохранению уникальной части игровой истории. Ares v146 стал первым инструментом, который сделал библиотеку LaserActive доступной без редкого и дорогого оборудования. Цифровое наследие сохранено, за что спасибо энтузиастам.', hub='история it'), Page(id='945300', title='Я тимлид, который искал работу в 2025', content='Дисклеймер: статья написана на основе интервью с руководителем отдела тестирования Лилией Иксановой Меня зовут Лилия. 10 лет я руководила отделом тестирования, последние 3 года работала начальником отдела тестирования в SBI банке.\\xa0 Комментарий редакции: по данным Хабр Карьеры, QA Lead получает от 360 до 570 тыс. ₽ в месяц. Раньше я искала работу не больше двух недель. В июле 2025 года я вышла на рынок труда и поняла, как все изменилось. Я слышала истории друзей и знакомых, которые ищут работу по полгода. Мне казалось это странным. Сейчас я сама столкнулась с тем, что даже с моим солидным опытом поиск занял целых два месяца. Расскажу, как все было. Воронка поиска За два месяца я сделала 90 откликов на интересные для меня вакансии. Результативность откликов: Примерно 20 отказов через hh ~10 приглашений на собеседования через hh 20-30 приглашений через прямые каналы (Telegram, WhatsApp) — это были отдельные HR-специалисты, которые нашли мое резюме на hh и написали мне напрямую В итоге сходила примерно на 50 собеседований за два месяца. Имею в виду не только с HR, но и следующие этапы — с нанимающими менеджерами и технические интервью. Мой поиск пришелся на июль-август — невысокий сезон. Считается, что в эти месяцы компании смотрят резюме, но не очень набирают. Многие процессы замедляются из-за отпусков и летнего затишья.\\xa0 Как ИИ помог структурировать опыт в резюме Базовое резюме у меня было, и раньше оно отлично работало — никогда не искала работу больше двух недель. А сейчас, даже с качественным резюме, поиск занял два месяца. Проблема не в том, что резюме плохое или его нужно кому-то проверять. Проблема в том, что рынок кардинально изменился. Так что я решила доработать свое резюме с помощью ИИ. Я составляла промпты с описанием своего опыта, ИИ систематизировал информацию, а потом я корректировала результат — убирала лишнее и дополняла своими деталями. Что получилось в резюме 1. Сразу указала все возможные варианты должности:  Руководитель тестирования, Head of QA, Team Lead QA, QA Lead. Это расширяет охват подходящих вакансий. 2. В каждой позиции указала конкретные результаты: Указала конкретные результаты с цифрами — они дают более четкое понимание масштаба работы и достижений 3. Написала не просто список инструментов, а показала, где и как применяла:\\xa0 4. Хронология четко показывает рост  — от руководителя группы тестирования до начальника отдела с расширением функций управления. Видно развитие карьеры и увеличение зоны ответственности. Дополнительно прошла несколько сертификаций на Госуслугах — по тестированию, Python, Docker. Это подтягивает профиль и показывает, что следишь за трендами. Правда, сертификаты действуют только год, но в резюме они создают хорошее впечатление. У меня получился структурированный опыт работы — формат, который лучше считывается как HR-системами, так и живыми рекрутерами. Как откликалась на вакансии Отбор вакансий Искала вакансии с названиями: «Team Lead QA», «Head of QA», «QA Lead», «Руководитель отдела тестирования», «Начальник отдела тестирования» с временным ограничением «за последние сутки». Принципиально смотрела только свежие вакансии. На старые вакансии уже подали заявки сотни человек, шансы минимальны. На что не откликалась: Вакансии с языками программирования Java, JavaScript, Go, C#. Я работаю на Python и не хотела распыляться на технологии, которые знаю поверхностно Офис пятидневка — это что-то из прошлого, доковидное время. Я искала гибридный формат — 2-3 дня в офисе достаточно для решения всех рабочих вопросов Оформление не по ТК Офис, до которого добираться больше двух часов (живу в ближнем Подмосковье) В прошлые поиски красным флагом были вопросы про стрессоустойчивость. Причем в контексте, что \"к вам будет приходить вице-президент кричать\". К счастью, сейчас такого не встречала. Сопроводительное письмо Писала сопроводительные письма к каждому отклику. В них указывала, какими конкретными компетенциями обладаю для данной вакансии. Многие HR даже отправляют чек-листы компетенций — нужно отметить, что умеешь, а что нет. По этим галочкам уже идет первичный отбор, потому что откликов на вакансии приходит очень много.\\xa0 Собеседования Первое, что бросилось в глаза — процесс найма стал гораздо дольше и сложнее. Раньше работодатели старались быстро закрыть вакансии, сейчас наоборот — могут позволить себе долго выбирать. Сейчас это рынок работодателя. Они ищут кандидатов с максимальным набором компетенций и не торопятся. Часто одна и та же вакансия появляется несколько месяцев подряд — работодатели смотрят кандидатов, но могут вообще никого не взять, если никто идеально не подходит. Раньше схема была простой: разговор с HR → собеседование с нанимающим менеджером. Сейчас этапов больше. HR собирает информацию о кандидате Передает данные нанимающему менеджеру для предварительного решения Отдельное техническое собеседование Финальное интервью с лицом, принимающим решение Раньше техническое интервью было частью встречи с нанимающим менеджером. Сейчас это отдельный этап. Подготовка к собеседованию В каждой компании спрашивают по-разному. Нет единого шаблона, но базовая структура остается: презентация опыта + технические вопросы + ситуационные кейсы. Обязательная часть — \"расскажите о себе\".  Обязательно нужно говорить в связке опыта работы и достижений компании — за что я отвечала конкретно, что делала, к каким результатом пришла. Здесь важно говорить не общие слова, а конкретные результаты с цифрами. Например: \"автоматизировала 50% регресса\". Персонализация под компанию критически важна.  В банках я делала акцент на банковском опыте. В IT-компаниях типа 2GIS рассказывала про весь технический бэкграунд за 10 лет — банковский опыт там не интересен. Подготовка к техническим интервью Я не готовлюсь ко всей базе сразу — смотрю на конкретную вакансию и повторяю именно те технологии, которые там указаны. Подстраиваюсь под требования и технологический стек компании. На подготовку к одному собеседованию уходит около часа. Чаще всего нужно освежить в памяти: Python:  типы данных, конструкции языка, принципы оптимизации кода Docker:  как собрать образ, запустить, остановить, внести изменения Linux:  базовые команды навигации по файловой системе Специфика компании  и ее технологического стека Я не веду детальную аналитику собеседований. Планировала начать, если поиск затянется, но оффер появился вовремя. Записывать конкретные вопросы тоже не стала. Они каждый раз разные, универсальной подготовки все равно не получается. Кейсы с собеседований Криптобиржа: все должны сидеть в офисе Здесь меня сразу пригласили к нанимающему менеджеру, минуя HR. Я рассказала о своем опыте — функциональное, автоматизированное, нагрузочное тестирование. Сказали, что опыт хороший. Потом сообщили главное условие: работать нужно строго из офиса, пять дней в неделю. Объяснили почему: прочитали в статье про индуса, который работал удаленно аж на 80 проектах одновременно и нанимал других людей делать работу за себя. Компания решила, что все должны работать в офисе, чтобы избежать таких ситуаций. И добавили, что сейчас рынок позволяет им быть избирательными — могут нанимать людей с условием работы в офисе, и хорошие специалисты все равно найдутся.\\xa0 Я посмотрела адрес. Из Подмосковья ехать было далеко, поэтому вежливо отказалась. Микросервисная компания: технический экзамен Должность — руководитель отдела автоматизации, но с требованием писать автотесты руками. После рассказа о моем опыте (UI и API автотесты на Python с Selenium, Request, PyTest) началось техническое собеседование. Вообще, для автоматизации тестирования глубокого знания Python не нужно. Но меня начали спрашивать именно углубленные вопросы по Python, типы данных, конструкции языка.\\xa0 Что ещё спрашивали: Анализ и оптимизация готового кода (это не каждый начинающий Python-разработчик осилит) Docker: команды для работы с контейнерами Linux: базовые команды файловой системы Поведенческие вопросы Один из вопросов запомнился: \"Что будете делать, если на общей встрече разработчик публично скажет, что автотесты не нужны?\" Здесь нет правильного ответа — кто как решает эти вопросы. Для кого-то это стресс, и он может начать кричать, доказывать. Я ответила, что поговорю с разработчиком отдельно, покажу, расскажу, зачем это нужно. Не при всех. Мы очень долго возились с вопросами — полтора часа не хватило даже на техническое собеседование. Должен был быть лайв-кодинг, но мы не успели. В итоге они выбрали другого кандидата — видимо, нужен был более сильный уровень именно программирования, а не управления. Банк Интервью с тремя женщинами с выключенными камерами. Задавали детальные вопросы о построении процессов: Как организовать тестирование, когда не хватает времени? Что делать, если команда маленькая, а задач много? Как выстраивать коммуникацию с бизнес-заказчиками? Как был устроен процесс тестирования в предыдущем банке? Я подробно рассказала про процессы и результаты, которых достигли. Понятно, без подробностей специфики банка — все, что разглашать нельзя, не разглашаем. Три человека без видео задают подробные вопросы о том, как все устроено. В голове промелькнула мысль, что меня пригласили перенять опыт и все.\\xa0 Сказали, что вернутся с обратной связью, и в итоге выбрали другого кандидата. Результат поиска Получила 2 оффера на позицию руководителя отдела тестирования. Вилку зарплаты и место, куда устроилась героиня, можно посмотреть в телеграм-канале  «Кухня известной IT-компании» . Важно найти сообщество\\xa0 Во время поиска зарегистрировалась в Сетке — соцсети от hh, аналог LinkedIn. Там много интересных постов и людей в похожей ситуации. Общение с теми, кто тоже ищет работу, очень помогает психологически. Понимание, что сложности переживают многие, снимает личную тревожность. Плюс можно обмениваться информацией о рынке. Были моменты, когда эмоции накатывали — это нормально.\\xa0 Стратегические выводы Что я для себя вывела из этой ситуации интересного: — Нужна подушка безопасности минимум на полгода. Это позволяет искать работу спокойно, без паники и необходимости хвататься за первый попавшийся вариант. — Важно найти сообщество людей в похожей ситуации. Взаимная поддержка помогает не только морально, но и информационно. — Рынок изменился кардинально. То, что раньше занимало две недели, теперь может растянуться на месяцы. Это новая норма. — Даже с солидным бэкграундом нужно поддерживать технические навыки и готовиться к каждому собеседованию индивидуально. — Времена, когда можно было найти работу за пару недель по одному звонку, прошли. Но при правильном подходе и терпении хорошие позиции все еще доступны. Дисклеймер: статья написана для блога  «Кухня известной IT-компании»  на основе интервью с руководителем отдела тестирования Лилией Иксановой Если вам понравилась эта история, вы можете прочитать и другие истории на телеграм-канале.', hub='тестирование веб-сервисов'), Page(id='944336', title='Как снимать на плёнку и не разочароваться в ней: снимаем бюджетно в 2025 году', content='Бывают разные зависимости у людей, разной степени вредности. Если зависимости от вредных привычек вредят здоровью, то зависимость от плёнки вредит лишь кошельку, — но и здесь можно найти варианты, как сэкономить и получать удовольствие от модного нынче увлечения, не разорившись и не разочаровавшись в нём. Дисклеймер: я точно не специалист в плёночной фотографии, но опыт некоторый имеется. Выбор камеры Вау, вы нашли на полке у ваших родителей (а то и вовсе — бабушки-дедушки) «Зенит» или другую советскую камеру? А может, это и вовсе\\xa0Praktika\\xa0из ГДР? Круто, здорово! А теперь осторожно возьмите это чудо советской инженерной мысли и поставьте на полочку. И даже не вздумайте снимать на него, пока не сделаете профилактику камеры у специалиста. Хотите получить положительный опыт от съёмки на плёнку? Не надо снимать на старую советскую камеру. Все они делались по устаревшим технологиям, а качество сборки было продиктовано именно что количеством, а не качеством (спасибо плановой экономике). Более поздние «Зениты», выпущенные в начале девяностых, были сделаны из дешёвого пластика. Да чего уж там — эти камеры Красногорский завод штамповал аж в самом начале нулевых, когда во всём мире уже начали постепенно переходить на «цифру». У таких камер было вообще всё пластиковое: сами «тушки», объективы (справедливости ради,\\xa0они выдавали неплохую картинку… ну, по меркам восьмидесятых годов, наверное) — у последних так и не появилось никакого автофокуса, а поворачивается\\xa0фокусировочное\\xa0кольцо максимально мерзко, рывками. Зенит 312м: скрипучий, очень дешёвый по ощущениям, а экспозамер такой, что лучше пользоваться замером через приложение в смартфоне. И да, это чудо вышло в 1999 году. «Практика», которая была из ГДР, тоже не самая надёжная камера.\\xa0ГДР не ФРГ, и качество точно отличалось от\\xa0ФРГшных\\xa0«Леек». Шторки хоть и\\xa0ламелевые, но заклинить могут, да и в целом механизм не сильно ушёл от советских камер тех лет. Разве что были короткие выдержки, которых в советских, а затем и российских «Зенитах» так и не появилось. Ну и зеркало лупит у «Практик» довольно сильно — не очень это приятно. Возникает вопрос: а что же взять тогда? Сразу спойлер: «билет» в плёночную фотографию стоит примерно десять тысяч рублей (статья пишется в августе 2025). Нет, вы, конечно, можете взять самую простенькую «мыльницу», но разве так интересно? Из самого очевидного —\\xa0Pentax\\xa0Spotmatic. Максимально простые, но недорогие камеры. Объективы подходят любые с резьбой\\xa0M42 — той же, что у\\xa0ГДРовских\\xa0«Практик» и советско-российских «Зенитов». За ремонт и обслуживание берётся любой, кто работает со старыми плёночными камерами. Средняя цена по рынку — около\\xa05000\\xa0рублей за саму камеру. Объектив вы без проблем найдёте на любой барахолке. Не берите самые дешёвые компактные камеры. «Мыльницы», у которых нет автофокуса — пустая трата денег. Найдите хотя бы\\xa0Samsung\\xa0Fino 30 SE: относительно недорогая и распространённая камера, у которой есть какой-никакой автофокус и относительно светосильный (в сравнении с другими «мыльницами») объектив с диафрагмой\\xa0f/4.5, плюс у неё огромный видоискатель. Но опять же, без слова «относительно» говорить про такие дешёвые камеры просто невозможно. Советовать старые японские компакты очень хотелось бы, но тоже не буду: они слишком специфичны в использовании, профилактику, а то и ремонт их никто не проводил (и не каждый возьмётся, в случае чего). Можете рискнуть, конечно — если хотите быть самым модным в тусовке. Хотите компактности и простоты в одном флаконе (тут, скорее, будет уместнее сказать «флакончике») — найдите\\xa0Olimpus\\xa0серии µ [mju]. Всего было три поколения, но вот самой топовой считается µ[mju:]-II, выпущенная в 1997 году. ОЧЕНЬ маленькая, с\\xa035мм-объективом\\xa0со светосилой\\xa0f/2.8 и очень хорошим автофокусом. Главное — не брать «мьюшку» с зумом, там оптика тёмная: на самом дальнем фокусном расстоянии диафрагма доходит аж до\\xa0f/9, что вообще не круто (а иначе никак, камеры и так компактные). Уж с такой камерой вы будете и\\xa0стильным-модным-молодёжным, и снимки хорошие получите. Вам мало 36 кадров? Всегда есть возможность подыскать полукадровую камеру! Из банального — «Чайка-2». Совсем простая, с не очень хорошим, и далеко не самым удобным, но относительно светосильным объективом. Стоят такие камеры примерно по 1500 рублей на Авито, но их нужно проверять. Никакого экспонометра в них нет. Но лучше, конечно, поискать\\xa0ФЭД-Микрон: это копия японской\\xa0Konica\\xa0Eye, объектив куда более светосильный у него. Самый же лучший вариант — поискать Canon Demi EE17 или\\xa0Olympus\\xa0Pen\\xa0F. Demi EE17 — шкальная камера, очень стильная и полностью механическая, а главное — компактная.\\xa0Pen\\xa0F\\xa0— зеркалка. Маленькая, со сменными объективами. Обе — шестидесятых годов, но по сей день очень красиво и модно смотрятся. На вторичке их можно найти за\\xa015-20\\xa0тысяч рублей. И пожалуйста, не надо брать современные мыльницы от\\xa0Kodak. Есть они и\\xa0полнокадрвые, и\\xa0полукадрвые. Но они вообще не стоят своих денег, а сделаны — максимально дёшево. Средний формат? Забудьте.\\xa0Нет, если\\xa0вы всё же хотите с ним побаловаться, найдите Любитель 166. Простая коробочка из пластика, максимально дешёвая конструкция. Да, у него может быть сбит механизм фокусировки — поэтому лучше сразу брать у людей, которые продают проверенные камеры. При должном уровне\\xa0извращённости,\\xa0можно даже отснять и 35 мм плёнку, заклеив смотровое окошко изолентой плотнее. Впрочем, про плёночные изощрения при небольшом бюджете будет сказано отдельным абзацем. «Любитель» вам нужен будет исключительно для того, чтобы понять, что средний формат — это по большей части дорого и бессмысленно, если вы не сами плёнки проявляете. Мой экземпляр. В нём отснял 35мм плёнку, вышло интересно! Плёнка: Свема КН-2 (снята как 20 исо) Золотой серединой для многих станут\\xa0просьюмерские\\xa0зеркалки\\xa0Canon\\xa0и\\xa0Nikon. И как обладатель\\xa0Nikon\\xa0F80, могу с уверенностью её советовать: это хорошо собранная, увесистая камера,\\xa0которая\\xa0имеет фичи не только необходимые каждому, но и дополнительные плюшки,\\xa0которые\\xa0при повседневной съёмке вы бы вряд ли стали использовать. Единственное — надо быть готовым к тому, что\\xa0замок\\xa0задней крышки будет сломан, и в\\xa0идеале\\xa0брать камеру с батарейным\\xa0блоком: с\\xa0ним\\xa0комфортнее. За\\xa0F80 без объектива могут просить примерно\\xa05-6\\xa0тысяч, чаще — немного больше. Объектив можно взять либо современный на 50 мм, либо из восьмидесятых. Я же смог выцепить автофокусный зум\\xa035-105\\xa0мм с диафрагмой\\xa0f/3.5-4.5 аж восьмидесятых годов. Обошёлся он мне в\\xa03000\\xa0рублей, и картинка с ним получается приятной. Если же вас не смущает мануальная фокусировка и отсутствие\\xa0экспозамера\\xa0при работе с мануальными объективами (да,\\xa0Nikon\\xa0— просто кладезь подобных «нюансов»,\\xa0что\\xa0сейчас,\\xa0что\\xa0в былые времена), то могу смело посоветовать Гелиос МС 81н. У него родной никоновский байонет. Вот этот красавчик обошёлся мне в смешные 5000 рублей Выбор плёнки Цены на плёнку всё так же высоки,\\xa0Kodak\\xa0на грани закрытия — как быть-то? Самый дешёвый и сердитый вариант — снимать на чёрно-белую плёнку. Намотка какой-нибудь\\xa0Тасмы-42 на 36 кадров обойдётся рублей в 500,\\xa0и\\xa0как говорят\\xa0в плёночном комьюнити,\\xa0ISO\\xa0у неё столько, сколько захочешь. Разные фотолаборатории продают её с разным номиналом: кто-то на 200\\xa0iso\\xa0(это близко к её номинальному значению, примерно 125), кто-то на 400, а кто-то — и вовсе как 800. При помощи\\xa0пуш-процесса\\xa0при проявке можно вообще снимать как 1200\\xa0iso\\xa0— но это уже извращение. В идеале я бы советовал брать\\xa0Ilford\\xa0Pan\\xa0400 (либо\\xa0Kentmere\\xa0Pan\\xa0400 — это то же самое): это хорошо зарекомендовавшая себя плёнка, которая стоит недорого, а результат получается хорошим, и пушить можно до 800\\xa0iso. Плёнка: Ilford Pan 400  Камера: Pentax MZ-M  Объектив: RMC Tokina 35-105mm f/3.5-4 Другой довольно популярной плёнкой в наших краях стала\\xa0Lucky\\xa0SHD\\xa0400. Она родом из Китая, но вот 400\\xa0iso\\xa0там нет: лучший результат у меня получился при съёмке как 200\\xa0iso. Но\\xa0зернище\\xa0просто ОГРОМНОЕ, им будто поцарапаться можно, очень специфичная плёнка, не прощающая ошибок экспонирования. Зато плюсы есть: катушки у неё многоразовые, можно использовать для плёночных экспериментов и самостоятельных намоток. А по цене — это самая дешёвая заводская намотка: при должном везении можно купить одну катушку рублей за 300. Каждая такая катушка обошлась в 300 рублей Камера: Nikon F80 Обьектив:  Nikkor AF MK1 35-105mm f/3.5-4.5 Плёнка: Lucky SHD 400 (как 200 исо) Хотите\\xa0вайбовых\\xa0снимков за небольшую стоимость? Ищите старую просрочку. Как-то раз я чисто случайно нашёл на популярном маркетплейсе где-то по 500 рублей за катушку среднеформатную Agfa Color XR 200, сроком годности аж до 1986 года. Одну отснял как 8\\xa0исо\\xa0— получилось ОЧЕНЬ необычно. Остальные отдал товарищу по себестоимости вместе с камерой (в какой-то момент захотелось полностью уйти от среднего формата, и Киев-60 продал). В среднем, адекватная цена за хорошую цветную просрочку сейчас около 500 рублей. Даже\\xa0Kodak\\xa0Vision\\xa02, который всё ещё иногда всплывает, можно выцепить за такую стоимость. Ну а ЧБ так и вовсе чуть ли не вдвое дешевле может стоить. Вот совсем недавно мне предложили размотать\\xa0Свему\\xa0КН-3, с остаточным\\xa0исо\\xa0где-то в 50 единиц. Всего 250 рублей за катушку на 27 кадров из-за плотности плёнки больше не намотать, увы)\\xa0— ну приятная ведь цена! Главное — поискать плёночные барахолки в\\xa0Телеграме, например. И помните, что 10 лет — минус один стоп в\\xa0экспозиции: например, если\\xa0плёнка\\xa0на 200\\xa0исо\\xa0выпущена в 2015 году, снимать\\xa0её\\xa0в 2025 году лучше, как 100\\xa0исо. У чёрно-белых плёнок чувствительность с возрастом уходит не так сильно, но надо экспериментировать. Камера: Nikon F80 Объектив: Гелиос мс 81н  Плёнка: Тасма тип 42л (как 800 исо) Намотка намотке рознь Видите на\\xa0всем\\xa0известной барахолке в продаже\\xa0намотку\\xa0от частника, да ещё и за очень привлекательную\\xa0цену?\\xa0Стоит\\xa0задуматься, какого\\xa0она\\xa0качества и не обманывает ли в чём-то продавец. Если кто-то не знает, что такое «намотка» — то это размотанная в кассеты плёнка с большой бобины: вы точно видели такие в кино,\\xa0например —\\xa0большие, круглые, железные. И да, цветную киноплёнку разматывают именно с таких бобин. Чёрно-белые же плёнки могут вполне официально продаваться в упаковках для самостоятельной размотки: скажем,\\xa0Fomapan,\\xa0Shanghai, да и та же\\xa0Lucky\\xa0(последняя, правда, продаётся в коробке из картона) — из большого рулона на 30 метров получается около 19 катушек по 36 кадров. А ещё можно заказать отечественную «Тасму» от производителя: есть совместные закупки, а есть возможность и напрямую взять с завода. Цены, правда, надо уточнять у представителей завода — они могут меняться. Камера: Pentax MZ-M  Объектив: RMC Tokina 35-105mm f/3.5-4  Плёнка: Kodak Portra 400NC (как 50 исо) Камера: Fuji TW-300 II  Плёнка: Kodak Portra 400nc (просрочка примерно 2003 года, снято как 50 исо) Намотки — это не плохо. Главное — понимать, что брать их стоит у проверенных людей.\\xa0Я\\xa0сам пару раз брал у незнакомых людей плохие намотки: однажды это была\\xa0Свема\\xa0КН-2, киношная плёнка, которую вообще по-хорошему надо снимать как 20\\xa0исо, не выше — но дед, который мне целую коробочку этих намоток\\xa0впарил, сказал,\\xa0что\\xa0там и 36 кадров есть (как оказалось, кадров в каждой катушке разное: и 30, и 32, и 36 иногда), и 50\\xa0исо\\xa0минимум\\xa0(даже утверждал,\\xa0что\\xa0можно в мыльнице снимать,\\xa0что\\xa0я даже и сделал однажды (получилось плохо, конечно же). А ещё брал Fuji Eterna 400T — продавали, как 36 кадров, а оказалось, что там их всего 24. Зато дёшево… Зато однажды удалось урвать десяток катушек Kodak Portra 400NC, чуть ли не по 300 рублей за штуку. Просрочка довольно давняя, но всё ещё способна давать приятные кадры! Камера: Kodak KB10  Плёнка: Lucky SHD 400 Проявка и скан А вот\\xa0тут\\xa0у нас дилемма: либо относим плёнку в лабораторию, где рублей за 500 всё сделают качественно и довольно быстро, либо самому этим заняться. Правда, хороший сканер будет стоить в районе\\xa020000\\xa0рублей точно, хороший бачок типа\\xa0Paterson\\xa0— ещё где-то\\xa03-5\\xa0тысяч. А ещё градусник, щипцы, химия — полный набор по проявке и скану обойдётся в круглую сумму. Кто-то скажет, что можно плёнку переснять — но для этого нужен нормальный фотоаппарат с хорошим\\xa0макро-объективом. Так что та же самая стоимость получится. Бачок, на первое время, можно найти советский — главное,\\xa0двухспиральный, с ним намного проще работать.\\xa0Главное\\xa0помнить, что тонкие плёнки в него лучше не засовывать. Но задумайтесь: а как часто вы снимаете, и как много свободного времени у вас на самостоятельную проявку-скан есть? Порой проще и выгоднее просто заплатить 500 рублей в месяц, чем тратить деньги на всё это оборудование. А если ещё и учесть то, что в лабораториях могут быть схемы с каждой десятой бесплатной проявкой — то вы так можете даже немного сэкономить. Собственно, такая вот упаковка для самостоятельной намотки А что в итоге-то? — Не скупитесь на первую камеру. «Зениты» может\\xa0и выглядят\\xa0стильно-модно-молодёжно, но эти камеры нуждаются в профилактике, но даже с ней опыт использования будет не самым приятным, в сравнении с японскими зеркалками. Мыльницы без автофокуса — отвратительны. Даже если это современный\\xa0Kodak\\xa0в ярких цветах. Средний формат — не бюджетен, но побаловаться пару раз можно. И вообще:\\xa0хотите максимально бюджетно снимать\\xa0на плёнку — возьмите полукадровую камеру. Всё равно большинство из вас не будет печатать большие снимки, ограничиваясь стандартными 10х15, и полукадра для таких размеров хватит. — Недорогая просрочка — ваш друг.\\xa0Главное\\xa0обращать внимания на сроки годности и не снимать по номиналу. — Если снимать планируете немного — ограничьтесь проявкой и сканами в лаборатории. Там вам всё сделают хорошо и быстро. © 2025 ООО «МТ ФИНАНС»', hub='фототехника'), Page(id='945364', title='Кодинг в Роблоксе в 14 лет: все про обучение', content='Мы в  Pixel  учим детей и подростков писать код на различных языках и ставим акцент на практике. В случае с Роблоксом речь о Lua и движке Roblox Studio: 14-летние ребята могут изучить первый через разработку игр на втором. А еще мы предусмотрели самостоятельную  образовательную траекторию , в которую, помимо остального, заложены уроки трехмерного моделирования.\\xa0 Сегодня хотим рассказать о заявленном направлении. Это обзорная статья с элементами рекламы. Если тема обучения ребенка программированию и моделированию в Роблоксе в 14 лет не интересует вас, материал не принесет пользы. О траектории «Разработка игр в Roblox» для младших школьников и подростков: сводные сведения Траектория поможет ребенку освоить: Трехмерное моделирование; Разработку игр; Программирование на языке Lua на движке Roblox Studio. Когда начать:  траектория подойдет младшим школьникам и подросткам от 9 до 14 лет. Сколько стоит:  цена одного занятия составляет от 600 рублей. В чем удастся разобраться:  в конструировании игровых миров на Roblox Studio, языке программирования Lua для написания скриптов, а также в создании 3Д-моделей, логике разработки и кодинга. Структура:  траектория объединяет два самостоятельных курса  3D-моделирования  и  создания игр . Когда уроки программирования в Roblox подойдут ребенку Учиться писать код и создавать модели на движке Studio от Роблокса в 14 лет можно и нужно, если ребенок: Увлекается компьютерными играми, хочет научиться создавать их с нуля; Интересуется IT, проявляет увлеченность одним из соответствующих направлений; Стремится к творческому самовыражению; Начинает задумываться о будущем обучении и профессии, хочет связать жизнь с информационными технологиями. Преимущества траектории для детей и подростков Запись в онлайн-школу программирования для детей на уроки Роблокса в рамках обозначенной траектории поможет получить, помимо остального, следующие преимущества: Именной сертификат после учебы . Когда ребенок защитит индивидуальный проект, мы подготовим и выдадим документ, подтверждающий личные успехи младшего школьника или подростка; Вычет . Наша онлайн-школа программирования для детей работает по лицензии, поэтому клиентам доступен налоговый вычет. Номер документа: Л035-01255-50/00822552. Лицензирующий орган: Министерство образования Московской области; Выгодная цена . Один урок программирования в Roblox в рамках курсов стоит от 800 рублей, в случае с траекторией – 600; Комплексное обучение . Отметили, что образовательная траектория объединяет два курса и основана на теории и практике программирования, моделирования и создания игр. А еще мы гарантируем геймификацию: успехи в учебе поощряются баллами, которые в дальнейшем можно обменять на ценные призы. Удачно ли сочетание моделирования и написания кода на уроках программирования в Roblox Считаем, что да, ведь одно тесно связано с другим.\\xa0 Движок Roblox Studio в данном смысле – комплексный инструмент: на нем можно создавать трехмерные модели персонажей и предметов, полноценные карты и даже игры. Для управления всеми этими вещами необходимо писать скрипты на отмеченном языке – Lua. Плюс последнего – легкость восприятия: «Луа» предназначен для пользователей, которые не сильны в программировании. Это выражается, скажем, в относительной простоте: дети и подростки успешно справляются с учебой даже в 9–10 лет, а в 14 – тем более. Синтаксис Lua несколько напоминает поздние языки, подобные Pascal. Писать текст можно свободно, команды разделяются пробельными символами. Вместе с тем базовый алфавит – английский, поэтому если в школе ребенок уже приступил к его изучению, траектория дастся без особых сложностей. Еще раз отметим, что на уроках моделирования и программирования в Роблоксе в 14 лет или ином возрасте дети осваивают не просто сухой код, а создание моделей и полноценных игр. Это вовлекает в обучение, делает его более интересным и вместе с тем успешным для каждого ребенка, заинтересованного в получении результата. Так, траектория содержательна и выгодна. Если ваш ребенок увлекается компьютерными играми и интересуется IT, приглашаем записаться к нам на уроки. FAQ Как часто проводятся уроки программирования в Roblox? От двух раз в неделю. В любом случае мы постараемся подстроить обучение под текущий уровень подготовки ребенка, его способности и интересы. Подойдет ли Роблокс в 14 лет? Как образовательный инструмент – вполне. Только хотим заострить внимание на том, что корректнее говорить о движке Studio, а не об игровой онлайн-платформе Roblox. Что еще вы преподаете в онлайн-школе программирования для детей кроме Роблокса? Мы учим детей программировать, создавать игры и сайты, работать с моделями и графикой. Узнать больше о направлениях, реализуемых нами, вы можете на  сайте .', hub='учебный процесс в it'), Page(id='944008', title='Тестирование CLI-приложений без костылей: единый фреймворк вместо десятка утилит', content='Готовые утилиты в области систем хранения данных зачастую не обеспечивают полного покрытия тестовых сценариев или ориентированы только на специфические задачи. Проверить массив из десятков или сотен дисков, учесть разные конфигурации железа и операционных систем, автоматизировать все до одного клика — такие задачи стандартные инструменты просто не решают. Перед инженерами встает выбор: продолжать вручную собирать «конструкторы» из разрозненных утилит или создать собственный инструмент. Так у нас появился кастомный фреймворк для тестирования CLI-приложений, который позволяет проводить различные виды тестирования, обеспечивает работу с оборудованием и предоставляет понятную отчетность в одном решении. Меня зовут Артём Хюппенен, я инженер по тестированию  в YADRO . Четыре года я занимаюсь разработкой инструментов и фреймворков для тестирования систем хранения данных. Свой фреймворк мы сделали из-за отсутствия решений под наши задачи. В статье я поделюсь техническими деталями и примерами из практики: как мы выбирали технологии, что оказалось удачным и как теперь любой член команды может быстро автоматизировать тесты для сложных CLI-приложений. В конце статьи — ссылка на репозиторий, чтобы посмотреть архитектуру на практике.  18 сентября в Санкт-Петербурге я буду выступать на QA-митапе YADRO. Обсудим целостность данных и на реальном кейсе разберем создание интеграционных тестов для сложных распределенных систем. Можно присоединиться как офлайн, так и онлайн, но нужно\\xa0 зарегистрироваться . Повторим основы С системами хранения данных мы сталкиваемся почти каждый день, даже не задумываясь об этом. Фотографии в облаке, сообщения в мессенджерах, огромные базы данных соцсетей, потоковые сервисы, интернет-провайдеры, которые где-то должны хранить весь трафик, — все это работает благодаря системам хранения. В основе любой СХД лежат накопители: жесткие диски, CD или SSD. Для того чтобы обеспечить скорость и надежность, их объединяют в RAID-массивы — логические устройства, построенные на основе технологии RAID. Если коротко, RAID — это технология, позволяющая объединить физические диски в одно логическое устройство и организовать хранение данных на нем так, чтобы достичь определенного баланса между скоростью, надежностью и эффективностью использования места. Что такое T-RAID и как он устроен в линейке СХД TATLIN мы уже  писали .\\xa0 Существует множество уровней RAID, но для примера мы возьмем такие: RAID 0  — объединяет диски в один большой. Это дает высокую скорость, потому что данные пишутся и читаются параллельно, но надежности тут нет совсем: сломается один диск — потеряются все данные. RAID 1  — дублирует данные на два диска. Если один выйдет из строя, второй продолжит работу, но при этом половина дискового пространства уходит под копию. RAID 5  и выше — более сложные схемы, где диски обмениваются информацией о соседях. Если один диск ломается, данные можно восстановить. Скорость при этом остается высокой, потому что запись идет на несколько накопителей одновременно. RAID — основа нашей работы. Тестируя СХД, мы проверяем не только сохранность данных, но и реакцию системы на сбои: если один диск выходит из строя — данные остаются целыми и доступны для чтения. Если падает производительность — нужно искать причину.  Главная проблема: большинство доступных инструментов для тестирования ориентированы на узкие задачи и не подходят для проведения комплексных нагрузочных сценариев — с моделированием отказов, нестандартных ситуаций и других стресс-кейсов. Именно это стало отправной точкой для идеи создать собственный фреймворк. Конструктор из утилит: рабочий, но неудобный путь Когда мы только начали думать о том, как тестировать наши СХД, первое, что пришло в голову, — взять готовые утилиты с рынка. Их немало, и многие из них знакомы даже людям, которые далеки от тестирования. CrystalDiskMark  — простая утилита с понятным интерфейсом: запустил, нажал кнопку и сразу видишь красивые цифры скорости чтения и записи. Удобно и наглядно, но хорошо работает для одного-двух дисков на домашнем ПК. Когда же речь идет о массиве из десятков накопителей и требуется автоматизация тестов, возможностей CrystalDiskMark конечно же не хватает.  Когда речь идет о большой системе с десятками накопителей, где нужно измерить производительность целиком, возможностей CrystalDiskMark уже недостаточно. Результаты теста CrystalDiskMark для твердотельного накопителя Samsung Есть и более «серьезные» варианты —  CLI-утилиты  вроде  FIO  или  VDBench . Они работают в терминале, поддерживают множество параметров и позволяют тонко настраивать нагрузочные тесты. Статистика axboe/fio Я уверен, что многие инженеры, которые хоть раз тестировали диски в Linux, с FIO сталкивались. Мы его тоже используем, и он прекрасно подходит для генерации нагрузки. Подробнее про работу FIO —  в статье .  Еще один важный инструмент в нашем стеке —  pgbench . Эта утилита создает нагрузку на PostgreSQL-базы данных, развернутые на тестируемых СХД, что позволяет оценить влияние дисковой подсистемы на работу реальных приложений. Ее сильные стороны — простота моделирования типичных сценариев — например, банковских транзакций и гибкость в настройке интенсивности запросов. Благодаря этому pgbench помогает выявить «узкие места» при интеграции СХД с enterprise-приложениями. Однако у метода есть ограничение: тестирование ведется на уровне СУБД, а не на уровне блоков, поэтому результаты зависят не только от скорости дисков, но и от конфигурации самой базы данных. Для анализа «голой» производительности накопителей без накладных расходов СУБД этот инструмент не подходит. Но у всех этих инструментов есть одно общее ограничение: они не решают всю задачу целиком. В итоге мы вручную комбинировали несколько утилит, писали к ним обвязку, подгоняли под конкретный случай — и каждый раз заново собирали «конструктор» из команд. Это работало, но занимало массу времени и сил. Почему готовых инструментов было недостаточно Решение создать свой инструмент возникло из потребности. У нас специфические сценарии тестирования, которые не покрывал ни один готовый инструмент. Например,  у разных заказчиков — разные конфигурации СХД : разное «железо», разные Linux дистрибутивы и версии ядер. Иногда система даже ведет себя по-разному в зависимости от типа дисков или конкретных драйверов. В таких условиях нужно, чтобы инструмент тестирования мог быстро подстраиваться под любую среду. Вторая проблема —  интеграция с оборудованием . CLI-утилиты вроде FIO и VDBench генерируют нагрузку на уровне блочных операций, но не предоставляют встроенных средств для мониторинга или управления СХД — например, проверки состояния дисков. Это вынуждает вручную «склеивать» тестовую нагрузку с внешними утилитами — запускать параллельные процессы, синхронизировать логи и интерпретировать данные из разных источников. Это не только неудобно, но и увеличивает риск ошибок: легко запутаться, где закончился один инструмент и начался другой. Третья задача —  отчетность . Для инженеров лог с кучей цифр — это нормально. Но для менеджера или заказчика нужен отчет с графиками, понятными выводами и итоговыми оценками. Готовые утилиты этим не занимались: максимум, что они делают, — выводят результаты в консоль или сохраняют их в файл. Еще одна особенность —  глубина логирования . Иногда баг прячется настолько глубоко, что нужно смотреть не только результат теста, но и весь путь его выполнения: команды, параметры, промежуточные ответы системы. Обычные инструменты дают либо слишком много «мусора» в логах, либо слишком мало деталей. И финальный аккорд —  автоматизация . Мы хотели, чтобы в идеале запуск всех регрессионных тестов требовал одного нажатия кнопки.\\xa0 В итоге мы пришли к выводу: нам нужен  единый инструмент , который: Умеет взаимодействовать с CLI-приложениями и самим оборудованием. Может управлять нагрузочными тестами и проверками целостности данных. Поддерживает гибкую настройку под разные конфигурации. Генерирует понятные и детализированные отчеты. Легко интегрируется в наши процессы автоматизации. Так и родилась идея  кастомного фреймворка , который объединит все это и станет универсальной платформой для тестирования наших систем хранения данных. 3 PM: Python, Paramiko, PyTest и Mapper Осознав, что готового решения нет, мы сосредоточились на выборе инструментов, которые подходят команде и позволяют быстро развивать проект. Мы выбрали  Python  и вот почему:\\xa0 Низкий порог входа — даже новичку проще освоить базовые конструкции Python. Популярность среди тестировщиков — язык уже стал «дефолтным» для автоматизации тестов, вокруг него большое сообщество, множество библиотек и плагинов. Для удаленного управления тестируемыми системами мы использовали  Paramiko  — проверенную библиотеку для работы с SSH в Python. Поскольку большинство СХД управляются через терминал, этот инструмент оказался идеальным: он позволил реализовать удаленное выполнение команд и получать результаты прямо в рамках фреймворка. Для организации и запуска тестов —  PyTest . Он прост в использовании, при этом позволяет строить сложную архитектуру тестов: параметризацию, фикстуры, хуки. Огромный плюс в том, что для PyTest уже есть тысячи плагинов, которые можно интегрировать без изобретения велосипеда. Подробнее о Pytest-плагинах —  в статье .\\xa0 В основе фреймворка —  mapper , абстракция над CLI-командами, которая предоставляет естественный Python-интерфейс для работы с CLI операциями СХД. Вместо ручного конструирования терминальных команд мы оперируем методами, структурно повторяющими синтаксис CLI, но с преимуществами языка программирования: типизацией, валидацией параметров и интеграцией в кодовую базу. Например, вместо вызова в терминале: eracli raid create --name my_new_raid --level 0 --drives /dev/sda /dev/sdb С помощью mapper эта же операция в автотестах будет выглядеть так: eracli.raid.create(name=\\'my_new_raid\\', level=0, drives=2) Ключевая идея: mapper не «упрощает» CLI-команды, а зеркалит их логику в виде читаемого и поддерживаемого кода. Это позволяет инженерам писать тесты на Python, сохраняя эмулирование привычного «терминального ввода команд». Что еще должно быть во фреймворке Есть еще несколько моментов, которые мы предусмотрели в фреймворке.\\xa0 Система логирования с понятными и структурированными записями Для тестировщика логи — это основной инструмент: чем они понятнее и детальнее, тем проще выявлять ошибки и разбираться в том, что происходит в системе. Мы выделили два главных принципа: Понятность и структурированность. Логи должны быть написаны простым, читаемым языком. Важно, чтобы в них можно было быстро разобраться, а не сталкиваться с «полотном текста», как в Java-трейсах. Достаточность без избыточности. В логах должна оставаться только полезная информация. Лишний «мусор» лучше фильтровать, чтобы не перегружать отчет и ускорить диагностику проблем. Интерфейс, отвечающий за удаленное подключение Мы работаем не с локальными машинами, а с полноценными системами хранения данных, которые размещены где-то в серверных. Чтобы взаимодействовать с ними, нужен инструмент, позволяющий подключаться к удаленной машине по ее IP-адресу. И с этой задачей помогает библиотека Paramiko, в которой уже реализованы все необходимые нам методы. Нам только нужно на ее основе реализовать свой класс-интерфейс для взаимодействия с удаленными нодами. Основная задача интерфейса — уметь подключаться к удаленной машине по SSH и выполнять команды. Для этого достаточно задать базовые параметры: IP-адрес, логин, пароль и, при необходимости, порт. Главным элементом здесь является функция  exec  (сокращение от execute). Она подключается к удаленному серверу, выполняет переданную команду и возвращает результат: успешное выполнение, ошибки, а также дополнительную информацию, с которой можно работать дальше. Как выглядит реализация: class SshConnect:\\n    def __init__(self, ip_addr: str, user: str, password: str, port: int = 22):\\n        self.ip_addr = ip_addr\\n        self.user = user\\n        self.password = password\\n        self.port = port\\n        self.__client = paramiko.SSHClient()\\n        self.__setup_client()\\n\\n    def __setup_client(self): …\\n    def exec(self, cmd: str) -> BashResult: …\\n Фактически Paramiko уже реализует метод  exec_command , поэтому писать свою реализацию с нуля не нужно. Все, что требуется, — передать команду в метод: он отправит ее на сервер, выполнит, вернет вывод и код завершения. В Linux код 0 означает успешное выполнение, 1 — ошибку (аналогично тому, как в API принято 200 и 500). Для целей логирования это особенно важно: можно зафиксировать саму команду, ее вывод, время выполнения и результат. Например:  def exec(self, cmd: str) -> BashResult:\\n        stdin, stdout, stderr = self.__client.exec_command(cmd)\\n        cmd_output = stdout.read().decode(\\'utf-8\\')\\n        exit_status = stdout.channel.recv_exit_status()\\n        return BashResult(cmd, cmd_output, exit_status, self.ip_addr) Всего несколько строк кода позволяют покрыть до 80% задач логирования и взаимодействия с системой:  def exec(self, cmd: str) -> BashResult:\\n        logger.info(\"[%s] cmd: [%s]\", self.ip_addr, cmd)\\n        start_time = time.time()\\n\\n        stdin, stdout, stderr = self.__client.exec_command(cmd)\\n        cmd_output = stdout.read().decode(\\'utf-8\\')\\n        exit_status = stdout.channel.recv_exit_status()\\n\\n        logger.info(f\\'cmd exit code: {exit_status}. Run time: \\'\\n                    f\\'{time.time() - start_time:.2f} s \\\\n\\\\n\\'\\n                    f\\'{cmd_output.decode(\"utf-8\")}\\')\\n\\n        return BashResult(cmd, cmd_output, exit_status, self.ip_addr)\\n Посмотрим на результаты. В первой строке лога фиксируется IP-адрес машины и сама выполненная команда. 17:53:35 [INFO] [172.16.23.122] cmd: [ls –l /root/]\\n17:53:36 [INFO] cmd exit code: 0. Run time: 0.12 s \\n\\ntotal 16\\n-rw-r--r-- 1 root root  395 Nov 16  2022 lic.txt\\ndrwxr-xr-x 2 root root 4096 Mar 18 15:02 mounted\\ndrwx------ 3 root root 4096 Nov 10  2022 snap\\n Во второй — результат ее выполнения и время работы. Далее выводится полный результат выполнения (output), аналогичный тому, что мы получили бы, запустив команду вручную в терминале. Например, при вводе  ls -l  в каталоге root мы увидим список файлов, тот же самый список появится и в логах. Так, буквально восемь строк кода решают большую часть задач по логированию. И все это благодаря одной библиотеке, которая уже реализовала за нас почти весь необходимый функционал. Mapper для работы с командами Linux терминала Он позволяет выполнять самые разные действия: создать каталог, перезагрузить систему, вывести содержимое логов или, например, использовать стандартные команды вроде  cat  или  ls : class AbstractLinuxMapper:\\n    …\\n    def exec(self, *args) -> BashResult: …\\n    def mkdir(self, *args)  -> BashResult: …\\n    def reboot(self) -> None: …\\n    …\\n    def your_func(self, *args): …\\n В Linux-mapper можно собрать любой набор команд, которые применяются в терминале при тестировании приложения или при работе со сторонними утилитами. Mapper для работы с разрабатываемым приложением Кроме работы с терминальными командами, во фреймворке нужен интерфейс для взаимодействия с самим приложением, которое разрабатывают наши инженеры и которое мы тестируем. CLI-интерфейс для управления СХД, реализован в виде утилиты eracli. Он позволяет инженерам управлять RAID-массивами, системными настройками и т. д. При помощи mapper мы зеркалируем этот интерфейс в наш фреймворк: class EracliMapper:\\n    @property\\n    def raid(self) -> EracliRaid:\\n        …\\n        return EracliRaid(*args)\\n В коде у метода есть подметоды —  create ,  destroy ,  show  и другие:  class EracliRaid():\\n    def create(*args): …\\n    def destroy(*args): …\\n    def show(*args): … Благодаря такому подходу формируется удобный и понятный интерфейс: есть родительский класс с методом raid, а у него — набор подметодов для управления рейдами: eracli.raid.create(name=\\'my_new_raid’, level=0, drives=2) На этом возможности фреймворка не ограничиваются. В него можно добавить любые дополнительные утилиты, которые необходимы для тестирования. Это могут быть как сторонние библиотеки, так и отдельные приложения для нагрузочного тестирования — например,  FIO  или  VDBench , которые позволяют создавать нагрузку на систему и проверять целостность данных. По сути, в фреймворк можно включить все, что нужно для работы, превратив его в максимально удобный и универсальный инструмент. Такой подход позволяет тестировать любое CLI подобное приложение. Пишем тесты После завершения базовой архитектуры фреймворка мы задумались, как упростить процесс написания тестов. Важно было, чтобы с этой задачей справлялись не только разработчики, но и ручные тестировщики без опыта программирования. Простой тест-кейс Для начала набросаем тест-кейс «на бумаге»: Создать рейд массив. Проверить, что массив создался и отображается в системе. Выполнить штатную перезагрузку сервера. После перезагрузки проверить, проверить что массив не удалился и отображается в системе. Во фреймворке это превращается в довольно понятный любому тестировщику код: def test_create_raid_():\\n    eracli.raid.create(name=‘test_raid’, level=5, drives=4)\\n    assert eracli.raid.show() Для тестировщика это читается почти как обычная инструкция: «создай RAID и проверь, что он есть». Идем дальше: действия с системой Теперь представим, что мы хотим проверить, что RAID остается в рабочем состоянии после перезагрузки системы. В CLI это целая цепочка команд. В нашем коде: def test_create_raid_():\\n    eracli.raid.create(name=‘test_raid’, level=5, drives=4)\\n    assert eracli.raid.show()\\n\\n    node.reboot() Метод  node.reboot() под капотом подключается к нужной машине по SSH, отправляет команду на перезагрузку и ждет, пока система снова будет доступна. Это и есть mapper для работы с командами Linux-терминала — фактически интерфейс нашей машины:  class AbstractLinuxMapper:\\n    …\\n    def reboot(self) -> None: …\\n    …\\n Например, мы можем удаленно вызвать у нее метод reboot, дождаться полной загрузки системы и затем убедиться, что все прошло успешно. В частности, проверяем, что после перезагрузки RAID-массив сохранился и не разрушился. def test_create_delete_raid_():\\n    eracli.raid.create(name=‘test_raid’, level=5, drives=4)\\n    assert eracli.raid.show()\\n\\n    node.reboot()\\n\\n    assert eracli.raid.show()\\n Автоматизация тестов Автоматизацию тестов можно значительно упростить и сделать элегантнее с помощью Pytest. Рассмотрим один пример. Допустим, мы хотим проверить создание RAID-массивов разных уровней — не только нулевого или пятого, но и других. Если писать такие тесты без особенностей Pytest, получится много однотипного кода, что противоречит хорошему стилю программирования. Нам нужно избежать дублирования, и здесь помогает параметризация. Для этого используется классический декоратор  @pytest.mark.parametrize . В нем мы передаем список параметров, которые будут подставляться в тест. В нашем случае это уровни RAID: 0, 1, 5, 50, N+M. Каждый запуск теста берет очередное значение из списка и выполняет проверку:  @pytest.mark.parametrize(\\'raid_level’, [0, 1, 5, 50, ‘nm’])\\ndef test_create_all_raid_types_(raid_level: str | int):\\n    eracli.raid.create(name=‘test_raid’, level=raid_level, drives=8)\\n    …\\n Так один тест автоматически прогоняется несколько раз с разными параметрами, и код остается компактным. Вместо заключения Подводя итог, можно выделить несколько ключевых результатов, которых удалось достичь благодаря такому подходу к созданию собственного инструмента для тестирования. Мы обеспечили поддержку многих популярных Linux-дистрибутивов и основных версий ядер — 4, 5 и 6 серии. Это делает фреймворк гибким и применимым в разных окружениях. Самое важное: мы добились возможности проводить полное регрессионное тестирование буквально нажатием одной кнопки. Для специалистов по тестированию веб-приложений это звучит привычно, но в мире «железа» — огромный шаг вперед. Ведь нужно проверить не только запись и чтение данных, но и их целостность в разных условиях: при сбоях, отказах компонентов, а то и при падении целой серверной стойки. Автоматизировать такие сценарии и свести их к одному клику — задача нетривиальная, и именно это стало нашей серьезной победой. У такого собственного инструмента, конечно, есть и плюсы, и минусы. Плюсы Минусы Возможность тестировать любые терминальные приложения с CLI-интерфейсом Нужно уметь писать код: команда должна обладать не только навыками тестирования, но и навыками разработки Легкость написания тестов: код максимально похож на терминальные команды, понятен даже инженерам по ручному тестированию без опыта работы с Python Высокая сложность backend-фреймворка: чтобы тесты были простыми, нужно продумать и реализовать сложную основу Возможность быстро создавать большое количество тестов, повышая надежность системы Риск ошибок в самом фреймворке: автоматизаторы могут допускать промахи так же, как и разработчики продукта Гибкость конфигурации: можно встроить любые утилиты и адаптировать инструмент под свои задачи Постоянная поддержка и актуализация: система развивается, и фреймворк нужно регулярно обновлять, чтобы он оставался рабочим Код фреймворка доступен  на GitHub . Любой желающий может посмотреть, как он устроен, и при необходимости адаптировать под свои задачи. Изначально проект появился как решение конкретной проблемы, но сам подход подойдет каждому, кто сталкивается с тестированием сложных систем через CLI. Для меня этот фреймворк стал наглядным доказательством: команда инженеров-тестировщиков способна не только «проверять чужой код», но и разрабатывать полноценные инженерные решения, которые меняют сам подход к работе.', hub='тестирование мобильных приложений'), Page(id='945356', title='Как я в пинболл играл и баги находил', content='Привет, Хабр! Думаю, каждый из активных пользователей сайта уже видел рекламку «Северстали» с запуском IT-завода и пинболом. В шапке страницы В подвале страницы  В правой колонке Короче много её было так что и я тоже не прошел мимо: с трудом набил 3 тысячи, понастольгировал по пинболу из старого Windows, и… на этом не остановился. Решил найти способ победить! Его сделали в 1995.. 30 лет назад.. Далее в статье я рассмотрю разные стратегии, игру в целом и баги, позволяющие набить любое количество очков по вашему желанию и набрав 35 тыс. участвовать в розыгрыше, а так же прекрасную модерацию ботов. Изучение игры и особенности механик Легальные игровые стратегии Автоматизация Баги Изучение игры Тут у нас всё просто: по сравнению с 3D Pinball Space Cadet, выпущенным аж в 1995 году, мы имеем поле, систему запуска, пару направляющих, «бамперов» и флипперов, а так же зоны «ускорения». Флипперы - это палочки, которыми мы управляем. Запуск шара производится слайдером; тут-то и кроется первая особенность: не важно, как сильно или слабо вы его переместите, сила запуска случайна от раза к разу. Так же, кстати, и с отскоком от игровых элементов: они придают разное ускорение. Далее — самая важная механика, которую будем абузить в дальнейшем, — это набор очков в зонах. За тик в зоне дают 50 очков, за удар о «бамперы» — всего десять. Больше вариантов заработать очки нет. Итого: все до боли банально. 3 шарика, запускаем каждый раз, надеясь на удачу, и судорожно пытаемся не дать шарику упасть, при этом отправляя его в сторону зон и бамперов. Легальные игровые стратегии Вариант 1:  Замастерить навык игры в пинболл, поехать в Америку и победить на чемпионате мира; вы ведь не ищете лёгких путей. Вариант 2:  Выработать стратегию, при которой без вашего непосредственного участия будут зарабатываться очки, например: запускать шар так, чтобы он бился о бампер и возвращался обратно. В таком случае попытка не будет считаться завершенной и жизнь не тратиться. НО вспомните про случайность запуска. Еще вариант: запустить шарик так, чтобы он застрял между стенкой и бампером и начал бесконечно биться между ними. Тут уже проблема в скорости и углах; чисто гипотетически это возможно, но шарик имеет скорость, которая от каждого удара увеличивается. При этом я пытался с помощью скриншотов в тики игры доказать, что и она случайна, но у меня не вышло. И даже если получится его так пропихнуть, то как его потом оттуда доставать? Вариант 3 (Реализуемый):  запустить шар так, чтобы он оказался в зоне ускорения вверх и, соответственно, в зоне набора очков. Он постепенно оттуда выпадет, но может успеть заработать нам большое количество очков. Вариант 4 : Найти такую начальную силу запуска, чтобы шарик без вмешательства набирал по 15к очков за раз. Тут мы довольно логично подходим к идее автоматизации. Автоматизация Пусть робот делает за нас действия, чтобы они каждый раз выполнялись одинаково. Именно так я и узнал, что запуски шара различаются по силе, даже если выполнять все действия одинаково. Для начала я автоматизировал запуск, перезапуск игры, а так же нажатие на пробел для отправки шарика. Думал, что, сделав сотню запусков, можно найти тот, который позволит набирать много очков, — не получилось. Далее я просто добавил периодические нажатия на клавиши, управляющие флипперами. Что не только не сильно улучшило результат, но сдаваться я не планировал. Те, кто знаком с творчеством  Code Bullet , понимают, что даже в тетрис или сапер, при желании, можно запихнуть ИИ. Следующим шагом было добавление отслеживания шарика по цвету, а точнее по 3м белым пикселям, расположенным по вершинам треугольника. Если они опускались ниже, чем нужно, срабатывали флиперы. С первого раза система показала себя плохо: при попадании в зону шар менял цвет с серого на красный, и, вероятно, это и мешало. Закончить автоматизацию я так и не успел, потому что нашел БАГ. Хотя признаюсь, в голове была уже идея делать нейронку для пинболла. Баги Так получилось, что я тестировщик не по призванию, а вынуждено: вокруг меня всегда ломается ПО; пока делал статью, обнаружил баг в 10 винде. Если сделать скриншот, открыть «Набросок фрагмента на экране», приблизить через Ctrl и колесо мыши, а затем нажать на кнопку линейки, то попросту окно закроется. Короче, во время тестов заметил, что количество очков явно больше, чем должно было быть, и полез тестировать. Оказалось, что если перейти со страницы с пинболлом, то очки ещё какое-то время считаются, а вот шар зависает на месте и даже теряет или набирает скорость в некоторых случаях. Соответственно если выйти пока он находился в зоне с очками, то они продолжат капать. За одно зависание добавлялось по 3-4 тыс очков. Первое, что я сделал (конечно, после того как немного побаловался и подтвердил результаты тестирования в другом браузере), — это написал в аккаунт «Северстали» и заодно спросил, могу ли я написать эту статью.  Ответом мне было молчание. Я не сдался, полез искать другие контакты. Телефон не подходил. Звонить на завод и говорить: «Дяденька, я тут баг нашел… в пинболле» — я не хотел, так что написал на почту. Оттуда я так и не получил ответа, а баг остался. Видимо, письмо попало в спам или ещё что. Собственно говоря, статью я все же решил не выкладывать, чтобы не портить проходящий конкурс. Пока лазил, обнаружил, что им прям в ВК ужи писали про вариант бага с раздвоением экрана, но там тоже реакции не было. Итого: Очки заработаны, до админв достучаться не удалось, вероятно я не единственный, кто его нашел, ну или там мастер пинболла набрал 190 тыс. пошел так скажем по 1 Варианту. Если с помощью этого бага я выиграю наушники, то думаю продам их и отдам деньги какому-нибудь приюту. Спасибо за прочтение, далее я просто хочу высказать свое мнение по поводу проведения таких конкурсов и, главное, бот-аккаунтов в них. Боты А теперь немного о наболевшем. Я понимаю, что модерация розыгрыша — дело не очень благодарное, но все же: в верхнем списке претендентов на самый крутой приз всего человек 30. Цифры взяты не с потолка: перед написанием я взял чужой аккаунт и догнал его до 40 тыс. очков. Так вот, я решил посмотреть тогда на 10 лидеров; среди них — 7 новых аккаунтов, созданных, вероятно, только для участия в розыгрыше. Ниже скрины с тогдашней таблицей лидеров: Таблица лидеров 26.08 Хотел разместить тут скриншоты аккаунтов и дат их регистрации с последней активностью, но думаю это не правильно, особенно если кто-то просто завел новый аккаунт, но вот пример Скрин от 09.09 Если вам интересно, попробуйте найти кто там сейчас бот. Сейчас еще добавились какие-то чуваки с космическими цифрами, созданные недавно. Видимо целый клан мастеров пинболла пришёл на хабр. Даже если предположить, что по итогу в главном розыгрыше участвовало аккаунтов 50, то приблизительно половина из них — это чьи-то дубли, созданные ради конкурса и на которые после того, как набили очки, не заходили. Почему их не удалили, вот что мне интересно; мне казалось, что все затеяно ради репутации компании и пиара, а такой пиар…  Ладно, всем спасибо, всем пока, заходите потестить пока есть время  https://severstal-pinball.habr.io/', hub='тестирование веб-сервисов'), Page(id='945348', title='Эксперимент «Надежда» Рихтера: гимн силе духа или научная ошибка?', content='В мире психологии и мотивации свои «городские легенды» — эксперименты, выводы которых кочуют из книги в книгу, обрастая вдохновляющими историями. Один из них — опыт американского психофизиолога Курта Рихтера, проведенный в 1957 году и известный как эксперимент «Надежда». Его традиционная трактовка стала гимном силе человеческого духа: якобы вера в спасение способна творить чудеса. Но что, если копнуть глубже? Мой анализ привел меня к выводам, которые скорее ужасают, чем вдохновляют. 🧪 Суть классического эксперимента Рихтер помещал крыс в высокие стеклянные цилиндры с водой, из которых нельзя было выбраться. Эксперимент состоял из двух частей: Группа А (Без надежды): \\xa0Крыс помещали в воду. Они плавали в среднем\\xa0 15 минут , после чего тонули. Группа Б (С надеждой): \\xa0Других крыс в момент, когда они начинали тонуть, их вынимали, давали отдохнуть, а затем снова помещали в воду. Эти крысы демонстрировали невероятную выносливость, плавая\\xa0 в среднем 60 часов , а одна из крыс продержалась\\xa0 81 час . 15 минут против 60 часов. Это не просто больше.  Это разница в 240 раз . Одна крыса плавает четверть часа, а другая — двое с половиной суток, и это звучит абсурдно с точки зрения простого психологического объяснения. Если бы разница была, скажем, в 2 раза (30 минут против 60), то «надежда» могла бы иметь смысл. Но 15 минут против 60 часов? Это не «немного больше выносливости»,  это увеличение на 24 000% и должно объясняться принципиально разными состояниями организма . Такое несоответствие и заставило меня попробовать глубже разобраться в возможных причинах и постараться найти более достоверную гипотезу и объяснение происходящего. 🌟 Традиционная интерпретация: гимн надежде Классический вывод звучит красиво и по-человечески:\\xa0 психологическое состояние напрямую влияет на физиологию . Отсутствие надежды на спасение заставляет мозг «сдаться» и выключить тело. И наоборот — стоит дать надежду (спасти и показать, что спасение возможно), как организм мобилизует все ресурсы для выживания. Этот эксперимент часто приводят как доказательство силы позитивного мышления и веры. Но что, если Рихтер и его последователи совершили фундаментальную ошибку, антропоморфизируя животных и не учтя базовые нейробиологические механизмы? 🔍 Критика: взгляд через призму биологии Моя интерпретация основана на двух ключевых биологических концепциях, которые полностью переворачивают традиционный нарратив -  танатоз  и  габитуация . 🧬 Гипотеза 1: Крысы тонут не от «безнадежности», а от танатоза У многих животных, существует врожденная защитная реакция на сильный стресс  \"Симуляция смерти\"  —\\xa0 танатоз \\xa0(или тоническая иммобилизация). Это не психологическая капитуляция, а\\xa0нейробиологическая программа выживания, запускаемая в\\xa0стволе мозга\\xa0(вентральными ядрами ретикулярной формации, периакведуктальным серым веществом) и модулируемая лимбической системой (миндалина, гипоталамус). Ведущий компонент -\\xa0иммобилизация\\xa0(обездвиживание) как защитная стратегия. Физиологические изменения (замедление дыхания, брадикардия) -\\xa0сопутствующие\\xa0элементы этой программы. Танатоз возникает так же у крыс и мышей. Важно отметить, что  он не контролируется высшей нервной деятельностью . Это\\xa0в первую очередь рефлекторная, стресс-индуцированная реакция, контролируемая низшими отделами нервной системы (ствол мозга, спинной мозг) и гормонами.\\xa0Хотя высшая нервная система (кора, лимбическая система) участвует в оценке угрозы и у\\xa0некоторых\\xa0видов может модулировать длительность или вероятность реакции на основе опыта,\\xa0но само состояние является непроизвольным и не может быть сознательно и произвольно \"включено\" или \"выключено\" животным по своему усмотрению в момент непосредственной угрозы. Может показаться, что танатоз полностью противоречит инстинкту самосохранения, но на самом деле это  увеличивающий выживаемость в естественных условиях . Логика танатоза в природе: Имитация мертвой добычи:  хищники инстинктивно ослабляют хватку или теряют интерес к добыче, которая перестает двигаться и выглядит мертвой. Это дает жертве шанс на побег, если хищник ненадолго отвлечется или ослабит хватку. Прекращение борьбы:  Прекращение движений и борьбы уменьшает вероятность нанесения жертве дополнительных травм (разрывы, переломы) во время захвата и транспортировки. Энергосбережение:  коллапс (падение давления, замедление пульса) резко снижает потребление кислорода и энергии. Если хищник не убивает жертву сразу (например, относит в логово или припасает), у \"притворившейся мертвой\" жертвы будет больше ресурсов для потенциального побега позже. Помимо непосредственной встречи с хищником танатоз может произойти и в момент сильного стресса, испуга, незнакомой обстановки. Это вскрывает саму суть и проблему эксперимента. Что происходит в эксперименте Рихтера?  Крыса не \"сдавалась\" и не \"решала утонуть\". То, что она тонет, — это фактор, обусловленный средой. Ее нервная система в ответ на сильный стресс активирует\\xa0защитный рефлекс\\xa0в ответ на невыносимый, неконтролируемый стресс и ощущение неминуемой гибели. Это физиологический паралич, а не психологическая капитуляция. Это была именно потеря сознания из-за стресса как защитный механизм, потеря надежды тут не при чем. В реальном мире танатоз, возможно, как раз бы спас жизнь крысе — хищник её бы не заметил. И он наступает довольно вовремя — на пике. В танатозе нет смысла через 60 часов, когда хищник давно бы съел, переварил и испражнился крысой.\\xa0Сам танатоз — это не капитуляция крысы, а единственно возможная стратегия выживания, отработанная эволюцией за миллионы лет. Он наступает тогда, когда он должен наступать. Автор эксперимента поставил его именно так, что при наступлении танатоза крыса гибнет. Это не отражение, что крыса сдается, это отражение больной фантазии экспериментатора и некомпетентности. Крысу поместили в полностью неестественную для неё среду и стрессовую ситуацию невозможную в реальном мире. Рихтер столкнулся с кажется необъяснимым фактом - дикие крысы, свирепые и сильные, тонули быстрее домашних и он не мог ответить почему такое происходит. Но принимая во внимание гипотезу танатоза ответ очевиден - именно для диких крыс обстановка была максимально стрессовой и танатоз наступал быстрее. И как раз это объясняет то, что не мог понять Рихтер. Проблема крысы только в том, что она не знает, как реагировать на незнакомую среду и опасность, она оперирует механизмами заложенными в неё эволюцией. В естественной среде этот механизм\\xa0спасает, а убивает он только в искусственных условиях эксперимента спроектированного Рихтером. Вывод: \\xa0крысы Группы А гибнут не из-за отсутствия надежды, а из-за срабатывания рефлекса, который в естественных условиях должен был бы их спасти. Экспериментатор создал условия, где спасительный механизм стал смертельным. 🧠 Гипотеза 2: «Надежда» — это выученная беспомощность и габитуация А что же группа Б? Крысы группы Б, которых вынимали, успокаивали и снова опускали, держались 60 и более часов после этого. Но это явление нужно рассматривать не через антропоморфный термин \"надежда\", а через поведенческую биологию. Габитуация (привыкание):\\xa0Повторяющееся воздействие стрессора (воды) без немедленного смертельного исхода приводит к снижению силы реакции на него. Это  обучение реакции на раздражитель — воду. Реакция становится не такой сильной - меньше гормонов стресса выбрасывается, меньше активность зон отвечающих за стресс в мозге. И это приводило к отключению срабатывания танатоза. Что происходит на самом деле? Снижается стресс: \\xa0поскольку пиковый стресс не достигает критической отметки, танатоз не запускается. Формируется пассивная стратегия: \\xa0крыса усваивает, что ее спасает гигантский рукав с неба (рука экспериментатора). Ее задача смещается с активных попыток спастись («бороться») на пассивное сохранение энергии («ждать спасения»). Она не плавает 60 часов из-за силы надежды — она\\xa0 экономит силы и медленно умирает \\xa0в ожидании внешнего вмешательства, которого больше может и не быть. Это не надежда. Это —\\xa0 выученная беспомощность . ⚗️ Методологические проблемы: какой эксперимент нужен был на самом деле? Оригинальный эксперимент Рихтера методологически несостоятелен для заявленных выводов. Сама методология эксперимента изначально выстроена некорректно. Эксперимент должен быть вообще гораздо сложнее и вариативнее. Эксперимент с возможностью побега. \\xa0Необходимо поместить крыс в воду, но дать им сложный, но достижимый путь к спасению (например, цепляться за постепенно уходящую под воду платформу). Крысы могут сбежать, но должны совершить экстра усилие.  Затем посмотреть: Становятся ли крысы из Группы Б ( «обнадеженные» ) после нескольких спасений\\xa0 менее склонными \\xa0к активному спасению себя, полагаясь на внешнюю помощь? Если «надежда» лишает их воли к самостоятельной борьбе, то это не сила, а слабость. Если после получения надежды крысы уже не могут совершить экстра усилие, то суть изначальной интерпретации меняется на противоположную — давая «надежду», мы не спасаем крысу, а только продлеваем её мучения и делаем её неспособной выбраться самой. Если после 10-20 спасений крыса уже просто будет только пассивно удерживаться на поверхности и вообще не пытаться выбраться, то это веский повод в пользу гипотезы о снижении стресса и танатозе как причине гибели крыс в группа А. Это идет вразрез с тем, как обычно рассказывают об этом эксперименте. Надежда становится не благом, а уродующим психику инструментом, продлевающим мучения и в то же время отбирающим последний шанс выбраться. Измерение физиологических маркеров. \\xa0Необходимо замерять уровень гормонов стресса и активности зон мозга у обеих групп, а не делать выводы только на поведении: Если у крыс Группы Б при погружении\\xa0 уровень стресса ниже \\xa0(благодаря габитуации), это объясняет отсутствие танатоза и подтверждает гипотезу о пассивном ожидании. Сравнительно высокий уровень гормонов стресса в Группе А будет прямым доказательством причины запуска танатоза. Без этих данных эксперимент остается лишь жутковатой историей с преждевременными выводами. ⚠️ Этическая и терминологическая проблема Использование терминов «надежда» и «безнадежность» по от��ошению к крысам —\\xa0 антропоморфизм . Мы проецируем на животное человеческие эмоции, которых у него может и не быть. Научно корректнее говорить: Вместо «надежды» \\xa0— «повторное воздействие стрессора без летального исхода» (габитуация). Вместо «безнадежности» \\xa0— «первичное воздействие экстремального неконтролируемого стрессора». Здесь традиционная интерпретация полна восхищения и видит триумф. Но вот только на самом деле дав «надежду», мы\\xa0продлеваем агонию животного на десятки часов, лишая его последнего защитного механизма — танатоза (который в естественно среде возможно спас бы ему жизнь) и лишая сил совершить экстра усилие для спасения. Выводы: не надежда, а проклятие В самой постановке эксперимента не учтены особенности поведения крыс, их реакция на стрессовые факторы. Предложенные гипотезы как вероятные интерпретации эксперимента, проведенного Куртом Рихтером, полностью переворачивают популярные выводы эксперимента о «надежде» и переосмысление эксперимента Рихтера приводит к пугающим выводам: Крысы гибнут не от безнадежности, \\xa0а из-за срабатывания древнего рефлекса (танатоза) в искусственно созданных неадекватных условиях. Основная причина гибели крыс - глупость экспериментатора поставившего некорректно эксперимент без учета особенностей поведения крыс при воздействии стресса. Долгое плавание «обнадеженных» крыс — это не триумф духа, \\xa0а трагедия выученной беспомощности и пассивного ожидания спасения извне на фоне сниженного стресса. Традиционная интерпретация оправдывает жестокость: \\xa0если дать «надежду», то можно оправдать многодневные мучения подопытного существа. Мы в ответе за тех, кого «обнадежили». \\xa0Спасая кого-то один раз, мы можем лишить его механизмов самостоятельного выживания, обрекая на зависимость от внешней помощи. Эксперимент «Надежда» — это не история о силе духа. Это история о том, как некорректная методология и антропоморфная интерпретация могут превратить акт продолжительной пытки в красивую басню о победе разума над материей. Традиционная интерпретация эксперимента Рихтера превращается в издевательский подтекст: \"Смотрите, если дать надежду, они так мучаются дольше! Как прекрасно!\" - это морально невыносимо. Мы даем крысе не «надежду», а делаем ее более пассивной. Крысы не \"надеются\", они просто физически не могут потерять сознание (танатоз не срабатывает) и вынуждены экономить силы в ожидании... чего? Спасения? Или просто конца? Это делает долгое выживание в эксперименте не триумфом надежды, а\\xa0трагедией продленной агонии и утраты автономии. И тогда получается, наше спасение крысы — это не наш дар, а проклятие. Это не наивная «надежда», а эта «надежда» — именно то, что делает крысу более слабой, и только поэтому она может держаться дольше, экономя ресурсы. Спасатель при этом растягивает агонию крысы не просто на минуты, а на часы и дни, лишая её возможности выбраться самой, даже если бы такая возможность была. Как сказал Экзюпери: Мы в ответе за тех, кого приручили Если ты спас крысу один раз, ты будешь должен спасать её снова и снова, т.к. ты отнял у неё страх, а вместе с ним и силы для борьбы. Как-то я слышал фразу, которая мне запомнилась: «Хуже ада может быть только надежда». А что вы думаете? Традиционная интерпретация, на ваш взгляд, все же имеет право на сосуществование?', hub='биология'), Page(id='945292', title='Подстилая соломку, или Как выжить в ситуационном центре', content='Привет, Хабр. Меня зовут Кирилл Борисов, я SRE в Ситуационном центре. Я часто видел, как неправильное использование паттернов отказоустойчивости архитектуры или их игнорирование приводит к серьёзным последствиям. Поэтому хочу рассказать, как обеспечить надёжность в условиях, когда может упасть любой микросервис. Так выглядит микросервисная архитектура Uber с обозначением всех взаимосвязей. У каких-то компаний ИТ-системы скромнее, у каких-то — обширнее, но суть в том, что микросервисы не живут в вакууме, они обязательно друг с другом взаимодействуют, обращаются в базы данных, в Kafka и т. д. Всё это нужно отслеживать. А это график реального сбоя у Amazon, произошедшего в 2021 году. Они накатили обновление (по моему опыту, 90 % проблем — это какой-то апдейт) и увеличили ёмкость одного из ЦОДов. И во внутренней сети случился сбой. Клиенты обращались за network pool-ами, получали отказ и начинали раз за разом повторять обращения. Возник шквал запросов, который положил Amazon, а вместе с ним Slack, Netflix, Epic Games и сервисы многих других компаний. Причина была в том, что в одном из компонентов сработал retry и не было rate limit. Фактически, они сами себя задидосили. Типичные проблемы Большие инциденты никогда не происходят из-за огромных проблем, причины всегда мелкие, незначительные. Например, высокая задержка в одном из сервисов. К нему обращаются, сервис не отвечает, переполняется connect-pool, и всё падает. Или, например, сетевые проблемы: отвалился канал в ЦОД, инженер быстро перевоткнул кабель, чтобы никто не заметил. Или возникла частичная деградация сервисов, что привело к снежному кому большого сбоя. Всевозможные мелкие проблемы приводят к крупным отказам двух типов: Метастабильное состояние , при котором система не выполняет своей функции после устранения триггера сбоя. Яркий пример — сборщик мусора в Twitter. У них был сервис на Java, в него пришёл трафик на уровне 100 RPS. Затем трафик вырос, и JVM начала чаще запускать сборщик мусора. А у него есть особенность: на доли миллисекунды он останавливает обработку всех запросов, чтобы очистить память. Из-за этого сервис начал отвечать дольше. А поскольку количество сессий сборки мусора увеличилось, стали расти очереди запросов. И даже если бы остановили трафик, накопившиеся запросы пришлось бы ещё долго разгребать. То есть система пришла в метастабильное состояние: функционировала, но новые запросы не обрабатывала, потому что своей очереди ждало множество старых. Каскадный сбой  — это когда один компонент падает и запускает цепную реакцию, парализующую всю систему. Очень распространённое явление. Один из интересных примеров произошел в Microsoft в 2018 году. Отказала система охлаждения в ЦОДе — штатная ситуация: перегрев, серверы автоматически выключились. Но в результате возник сбой в управлении, и выключились вообще все серверы, в том числе управлявшие кластерами. Из-за этого отключился Azure Resource Manager: пропал мониторинг, возможность восстановления и миграции виртуальных машин. В таких случаях нельзя обезопасить себя полностью, но можно уменьшить травматичность подобных сбоев. Для этого используют паттерны отказоустойчивой архитектуры. Паттерны отказоустойчивости Повторные запросы (Retry Pattern) Сеть нестабильна. В сервисах часто встречаются различные ошибки: 110 Connection timeout 100 Network is down\\xa0\\xa0 111 Connection refused 504 gateway timeout 503 service unavailable 500 internal server error Можно обратиться к сетевым инженерам и попробовать разобраться с причинами. Но нужно всегда помнить о потенциальной нестабильности сети и заранее к этому подготовиться. Например, отправлять повторные запросы. Допустим, сервис А обращается к сервису В. Тот отвечает ошибкой: network down, connection refused или чем-то другим. Тогда сервис А шлёт ещё один запрос. В ответ снова ошибка. Делаем ещё один запрос, и, наконец, получаем ответ. То есть этот паттерн подразумевает отправку повторных запросов, пока не получим корректный ответ. Такой подход помогает при коротких сбоях, однако он опасен без jitter и может привести к возникновению лавины запросов. Как сделать так, чтобы повторы не перегружали систему? Для этого используют exponential backoff: каждый следующий повторный запрос через увеличенный промежуток времени. Например, повторили первый раз, через 20 секунд — второй раз, ещё через 40 секунд — третий раз, и так далее. Это можно сравнить с тем, как вы пытаетесь достучаться до коллеги: сначала спросили, он не отвечает, вы повторили погромче, а через какое-то время крикнули, и тогда он вам ответит. Второй способ обезопасить паттерн retry: добавить jitter (случайную задержку), особенно в сочетании с exponential backoff. Это позволит ещё больше размыть запросы во времени. Также можно ограничить общее количество повторных запросов и добавить для них общий таймаут. Если сервис несколько раз не отвечает, то не стоит больше стучаться: у него серьёзный сбой. Как нет смысла 20 раз кричать коллеге, после первого раза проще подойти и похлопать по плечу. Формула exponential backoff с jitter: delay = min(base_delay   (2^attempt), max_delay)   jitter_factor где: jitter_factor = random(0.5, 1.5) # полный jitter или jitter_factor = 1 + random(-0.1, 0.1) # равный jitter Типы jitter: Full Jitter: delay = random(0, calculated_delay) Equal Jitter: delay = calculated_delay/2 + random(0, calculated_delay/2) Decorrelated Jitter: delay = random(base_delay, previous_delay * 3) Не все запросы целесообразно повторять. Повторять можно GET-запросы, они ничего не ломают. А с POST и PUT всё сложнее. В этом случае рекомендуется использовать ключи идемпотентности. Это уникальные идентификаторы, который мы добавляем к запросам. Даже если сервер ответит ошибкой, он может обработать запрос. Например, чтобы не было ситуаций, когда в интернет-магазине кто-то трижды обратился к платёжному сервису и трижды оплатил один и тот же заказ. И, конечно же, мониторинг. Нужно знать, где и какие проблемы возникают, потому что некоторые причины повторных запросов можно исправить. Мониторинг и метрики отказоустойчивости Для эффективной работы паттернов отказоустойчивости критически важно отслеживать правильные метрики. Ключевые метрики для Retry Pattern: Количество повторных попыток по сервисам. Success rate после retry и первой попытки. Время выполнения с учётом retries. Распределение ошибок по типам. \\xa0Чек-лист для Retry Pattern: [ ] Используется экспоненциальный backoff? [ ] Применён jitter для рандомизации? [ ] Ограничено максимальное количество попыток? [ ] Настроены метрики отказов повторных запросов? Эти меры помогут сгладить пики повторных запросов. Таймауты (Timeout Pattern) Представьте ситуацию: сервис журналирования пишет данные в базу без какого-либо таймаута. Тут один из хостов завис, вызов не обработан и приложение заблокировалось, в журнал не пишет. Такое происходит по разным причинам: из-за перегрузки сервиса, программного сбоя, ошибки оборудования, потерь в сети. Любая инфраструктура нестабильна, это нужно принимать как данность. Поэтому используйте таймауты. Поясню на схеме: Service A идёт в Service B. Запрос был некорректный и отбился по стандартному таймауту — одной секунде. Мы переделали запрос, отправили снова, и на этот раз быстро получили корректный ответ. Но в сумме набралось 1020 мс. Пример искусственный, но идею, думаю, вы поняли. Как можно улучшить ситуацию: Добавить таймауты на стороне клиента . Я, как пользователь, обращаюсь к сервису с заранее настроенным у меня таймаутом, и по его достижении просто верну себе ошибку. Deadline propagation . Очень удобный инструмент, хотя настраивать его не слишком просто. Идея такая: при обращении к сервисам вы не просто задаёте себе таймаут, но ещё и при его превышении просите сервис больше не обрабатывать ваш запрос. Это полезно в случаях, когда вы не хотите долго ждать ответ и впустую тратить на обработку ресурсы сервиса и оборудования. Ограничение общего времени для повторных запросов , чтобы не бомбить бесконечно мёртвый сервис. Настроить таймаут по 99 или 95 перцентилю . Мне больше нравится 95, он более щадящий. Это статистическая метрика, отражающая долю запросов, которые обрабатываются быстрее заданного временного порога. Например, быстрее 500 мс. Не нужно использовать среднее значение, потому что вы будете отбрасывать по таймауту многие запросы, которые могли бы обработать. Согласованность таймаутов . Без этого никак. Если в цепочке взаимодействий между сервисами все таймауты будут разные, это может привести к излишнему отбрасыванию запросов. Старайтесь согласовывать таймауты, в идеале — делать их одинаковыми. Чек-лист для Timeout Pattern: [ ] Таймауты основаны на реальных задержках? [ ] Используются перцентили для настройки? [ ] Таймауты дифференцированы по типу запросов? [ ] Журналируются таймауты и причины? Автоматический выключатель Допустим, вы копаетесь в логах и замечаете, что в какие-то моменты сервис работает некорректно. Например, резко возрастает нагрузка на процессор, или взлетает количество операций ввода-вывода, или возникает волна ошибок 500. А вы этому сервису шлёте повторные запросы, которые только ухудшают ситуацию. Сервис цепляет какую-нибудь базу данных, которая живёт в кластере и тянет за собой другую базу, и т. д. Короче, происходит каскадный сбой. Для решения этой проблемы можно настроить автоматический выключатель (circuit breaker), чтобы спокойно разбираться с возникающими сбоями, не отправляя трафик на захворавший сервис. Например, для этого можно автоматически отключать зависимости, а через некоторое время проверять его состояние: таймаут, /health, мелкие тестовые запросы. Если сервис опять не ответил, сбрасываем таймаут и снова ждём. В Kubernetes для этого служат зонды readiness-liveness. Также можно применять состояние half-open, оно очень похоже на канареечные релизы: сначала пускаете 5 % трафика, проверяете работу сервиса, потом 10 %, 20 %, 30 %, 100 %. Чек-лист для Circuit Breaker: [ ] Есть ли fallback? Всегда возвращайте клиенту не ошибку, а понятное сообщение. [ ] Применяется Half-Open state? [ ] Поддерживается прогрессивное восстановление? [ ] Есть оповещения на срабатывания выключателя? Ограничение количества запросов (Rate Limiting) Бывают ситуации, когда принимающая сторона не может справиться с ростом трафика. Например, знаменитость опубликовала в соцсети важный пост, и куча людей кинулась его читать; или компания устроила распродажу на праздники, и покупатели начали обрывать сайт; или разработчики отправили некорректный запрос; или начался банальный DDoS. Для защиты от подобных ситуаций применяют ограничение частоты запросов (rate limit). Очень эффективный инструмент: просто отрезают какое-то количество трафика. Устанавливайте ограничения на клиентах и серверах. Например, сервис А говорит сервису Б, что будет обращаться к нему не чаще 100 раз в секунду, и сервис Б говорит сервису А, что будет принимать запросы не чаще 100 раз в секунду. Устанавливайте burst limit. Это механизм постепенного отбрасывания трафика выше какого-то предела, для сглаживания всплесков. Алгоритмы Rate Limiting: Token Bucket . Самый популярный. Ведро постоянно пополняется токенами с заданной скоростью. Запрос проходит, если есть токен. Leaky Bucket . Запросы поступают в ведро и вытекают с постоянной скоростью. Если ведро переполнено, запросы отбрасываются. Fixed Window . Подсчёт запросов в фиксированных временных окнах (например, 100 запросов в минуту). Sliding Window Log . Точное отслеживание времени каждого запроса в скользящем окне. *Sliding Window Counter . Компромисс между точностью и производительностью. Сравнение алгоритмов: Token Bucket:\\xa0 \\xa0 [+] Поддержка burst\\xa0 [-] Сложность реализации\\xa0\\xa0 Fixed Window:\\xa0 \\xa0 [+] Простота \\xa0 \\xa0 \\xa0 \\xa0 [-] Эффект границы окна Sliding Window:\\xa0 [+] Точность \\xa0 \\xa0 \\xa0 \\xa0 [-] Потребление памяти Используйте разные ограничения для разных клиентов. Чек-лист для Rate Limiting: [ ] Есть ли лимиты на внешнем периметре (API-шлюзы, Ingress)? [ ] Есть ли отдельный лимит для фоновых задач и скриптов? [ ] Есть ли мониторинг rate-limiting событий (графики, оповещения)? Я описал четыре паттерна, которые вы можете использовать практически сразу же. Код для ограничения нагрузки, автоматического выключения и таймаутов написать легко, алгоритмы простые. Продвинутые техники отказоустойчивости Bulkhead Pattern (Паттерн Переборок) Bulkhead pattern — это изоляция ресурсов для предотвращения каскадных сбоев. Название пришло из судостроения: корпус корабля делят переборками на отсеки, чтобы затопление одного отсека не потопило весь корабль. Принцип работы Основная идея: разделить системные ресурсы на независимые пулы: Thread pools: отдельные пулы потоков для разных операций. Connection pools: изолированные пулы подключений к БД. Memory allocation: выделенная память для критичных компонентов. CPU resources: распределение процессорного времени. Типы изоляции 1. По критичности: Критичные операции:\\xa0 [ThreadPool-Critical: 50 threads] Обычные операции:\\xa0 \\xa0 [ThreadPool-Normal: 30 threads]\\xa0\\xa0 Фоновые задачи:\\xa0 \\xa0 \\xa0 [ThreadPool-Background: 10 threads] 2. По клиентам: VIP клиенты: \\xa0 \\xa0 \\xa0 \\xa0 [ConnectionPool-VIP: 20 connections] Обычные клиенты: \\xa0 \\xa0 [ConnectionPool-Regular: 50 connections] Внутренние сервисы:\\xa0 [ConnectionPool-Internal: 10 connections] 3. Географическая изоляция: US-East region:\\xa0 \\xa0 \\xa0 [Resources-US: CPU, Memory, Network] EU-West region:\\xa0 \\xa0 \\xa0 [Resources-EU: CPU, Memory, Network] Asia-Pacific:\\xa0 \\xa0 \\xa0 \\xa0 [Resources-APAC: CPU, Memory, Network] Лучшие практики Bulkhead Правильное разделение: группируйте операции по критичности, а не по функциональности. Мониторинг: отслеживайте загрузку каждого пула отдельно. Настройка размеров: размеры пулов должны соответствовать нагрузке. Fallback стратегии: предусмотрите, что делать при переполнении пулов. Тестирование изоляции: регулярно проверяйте, что перегрузка одного пула не влияет на другие. Чек-лист для Bulkhead Pattern: [ ] Определены критичные и некритичные операции. [ ] Настроена изоляция пулов соединений/потоков. [ ] Реализован мониторинг для каждого пула. [ ] Настроены оповещения на переполнение пулов. [ ] Изоляция протестирована под нагрузкой. Adaptive Timeout (Адаптивные таймауты) Adaptive Timeout — это динамическое изменение значений таймаутов на основе текущей производительности системы. Вместо использования статических значений, таймауты адаптируются к реальным условиям. Проблема статических таймаутов Статические таймауты имеют недостатки: Слишком короткие → много ложных срабатываний. Слишком длинные → медленная реакция на сбои. Не учитывают текущее состояние системы. Одинаковые значения для разного времени суток. Алгоритм адаптивного таймаута Базовая формула: adaptive_timeout = percentile(recent_response_times, P) * multiplier + buffer где: P — 95 или 99 перцентиль; multiplier = 1,2-2,0 (запас на вариативность); buffer — минимальный буфер времени; Алгоритм экспоненциального сглаживания: new_timeout = α   current_response_time + (1-α)   previous_timeout где α = 0,1-0,3 (коэффициент сглаживания) Лучшие практики Adaptive Timeout Достаточно данных: не обновляйте таймаут на основе < 10-20 измерений. Сглаживание: используйте экспоненциальное сглаживание для стабильности. Границы: всегда устанавливайте min/max значения. Разные сервисы: у каждого сервиса свой адаптивный таймаут. Мониторинг: отслеживайте изменения таймаутов и их эффективность. Чек-лист для Adaptive Timeout: [ ] Настроено измерение времени ответов для каждого сервиса. [ ] Установлены разумные min/max границы таймаутов. [ ] Реализовано экспоненциальное сглаживание. [ ] Добавлен мониторинг изменений таймаутов. [ ] Протестирована работа при различных нагрузках. Backpressure Handling (Обработка обратного давления) Backpressure — это механизм контроля нагрузки, когда медленный получатель сигнализирует отправителю о необходимости снизить скорость передачи данных. Это критично для предотвращения переполнения буферов и сбоев системы. Проблема без Backpressure Что происходит при отсутствии контроля: Быстрый producer → медленный consumer. Накопление в очередях и буферах. Потребление памяти растёт вплоть до Out Of Memory. Увеличение задержки обработки. Потеря данных при переполнении. Стратегии Backpressure 1. Push-based (проталкивание): Producer → [Queue] → Consumer \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0↑ очередь растёт Проблема: consumer не может контролировать скорость. 2. Pull-based (вытягивание): Producer ← [Queue] ← Consumer запрашивает данные \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0↑ контролируемый размер Решение: consumer запрашивает только то, что может обработать. 3. Adaptive (адаптивная) Producer ⇄ [Queue] ⇄ Consumer \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0↑ динамический размер Комбинация: автоматическое замедление producer-а. Лучшие практики Backpressure Выбор стратегии: block для критичных данных, drop для метрик и логов. Мониторинг: отслеживайте rejected- и dropped-элементы. Graceful degradation: возвращайте клиентам понятные ошибки. Адаптивность: динамически изменяйте стратегию по нагрузке. Circuit breaking: комбинируйте с circuit breaker для защиты. \\xa0Чек-лист для Backpressure Handling: [ ] Определена стратегия обработки перегрузки (Block/Drop/Adaptive). [ ] Реализован мониторинг размеров очередей и отклоненных элементов. [ ] Настроены meaningful HTTP status codes (503, 429). [ ] Добавлены заголовки Retry-After для клиентов. [ ] Протестирована работа под высокой нагрузкой. Чек-лист готовности к production: [ ] Все критичные интеграции имеют таймауты. [ ] Настроены retry для идемпотентных операций. [ ] Внедрены circuit breaker для внешних API. [ ] Работает rate limiting на входе. [ ] Настроены оповещения на ключевые метрики. [ ] Проведено chaos testing. [ ] Команда обучена работе с новыми инструментами. [ ] Есть runbook для типовых инцидентов. Резюме Надёжность должна быть заложенным в архитектуру свойством, а не случайным совпадением. То есть, всё то, что описано в этой статье. Каждый инструмент — потенциальный источник ошибок, если неправильно настроен. Можно слать повторные запросы самим себе, можно выставить такие таймауты, что ответа не дождёшься или отбросишь множество полезных запросов, и т. д. Но главное — все эти паттерны нужно не просто внедрить, а  проверить в боевых условиях через chaos engineering . Только в искусственно созданных сбоях вы поймёте, как поведёт себя система: выдержит ли rate limiting, правильно ли сработает circuit breaker, не обрушит ли retry ваш сервис, не окажутся ли таймауты слишком жёсткими или мягкими. Chaos engineering позволяет превратить теоретическую отказоустойчивость в практическую. Он помогает убедиться, что выбранные решения действительно работают и команда знает, как действовать при инциденте. Что бы вы ни создавали, спрашивайте себя: «Что будет, если всё пойдёт не так?», и проверяйте это не на клиентах, а заранее, в контролируемом эксперименте.', hub='devops'), Page(id='945344', title='Куда пойти работать в российский геймдев, если не хочешь создавать «донатные помойки»', content='Многие приходят в геймдев за мечтой — создавать миры, в которые хочется погружаться, истории, которые цепляют, и механики, от которых невозможно оторваться. Но слишком часто эта мечта сталкивается с реальностью, где главным приоритетом становится не игра, а монетизация. Там, где когда‑то придумывали квесты и балансировали боевку, теперь выстраивают воронки доната, рассчитывают психологические триггеры и добавляют искусственные ограничения, чтобы игроку было проще заплатить, чем долго достигать чего-то самому. Для многих разработчиков это превращается в личную дилемму: продолжать работать над проектом, который приносит деньги, но вызывает внутреннее отторжение, или искать место, где ценят саму игру, а не только ее способность приносить прибыль. И такие места есть. В России работают студии, которые делают честные проекты — без агрессивных микротранзакций, навязчивых «сундуков удачи» и ощущения, что игрока рассматривают как живой кошелек. В этой статье разберем, по каким признакам можно понять, что студия не скатится в казино-механики, какие направления в российском геймдеве позволяют работать над честными проектами и приведем конкретные примеры команд, к которым стоит присмотреться. Как понять, что студия разделяет ваши ценности Определить, что перед вами «здоровая» творческая игровая студия, можно еще до собеседования — если внимательно изучить ее проекты, вакансии, публичные заявления и отзывы. Это не какая-то магия, а набор вполне конкретных сигналов, которые опытные разработчики и рекрутеры называют «красными» и «зелеными» флагами. Первое, на что стоит смотреть, — портфолио игр.  Если у студии в активе в основном условно-бесплатные проекты с агрессивными механиками удержания, это тревожный знак. В «донатных помойках» геймплей часто строится вокруг искусственных ограничений: таймеров, дефицита ресурсов, pay-to-win элементов. В честных проектах внутриигровые покупки, если и есть, не ломают баланс и не тормозят прогресс частыми «пейволлами». Простой тест — посмотреть стримы от разработчиков: если авторы обсуждают сюжет, механики и атмосферу, это хороший знак. Второй слой проверки — вакансии и формулировки в них.  Компании, ориентированные на честный продукт, ищут специалистов для улучшения геймплея, нарратива, визуала. Если же в описании задач много про «монетизационные воронки», «оптимизацию ARPU» и «повышение конверсии в платящего игрока» — это прямой индикатор, что бизнес-модель строится вокруг доната. Опытные HR в геймдеве советуют читать такие тексты между строк: даже если слово «донат» не упомянуто, упор на метрики почти всегда означает агрессивную монетизацию. Третий источник информации — репутация в сообществе.  Поищите отзывы бывших сотрудников на DreamJob, Glassdoor, в профильных Telegram-чатах. Обратите внимание не только на зарплаты и условия, но и на то, как описывают подход к продукту. Плюс полезно смотреть, как студия общается с аудиторией: открытые блоги, честные постмортемы, участие в фестивалях — все это признаки прозрачности. Наконец, внутренняя культура.  Ее сложнее оценить снаружи, но можно примерно понять по косвенным признакам: частота релизов (слишком частые могут означать постоянный кранч), текучка кадров, открытость руководства. В интервью и подкастах руководители «здоровых» студий говорят о балансе между бизнесом и творчеством, а не только о KPI. Короче говоря, вам нужна среда, где ценят геймплей и историю, уважают игрока и команду, а игра не служит бизнес-модели. Карта направлений: где искать творческий геймдев в России Если присмотреться, в российской игровой индустрии можно найти несколько четких направлений, в которых можно работать, не чувствуя, что ты обслуживаешь «донатную воронку». У каждого из них своя специфика, риски и возможности. Инди и авторские команды  — это маленькие студии, часто из нескольких человек, которые делают игры «для души». Здесь нет отдела монетизации, а бюджет обычно складывается из грантов, краудфандинга или собственных средств. Такие команды ценят творческую свободу и готовы рисковать ради уникальной идеи. Но вместе с этим приходит и нестабильность: зарплаты могут быть скромными, а сроки бесконечно сдвигаться. Зато именно здесь рождаются проекты, которые потом становятся культовыми: Potion Craft, Black Book, Loop Hero и другие. Средние и крупные премиум‑студии  — это компании, которые работают по классической модели: игра продается за фиксированную цену, а дополнительные доходы приносят DLC или косметические дополнения. Они ориентированы на международный рынок, часто сотрудничают с западными издателями и держат высокую планку качества. Здесь больше ресурсов, стабильная зарплата и возможность учиться у опытных коллег. Минус — меньше креативной автономии: решения принимаются на нескольких уровнях, и не всегда в пользу авторской задумки. Аутсорс  — направление, которое редко приходит в голову новичкам, но дает уникальный опыт. Российские студии участвуют в создании контента для мировых ААА‑проектов: делают уровни, анимацию, модели, иногда целые игровые механики. Здесь нет влияния на монетизацию — вы работаете над конкретной задачей в рамках большого проекта. Плюс — доступ к высоким стандартам и технологиям, а также возможность собрать хорошее портфолио. Минус — вы не контролируете финальный продукт и можете остаться «за кадром» для широкой аудитории. Образовательные и экспериментальные проекты  — это лаборатории, стартапы и команды при университетах, которые создают игры для обучения, исследований или культурных инициатив. Здесь можно работать над чем‑то по‑настоящему новым, тестировать необычные механики и жанры. Но рынок таких игр ограничен, а финансирование часто зависит от грантов и партнерств. Это четыре разные экосистемы внутри одной индустрии. Выбор зависит от того, что для вас важнее: стабильность или свобода, участие в громких релизах или создание чего‑то своего, пусть и нишевого. Примеры российских студий, которые делают честные премиум-игры В российском геймдеве действительно есть команды, для которых игра — это в первую очередь искусство и увлекательный опыт, а не инструмент выкачивания денег. Morteshka  — маленькая инди-команда из Перми, известная по The Mooseman и Black Book. Их игры — это путешествия в мир мифов и фольклора, где каждая деталь продумана, а монетизация сводится к разовой покупке. В Morteshka нет отдела, который считает ARPU и LTV, зато есть художники и сценаристы, которые часами спорят о том, как передать атмосферу северных легенд. Ice-Pick Lodge  — московская студия, которая с конца 90‑х делает авторские, философские проекты вроде «Мор. Утопия» и «Тургор». Их игры сложны, иногда даже намеренно неудобны, но именно в этом их ценность — они заставляют думать над высшими материями. Здесь нет места pay-to-win — только глубокие миры и моральные дилеммы. Four Quarters  — питерская команда, прославившаяся Loop Hero. Это пример того, как необычная механика и минималистичный стиль могут покорить мир. Игра вышла в партнерстве с крупным западным издателем Devolver Digital, продается по премиум-модели и получила признание критиков и игроков по всему миру. Saber Interactive  (питерский офис)  — часть международной компании, работавшая над SnowRunner и Space Marine 2. Российский офис участвует в разработке премиум‑игр для глобального рынка, где монетизация не диктует геймплей. Sperasoft   — крупная аутсорс‑студия из Санкт‑Петербурга, которая делала контент для Assassin’s Creed, Halo, Mass Effect. Здесь нет влияния на бизнес‑модель — команда отвечает за качество конкретных элементов игры. Do My Best  — создатели The Final Station и The Bookwalker. Их проекты часто экспериментальны, но всегда продаются по честной модели. Это небольшая команда, которая делает заметные игры для международной аудитории. Hypetrain Digital  — издатель, который поддерживает независимых разработчиков, выпускающих премиум‑проекты (Police Stories, Tunche). Они помогают инди‑командам выйти на рынок без давления в сторону F2P. Почему даже честные студии могут ввести донат Даже если студия изначально строит проект на честной премиум‑модели, реальность рынка и давление со стороны издателей или инвесторов могут изменить курс. Иногда это выглядит как постепенное «размывание» принципов: сначала добавляют косметические DLC, потом — ускорители прогресса, а через год в игре появляются механики, которые еще вчера казались неприемлемыми. Причины почти всегда прагматичны.  Разработка игр — дорогое удовольствие, особенно если речь идет о долгосрочной поддержке проекта. Серверы, обновления, багфиксы, маркетинг — все это требует денег. Если продажи на старте оказались ниже ожиданий, а аудитория просит новый контент, у руководства может возникнуть соблазн ввести внутриигровые покупки, чтобы закрыть финансовую дыру. Иногда инициатива идет от издателя, который видит в проекте потенциал для дополнительной монетизации и готов вложить больше в продвижение — но при условии, что игра начнет приносить регулярный доход. Есть и более тонкий момент —  компромисс ради выживания. Для небольшой студии отказ от доната может означать сокращение команды или даже закрытие. В таких случаях разработчики могут пойти на минимальные формы доната — например, продавать косметику или дополнительные предметы снаряжения, не влияющие на баланс. Формально это не превращает игру в «донатную помойку», но для кого‑то сам факт появления магазина уже будет сигналом, что принципы пошатнулись. Как к этому относиться разработчику?  Здесь важно трезво оценивать свои личные границы. Если для вас неприемлема любая форма внутриигровых покупок — лучше сразу уточнять на собеседовании, как студия видит монетизацию в долгосрочной перспективе. Если же вы готовы к компромиссам, стоит заранее определить, где проходит ваша «красная линия». Косметика? Сюжетные DLC? Ускорители прогресса? Понимание этих нюансов помогает избежать разочарования. Решения о монетизации принимаются не с потолка или от жадности, а под давлением рынка, бюджета и ожиданий аудитории. Главное — чтобы эти решения не разрушали саму игру и не превращали ее в инструмент выкачивания денег. Даже в России существует целый пласт студий, которые делают игры так, как их задумывали изначально: ради истории, атмосферы, геймплея. Они могут быть маленькими и независимыми, работать в партнерстве с западными издателями или создавать контент для мировых ААА‑проектов, но их объединяет одно — уважение к игроку. Выбор, куда пойти работать, — это всегда баланс между амбициями, условиями и ценностями. Придется внимательнее изучать портфолио студий, задавать прямые вопросы на собеседованиях и строить личный бренд, как разработчика хороших игр. Честный геймдев в России есть. Он не всегда на виду, не всегда с громкими бюджетами, но он живет и развивается благодаря тем, кто отказывается мириться с превращением индустрии из игровой в игорную. И чем больше таких людей будет в индустрии, тем больше шансов, что она постепенно выздоровеет.', hub='разработка игр'), Page(id='945342', title='Комплексная защита АСУ ТП или ICS XDR в действии', content='Всем привет! Меня зовут Максим Гусев, я инженер направления защиты ИТ-инфраструктуры в  К2 Кибербезопасность . Последние несколько лет мы наблюдаем масштабный рост количества атак на производственные объекты. При этом они еще и усложняются — становятся целенаправленными на разрушение ИТ-инфраструктур конкретных организаций. Для собственников и сотрудников производств ситуация еще усложняется растущими требованиями по кибербезопасности со стороны государства. Поэтому для эффективного отражения атак сегодня необходимы новые подходы — комплексные системы мониторинга и реагирования. В частности, все популярнее становится ICS XDR, адаптированный под задачи промышленности. В этой статье я подробно описал, что из себя представляет и зачем нужна эта платформа, а также показал ее эффективность на примере работы ICS XDR от Лаборатории Касперского. Зачем нужны XDR и ICS XDR   Перед практикой разберемся в теории. Как мы вообще пришли к XDR? Каждое средство защиты выполняет свою конкретную функцию, но не обеспечивает полноценную защиту предприятия от киберугроз. Для эффективного же решения проблем безопасности требуется комплексный подход с точки зрения технологий, когда всесторонне анализируются все компоненты системы и интеграции между разными типами средств защиты. Одной из технологий, закрывающих такую необходимость, стал XDR. XDR  (Extended Detection and Response) — это передовая концепция информационной безопасности, которая вышла за рамки традиционной технологии EDR (Endpoint Detection and Response). XDR не просто расширяет возможности EDR, но и интегрирует в себя данные из различных источников для обеспечения более глубокого и комплексного анализа угроз. Если сравнивать защищаемые системами цели, то новая концепция представляет собой endpoint security в самом широком смысле этого понятия. Добавляется защита часто используемых векторов распространения угроз, таких как корпоративные почтовые шлюзы, веб-сайты, и сбор данных с анализаторов сетевого трафика.\\xa0 Платформы XDR позволяют устанавливать приоритеты в соответствии с потенциальным воздействием атаки, что позволяет сосредоточить ресурсы на наиболее критических угрозах. Также XDR может частично или полностью автоматизировать процессы аналитики, обнаружения, расследования и реагирования на угрозы. Отсюда — эффективность без необходимости больших ИБ-подразделений и снижение затрат на безопасность. Основные компоненты защиты XDR: EDR; Антивирусное ПО; IDS/IPS; SIEM; Централизованное управление компонентами; Vulnerability Management. Также об XDR можно почитать в статье моих коллег —  тут . Когда мы говорим про защиту АСУ ТП, то здесь надо учитывать три важных момента: рассматривать кибербезопасность в рамках общей безопасности АСУ ТП; находить баланс между безопасностью, удобством использования и стоимостью системы; контролировать неинвазивность средств защиты по отношению к процессам, обеспечивающим штатные режимы работы АСУ ТП.\\xa0 Технологический процесс всегда стоит на первом месте, и важно, чтобы кибербезопасность не мешала развитию, а, наоборот, помогала безопасно внедрять современные цифровые технологии. Все эти моменты и помогает нам учесть  ICS XDR  (Extended Detection and Response for Industrial Control Systems), который как раз специализируется на защите АСУ ТП и отвечает следующим требованиям:\\xa0анализ промышленных протоколов, неинвазивный режим работы и пониженные аппаратные и программные требования. Состав ICS XDR ICS XDR состоит из нескольких ключевых компонентов, которые интегрируют данные из нескольких источников для обнаружения и реагирования на угрозы в различных участках инфраструктуры.\\xa0 Средства защиты, входящие в его состав, закрывают следующие проблемы: Защита конечных точек — антивирус: Обнаружение угроз : Антивирусы мониторят активность на конечных точках, анализируя файлы и их поведение на наличие признаков вредоносности. Это помогает обнаруживать и изолировать потенциально опасные объекты, такие как вирусы, трояны, Rootkit и т.д. Реагирование на угрозы : После обнаружения антивирусы могут блокировать запуск вредоносных программ, изолировать зараженные файлы, а также предоставлять возможность для самостоятельного реагирования на вредоносы. Защита конечных точек — EDR (Endpoint Detection and Response): Обнаружение угроз : Конечные точки часто являются местом первичного вторжения в сеть. EDR-решения мониторят активность на конечных точках и детектят потенциальные атаки, обнаруживая аномалии и необычное поведение программ или пользователей. Реагирование на угрозы : После обнаружения угрозы EDR предоставляет возможности для быстрого реагирования, включая блокирование вредоносных процессов, изоляцию зараженных устройств и удаление подозрительных файлов. Сбор и анализ данных — SIEM (Security Information and Event Management): Централизованный анализ данных безопасности : SIEM собирает данные с различных источников: журналы событий операционных систем, системы детекции вторжений, системы управления угрозами и т.д., и предоставляет централизованное место для анализа и корреляции информации о безопасности иных средств защиты. Обнаружение сложных атак : SIEM использует правила корреляции для обнаружения сложных атак. Например, распределенных по времени. В соответствии с правилами события или несколько событий поднимаются до уровня инцидента. Анализ сетевого трафика — NTA (Network Traffic Analysis): Обнаружение сетевых аномалий : NTA анализирует сетевой трафик, чтобы выявлять новые неопознанные устройства, аномалии, необычные паттерны и подозрительное поведение, которые могут указывать на наличие вредоносных активностей в сети. Раннее обнаружение атак :   Анализируя сетевой трафик, NTA может обнаруживать атаки на более ранней стадии, до того как они достигнут конечных точек, что позволяет реализовать оперативное реагирование. Система управления уязвимостями (Vulnerability Management): Идентификация уязвимостей в инфраструктуре:  Включает в себя сканирование инфраструктуры на предмет известных уязвимостей, связанных с устаревшим программным обеспечением или с конфигурационными ошибками, и сохранение результатов для последующего анализа и триажа. Помимо сканирования АРМ, серверов и сетевого оборудования происходит поиск уязвимостей на оборудовании АСУ ТП. Это позволяет выявить потенциальные энтрипоинты для атак и своевременно предпринять меры по устранению проблем. Приоритизация уязвимостей в соответствии с рисками : Управление уязвимостями помогает определить наиболее критические уязвимости, учитывая их потенциальное воздействие на систему и бизнес-процессы, что в контексте XDR позволяет качественно ранжировать приоритетность реагирования на угрозы. ICS XDR на практике   На сегодняшний день на российском рынке есть два вендора, заявляющих о построении полноценного промышленного XDR: Лаборатория Касперского и Positive Technologies.\\xa0 Недавно у нас был проект по защите инфраструктуры крупной компании с многостадийным производственным процессом при помощи KICS (Kaspersky Industrial CyberSecurity). Поэтому рассмотрим работу IСS XDR на примере продуктов Лаборатории Касперского.\\xa0 Возможная архитектура KICS включает в себя выделенный сегмент для аналитиков SOC. На уровне технологической сети осуществляется сбор копии трафика с сетевого оборудования, а защита и возможность реагирования реализована с помощью KICS for Nodes (промышленного антивируса) и KEA (агента сбора телеметрии с конечного узла), которые вместе представляют из себя промышленный EDR. В DMZ-сегмент выделены сервера средств безопасности: коллектор KUMA, осуществляющий сбор событий безопасности с конечных узлов технологической сети; jump-сервер для SOC-аналитиков, необходимый для подключения к инфраструктуре; KICS for Networks, проводящий анализ копии трафика из технологического сегмента. В сегменте SOC располагается средство администрирования компонентов ICS XDR — KSC и ядро SIEM-системы, где происходит обработка событий безопасности. Описание атаки и ее реализация Атака начинается с проникновения через зараженную флешку, с помощью которой троян попадает на ноутбук подрядчика и далее — в технологическую сеть Заказчика. Злоумышленник получает доступ к внутренней инфраструктуре, сканирует сеть, находит станцию оператора, подбирает к ней пароль методом брутфорса, получает контроль над SCADA-системой и изменяет критический параметр технологического процесса. На завершающем этапе на SCADA-станции обнаруживается вредоносное программное обеспечение. Шаг 1.  Зараженный трояном с флешки ноутбук подрядчика подключается в технологическую сеть (Replication Through Removable Media T0847, User Execution T0863). Атакующий получает доступ к технологической сети. Обнаружение станции Hacker происходит с помощью KICS for Networks, который видит в трафике появление нового устройства. У нового устройства стоит статус “Неразрешенное”, что является маркером для аналитика ИБ. Шаг 2.  Атакующий сканирует технологическую сеть (Network Sniffing T0842). В разделе события на KICS for Networks видим инцидент с названием “Признаки сканирования сети”. Соответствующее событие присутствует на KUMA благодаря интеграции KICS for Networks и KUMA. Шаг 3.  Произошло обнаружение хакером станции оператора. Методом грубой силы производится подбор пароля к станции оператора (Brute Force T1110). Событие о переборе пароля видим на KICS for Networks, также соответствующее событие поступает в KUMA как на скрине выше.\\xa0 Шаг 4.  Получен доступ к станции оператора. Атакующий получает доступ к SCADA (Remote Service T1021) и изменяет параметр технологического процесса (Manipulation of Control Settings T0832). Изменение технологического тега воздуходувки регистрируется в трафике при помощи KICS for Networks. Для каждого параметра (тега) на KICS for Networks заведены правила, при отклонении от которых системой генерируется алерт. Например, легитимное значение параметра варьируется от 5 до 6, тогда при выходе за данный диапазон система сгенерирует алерт. Соответствующее событие также поступает в KUMA. Шаг 5.  Обнаружен зараженный объект на SCADA Инцидент с обнаружением ВПО на SCADA сформирован с помощью KICS for Nodes и был передан с помощью интеграции KICS for Networks + KICS for Nodes + KEA в общую консоль KICS for Networks, откуда попадает в KUMA. Вывод Рост числа целенаправленных и технически сложных кибератак на промышленные объекты требует перехода от разрозненных средств защиты к комплексным и интегрированным решениям. Традиционные подходы к кибербезопасности АСУ ТП зачастую не справляются с современными угрозами в условиях необходимости обеспечения бесперебойности технологических процессов.\\xa0\\xa0 ICS XDR — это ответ на вызовы времени. Он объединяет возможности антивирусной защиты, EDR, NTA, SIEM, управления уязвимостями в единую платформу, адаптированную под особенности промышленной среды: поддержку промышленных протоколов, неинвазивность, пассивный мониторинг и минимальное влияние на производственные процессы.\\xa0\\xa0 На примере реализации Kaspersky Industrial CyberSecurity я показал, как ICS XDR позволяет эффективно обнаруживать и реагировать на многоэтапные атаки — от заражения через съемные носители до попыток изменения уставок технологического процесса. Интеграция данных с конечных точек, сетевого трафика и систем управления позволяет не только быстрее выявлять инциденты, но и проводить глубокое расследование, повышая зрелость кибербезопасности в целом.\\xa0\\xa0 ICS XDR — это не просто набор инструментов, а стратегический подход к защите критической инфраструктуры, обеспечивающий прозрачность, оперативность реагирования и устойчивость к современным киберугрозам. В условиях цифровизации промышленности такие решения становятся не роскошью, а необходимостью.', hub='информационная безопасность'), Page(id='945338', title='Чему надо учиться? Рассуждаю НЕ про вкатывание в IT', content='Первоклассника сажаем за Python, а домохозяйка радостно осваивает Blender? Конечно, почему бы нет. Но никто не сможет с уверенностью сказать — будут ли те или иные знания востребованы в будущем. А есть ли навык, который если не обеспечит зарплату $100К/нс, то хотя бы поможет в любой сфере (хоть технической, хоть гуманитарной). Мне кажется, я это понял. TL;DR: самое важное —\\xa0 хотеть \\xa0докапываться до сути. Как устроена эта собака? Ну, вступление получилось вполне кликбейтное, хоть рекламу ТГ-канала ставь. Но вопрос, поставленный в заголовке, меня мучает с тех пор, как я стал свидетелем метания нескольких знакомых родителей. А вопрос извечный: «куда отдать учиться деточку?». Истерию (в хорошем смысле) родителей легко понять: кто же не хочет счастья, любимой работы и много денег для ребенка. Но ответить на этот вопрос ой как непросто. В начале 90-х большинство людей посоветовало бы стезю бухгалтера. Пять лет спустя — банковское образование. Вечные профессии вроде стоматолога я не беру — к ним есть интерес всегда, но это, скорее, нишевая история. В последние годы советуют идти в IT, хотя сейчас уже звучат осторожные голоса о перепроизводстве кадров в этой области. Но я не об этом. Давайте примем как аксиому, что\\xa0 нельзя предсказать , какие профессии будут в топе через 10 лет. Понятно, что наиболее живучей будет сфера «человек-человек», но какой родитель захочет, чтобы его ребенок работал, скажем, массажистом или нянечкой (я ни в коем случае не умаляю важности такого труда, лишь сетую на то, что его престижность нынче невелика). Так вот, предсказать мы не можем, угадывать — дело неблагодарное. Остается утвердиться в мысли, что\\xa0 учиться нужно постоянно . Метафору про «бежать, чтобы оставаться на месте» все слышали? Поэтому вышеупомянутой деточке нужно вложить в голову простую истину: отучиться в школе/колледже/вузе и потом с полученным импульсом работать по специальности за много денег не получится. Будет либо тяжело (нудная работа, выгорание, конкуренция в коллективе), либо мелкий прайс, либо и то, и другое. Постоянно впитывать в себя новые знания (хоть по своему профилю, хоть по смежным) — это\\xa0 насущная необходимость . И вот мы подходим к выводу, к которому я пришел (вы не поверите) находясь на отдыхе в Турции. Историю убираю под спойлер не потому, что она 18+, а чтобы нелюбители лирических отступлений не обиделись… Но предупреждаю, в этой истории — главный смысл поста :). История Два корпуса отеля, в котором я проживал, были соединены мостом, проходящим над улицей. Примерно так И за автоматическими дверями в тамбуре одного из корпусов (куда я входил с моста),\\xa0 постоянно \\xa0стояла табличка «Осторожно, мокрый пол». Увидел я ее раз, не придал значения. Увидел второй, удивился. Потом понял, что она там стоит всегда и на этом месте\\xa0 всегда лужа . Начал думать. На потолке подтеков нет, значит капает не оттуда. Кранов и вообще каких-то источников воды рядом нет. Трещин в полу нет, да и откуда грунтовые воды на втором этаже. Короче, сломал всю голову. И вот в очередной раз подхожу я к этому месту и издалека слышу разговор двух людей: - %$я, ну откуда тут постоянно вода? - С потолка вроде не капает… ни фига не понятно... Подхожу и вижу двух граждан, который так же, как и я, изучают феномен. Мы с ними как родные поговорили, обсудили такие фантастические гипотезы, как встреча жаркого и влажного уличного воздуха с холодным и сухим = выпадение конденсата. И один из них мне поведал, что всю неделю, пока тут находится, ломает голову. До сути проблемы мы не докопались, но не в этом главное. Этот человек не прошел мимо, как сотня других людей. Он заинтересовался.\\xa0 Он захотел разобраться! И вывод, который долго зрел в моей голове, наконец оформился. Учиться — это вторично (хотя, без сомнения, нужно). А главное - растить в детях (ну и в себе тоже)\\xa0 любовь к исследованию . Пусть вопрос, который захотелось изучить, не планетарного масштаба и решился он за пять минут. Главное — хотеть разобраться в природе вещей (ну или в том, почему не до конца срабатывает кнопка на сливном бачке унитаза). Долго искал подходящее определение, нашел.\\xa0 Пытливость ума . Вот что в первую голову надо тренировать в детях - желание дойти до самой сути (с). Ребенок хочет программировать — прекрасно, но только в том случае, если не просто научится ставить операторы в нужном порядке, но и будет строить в голове алгоритм. Ребенок хочет готовить еду? Еще лучше, но не по видео с готовыми рецептами, а с «копанием» (пусть разберется почему, например, нельзя в чай с молоком класть лимон). Примеры звучат наивно, но, думаю, суть вы уловили. Ну и последнее, про 100500 денег. Любовь к исследованию, погружению в вопрос — универсальная и всепроникающая. Это  буст абсолютно к любой профессии  (хоть уже упомянутого массажиста, хоть лесника, хоть финансового директора). И «прокачивать» пытливость ума можно в любом возрасте. Главное, чтобы это не прочухали инфоцыгане и не начали предлагать нам соответствующие курсы... Добавлю в постскриптум немного душноты На фоне вышесказанного меня огорчает распространенный нынче тренд \"не буду чинить, куплю новое\". Ему, к слову, следуют люди самых разных поколений. Бесит тут многое: и умножение количества мусора, и лишние траты, и поощрение шопоголизма. Но главное (ИМХО) - это лишение себя удовольствия заглянуть внутрь вещи, поняв, как она работает. Пусть не получится починить. Пусть пунктом назначения станет все та же помойка. Но лишить себя удовольствия разобрать вещь по винтикам и огрокать ее в полноте (с) - вот не понимаю, как так можно...', hub='мозг'), Page(id='945340', title='Взгляд со стороны ИТ-директора на REST API «Битрикс24»', content='Антон Бобров Директор по развитию K-Team, «КОРУС Консалтинг»  Если вы внедряете «Битрикс24» не как игрушку для HR, а как полноценный инструмент управления процессами,  вопрос интеграции  возникнет сразу. Причем остро. Как ИТ-директор, вы должны понимать: может ли система легко синхронизироваться с 1С, Jira, SAP, Power BI, корпоративной почтой или веб-сайтами. И может ли вообще CRM-система встроиться в ваш ИТ-ландшафт. В случае с Битрикс24 — да, может, через REST API. В коробочной версии доступны модули REST API, коннектор к MS SharePoint и MS Exchange, интеграция через CalDAV и CardDAV протоколы. Обо всем подробно я,  Антон Бобров, директор по развитию K-Team от ГК «КОРУС Консалтинг»  и расскажу в этой статье. Почему REST API Битрикс24 – стратегическое преимущество «Битрикс24» — это не просто портал с задачами и CRM, а полноценный инструмент, который можно встроить в систему любой сложности: 1С ЗУП, ERP, SAP, Microsoft Dynamics Решения для управления задачами и проектами: Jira, ServiceDesk, Redmine Exchange, Outlook Power BI, ClickHouse Учебные порталы, облачные сервисы, шлюзы мессенджеров, чат-боты Телефония, голосовые шлюзы REST API позволяет подключаться на уровне бизнес-сущностей: CRM, задачи, сотрудники, сообщения, звонки, календари и не только. Вы управляете ими как через внутренний интерфейс, так и из кода — без хака ядра, а через документацию с примерами. Как это устроено? REST API «Битрикс24» — это открытый интерфейс, через который можно управлять сущностями системы. API работает по классическим принципам REST: Доступ по HTTP/HTTPS Работа с CRUD-операциями (создание, чтение, обновление, удаление) Передача данных в формате JSON Аутентификация через OAuth 2.0 или вебхуки. 4 основных принципа работы REST API «Битрикс24»  За вызовами скрыты бизнес-сущности «Битрикс24»: CRM, задачи, пользователи,      звонки, календари, файлы, сообщения и так далее. Каждая сущность имеет логичное представление: crm.lead.add, tasks.task.update, im.message.add. Эндпоинты группируются по бизнес-направлениям: CRM, tasks, telephony и прочие.Запросы обрабатываются через REST API шлюз и возвращают структурированный ответ с кодом статуса и данными. 2 сценария аутентификации: OAuth 2.0      – для безопасной и масштабируемой авторизации стороннего сервиса от имени      пользователя или приложения. Вебхуки – простой способ «подключиться» к порталу для получения      или отправки данных, не требующий реализации OAuth (ручная генерация на      стороне «Битрикс24»). Рисунок 1. Пример запроса на создание задачи «Битрикс24» Типичный сценарий – обратная форма на Tilda, где в настройках действия выбирается внешний webhook Bitrix24 для отправки данных. Когда посетитель оставляет заявку, ее содержимое через POST отправляется напрямую в CRM, где и создается лид. Рисунок 2. Пример добавления вебхука в «Битрикс24» Аналогичный подход: В  Jira  — при добавлении/изменении задач отправляется POST-запрос на URL Битрикс24. В  Trello  — действие в канбане инициирует webhook на CRM. В в  конструкторах типа Make/Albato  — появляется новая строка в таблице и автоматически вызывается webhook. Webhook чаще всего используют для простых, но массовых сценариев, где важна скорость внедрения и нет сложной логики. Они отлично подходят для связки порталов, форм на сайтах, LMS, Helpdesk-систем и другого ПО без полноценной API-интеграции. Если же требуется защищенный обмен, работа по расписанию, кастомные обработки – включайте OAuth 2.0 и идите через REST API полноценно.  Документация  включает в себя: Более 400 методов API Пояснения по структуре запросов Интерактивный тестовый интерфейс (REST API Explorer) Описание ограничений и параметров. Важные возможности: Поддержка входящих и исходящих вебхуков Подписка на события (event binding) – внешняя система получит уведомление при изменении данных в «Битрикс24» Подключение собственного веб-приложения прямо в интерфейсе портала (встраиваемые виджеты и iframe-интеграция) Библиотеки для работы с API на JS, PHP, Python. Интерфейс REST API в «Битрикс24» – зрелый и полнофункциональный. Он охватывает все ключевые элементы портала и может использоваться как для задач простого обмена данными, так и для построения полноценных интеграционных решений с внешними системами. Битрикс24 как платформа для HRM: пример K-Team Если вы рассматриваете «Битрикс24» не только как CRM, но и как системообразующий элемент для управления персоналом, стоит обратить внимание на платформенные продукты, построенные на его базе. Один из таких примеров —  K-Team HRM. Это решение разработано на коробочной версии «Битрикс24» и превращает ее в полноценную HRM-систему. За счет глубокой архитектурной интеграции с платформой, K-Team сохраняет полный доступ к REST API, а значит, все, что вы уже умеете делать с API «Битрикс24» вы сможете сделать и с HR-данными. Что нового есть в K-Team HRM? Модуль адаптации сотрудников Построение целей и моделей KPI Обучение и оценка, включая 360-градусную обратную связь База знаний с управлением правами доступа Механизмы геймификации: баллы, магазин призов и не только Контроль кадровых событий через автоматизацию Все данные, созданные внутри K-Team HRM, также, как и базовые сущности «Битрикс24», доступны через REST API, а при необходимости и через SOAP. Это значит, что вы можете интегрировать адаптацию, цели, планы, оценку и обучение с внешними системами, например, LMS, кадровым порталом, корпоративной BI-системой, или наоборот – получать внешние данные о прохождении курсов или результатах тестирований.  Также в K-Team поддерживаются авторизация через webhook, OAuth, собственные REST-серверы в коробке и сложные сценарии событий. Для ИТ-директора это означает одно – HRM-функциональность не «утопает» в закрытом модуле, а остается частью открытой ИТ-архитектуры, в которую можно встроиться также, как в CRM, задачи или сервис-деск . Таким образом, K-Team HRM – это не просто надстройка, а возможность расширить коробочный «Битрикс24» без потери контроля, скорости и гибкости в интеграции.   Что можно автоматизировать и интегрировать через REST API «Битрикс24»? 1. Интеграция с ERP/учетными системами: 1С, SAP, Oracle, Microsoft Dynamics Автоматическая синхронизация контрагентов из ERP в Битрикс24 и наоборот Выгрузка заказов/сделок из «Битрикс24» в бухгалтерские и контрактные модули ERP Учет оплат и задолженностей — оперативный доступ к финкору из CRM Актуализация номенклатуры и остатков товаров в «Битрикс24» Подключение задач по отгрузке к конкретным этапам бизнес-процесса ERP Пример:  Новое поступление в 1С → постановка задачи склада → CRM получила статус «Готов к отгрузке». 2. Интеграция с BI и аналитикой: Power BI, Google Data Studio, ClickHouse Получение CRM-сущностей: лиды, сделки, звонки, активности Построение воронки продаж/загрузки менеджеров в real-time Сравнение эффективности рекламных кампаний с привязкой к продажам Пример:  Ежедневные отчеты по отделам в Power BI подтягивают данные из  crm.deal .list и crm.activity.list. 3. Интеграция с корпоративными календарями, почтой, чатами Автосоздание встреч и событий в Outlook/Google Calendar Синхронизация писем и их привязка к сделкам Уведомления/интеграции со Slack, Telegram и другими мессенджерами Рассылки автоматических e-mail/уведомлений из «Битрикс24» Пример:  Письмо → webhook → создание лида, задача менеджеру, уведомление в Teams. 4. Автоматизация кадрового контура (HR + AD) Получение списка сотрудников и отделов – через user.get, department.get Синхронизация статусов: увольнение → отключение доступа Назначение ролей и прав по API Создание пользователей при выходе новых сотрудников Пример:  HR в «1С:ЗУП» оформил нового сотрудника → через API пользователь автоматически появляется в «Битрикс24» и прикрепляется к нужному отделу. 5. Управление задачами, процессами и проектами Массовое создание задач/подзадач Создание шаблонов задач на основе данных из внешней БД, например, тикет Интеграция с Jira: инцидент → задача разработчика Привязка задач к сделкам или обращениям Автоматическое закрытие задач/подтверждение статусов через API Пример:  Подключение REST API Jira → «Битрикс24» для поддержки техподдержки и продуктовых задач в едином контуре. 6. Синхронизация с внешними веб-сервисами CRM-связка с формами захвата лидов: LP-платформы, лендинги Коннекторы с сервисами логистики, доставки, IP-телефонией Получение и отправка данных из e-commerce витрин с высокой скоростью Что это дает? Уменьшается рутинная нагрузка на ИТ-поддержку – становится меньше ручных операций Повышается прозрачность и контролируемость процессов Благодаря REST API можно избежать «застревания» в одной системе и строить интерфейс логики компании так, как удобно тебе Централизация процессов и данных сокращает ошибки и увеличивает управляемость Ограничения REST API и способы обхода REST API «Битрикс24» – мощный инструмент для интеграций и автоматизации. Но, как и у любой зрелой платформы, у API есть ограничения, которые стоит учитывать заранее. Ниже – ключевые ограничения и практики, которые позволяют работать с ними без потери стабильности и гибкости. 1. Ограничения на количество запросов (Rate Limits) «Битрикс24» ограничивает количество REST-запросов от одного приложения или вебхука в единицу времени, чтобы защитить систему от перегрузок и DDoS-атак. Обычно лимит – 2 запроса в секунду и до 120-180 по таймеру со стороны портала Для событий и очередей обрабатываются события пачками (batch) Как обойти? Использовать batch-запросы – работают в 1 REST-вызов, но внутри до 50 действий Распараллелить запросы по разным точкам входа (несколько вебхуков) Использовать очереди задач на своей стороне, например, Redis, RabbitMQ, добавляя throttle/таймаут. Пример:  Если вам нужно создать 200 задач, не отправляйте 200 запросов подряд. Сгруппируйте их в 4 пачки по 50 задач через batch. 2. Ограничения по OAuth-авторизации Любое внешнее приложение, использующее OAuth 2.0, обязано обновлять свой access token (токен доступа) каждые 3 600 секунд. Refresh token используется всего 1 раз, иначе авторизация сломается. Рекомендации по использованию: Хранить refresh-токен в защищенном хранилище и регулярно обновлять токен Использовать автоматические обновления токена средствами middleware (например, Laravel, NestJS, Node) При ошибке авторизации использовать резервный вход (webhook или другой аккаунт доступа) Если ошибка происходит постоянно, то смотреть логику своего приложения, а не идти в другие методы Совет:  При настройке интеграции продумайте фоновый мониторинг статусов токенов и оповещайте разработчиков/интеграторов до таймаута. Фоновое оповещение о скором истечении токена помогает избежать сбоев до их возникновения. Хотя по OAuth токен можно обновить при ошибке 401, на практике это ненадежно: не все клиенты обрабатывают ошибки корректно, refresh-token может быть недействителен, а в no-code/low-code решениях (Tilda, Make, Google Sheets) автообновление часто отсутствует. При сбое в общей точке интеграции можно потерять данные, а о проблеме вы узнаете слишком поздно. 3. Ограничения доступа к административной части и ядру REST API «Битрикс24» – это доступ только к бизнес-сущностям, таким как CRM, задачи, сотрудники, документы, сообщения и так далее. Из API нельзя напрямую: Работать с ядром системы или компонентами Управлять правами файлов, группами или настройками Обращаться к файловой системе, nginx/apache, php.ini или ядру Bitrix Framework Выполнять код от имени администратора на уровне сервера. И если вам кажется, что «надо бы докрутить», точно не нужно лезть в ядро. Как расширять правильно? Для этого в «Битрикс24» предусмотрены полноценные REST-приложения, которые: Работают полностью через открытое API Размещаются на отдельном сервере или в облаке Могут быть: iframe-приложением, встроенным в интерфейс «Битрикс24» (например, для настройки KPI, кастомного импорта из SAP, расширенного UI) консольным или фоновым приложением, которое выполняет фоновые сценарии синхронизации, расчетов и так далее. Иными словами, если вы хотите реализовать свою бизнес-логику (например, уникальные правила назначения прав доступа, распределение задач не по стадиям CRM, а по ролям в AD или внутренним регламентам), вы не лезете в ядро, а делаете REST-приложение и управляете всем снаружи через API. 4. Динамические поля и кастомные структуры Кратко:  Кастомные поля доступны через API, но их идентификаторы (field codes) могут быть сложными или нестабильными между инсталляциями. Как обойти? Создавайте поля с понятными символьными кодами (UF_*) Храните схему соответствия ID → название поля во внешнем хранилище Используйте REST-методы  crm.deal .userfield.list / userfield.get для управления через API 5. Отсутствие транзакций REST API «Битрикс24» не поддерживает классические ACID-транзакции. То есть, когда вы отправляете несколько запросов подряд (например, создать сделку → добавить комментарий → прикрепить файл), может получиться, что: Сделка создалась Комментарий не ушел (сбои сети, токен истек, 429) Файл вообще не загрузился, и вы об этом не сразу узнаете. В результате — «неконсистентное» состояние системы. Как строить архитектуру в условиях отсутствия транзакций? Используйте паттерн компенсирующих операций.  Если шаг 3 не прошел, то откатываем шаги 1 и 2 (где это возможно). Рисунок 3. Пример операции при отсутствии транзакций Разделяйте операции по критичности.  Сформулируйте у себя в архитектуре, что обязательно, что по желанию, а что можно повторить позже. Это называется eventual consistency – целостность добивается не через транзакции, а через логическое управление состоянием. Внедряйте промежуточный слой: sharding queue / event bus.  Все события пишутся сначала в свою очередь (Redis, Kafka, RabbitMQ). При успешной обработке снимается флаг подтверждения, а если API вернул ошибку или ничего не вернул, событие попадает в повторную обработку. Можно применять дедупликацию, повторные вызовы, backoff/retry и лог только как последний рубеж диагностики исключений. Если вы работаете без транзакций, проектируйте вызовы API с пониманием риска потерь и откатов, как это происходит в распределенных системах. И помните, что REST API «Битрикс24» этим не занимается – это делает ваша инфраструктура. «Битрикс24» не «черный ящик»: почему вам удобно и безопасно его интегрировать? Для нас важны не только функции, но и зрелость решения: насколько оно гибкое, предсказуемое, управляемое и подконтрольное. В этом смысле «Битрикс24» – одна из немногих платформ на рынке, которая предоставляет сразу несколько уровней интеграции: Системный: через REST API с доступом к десяткам бизнес-сущностей Визуальный: через no-code инструменты, webhook-и, шаблоны роботов и бизнес-процессов Архитектурный: с возможностью построения гибридных решений, масштабируемых и отказоустойчивых. Что мы имеем?  Возможность встроить «Битрикс24» в любой цифровой ландшафт – от ERP до BI и Jira. Гарантию, что процессы не «замкнутся» внутри одной системы и их можно контролировать. Гибкую платформу с REST-интерфейсом, документацией и поддержкой стандартных протоколов. Инструменты для постепенной интеграции, без большого кода и затрат. Поддержку low-code сценариев для быстрой автоматизации повседневных задач. При этом «Битрикс24» развивается постоянно – API расширяется, появляются новые инструменты (например, «Сценарии» или «Смарт-процессы»), поддержка нотификаций, очередей и событий становится глубже. Это делает платформу удобной не только для конечных пользователей, но и для ИТ-команды. Чек-лист: «Когда REST-интеграция уместна в “Битрикс24”» Планируете нестандартную интеграцию с 1С ЗУП, SAP HR или AD. Хотите сделать интеграцию с 1С ERP или Jira. Нужно ссинхронизировать портал с внешними сайтами/CRM/API. Важно выгружать метрики «вживую» в Power BI. Необходима автоматизация на событиях без разработки большого кода. Если перед вами стоит задача построить удобную, гибкую и масштабируемую инфраструктуру автоматизации и процессов, «Битрикс24» станет не ограничением, а полноценным участником ИТ-ландшафта.', hub='софт'), Page(id='945332', title='От репейника до глобального успеха: история создания «липучки» VELCRO', content='Вы когда-нибудь задумывались, что простая идея может изменить жизнь?  Немало привычных вещей, без которых сегодня сложно представить наш быт, создали не разработчики из международных корпораций, а обычные люди. Они просто были увлечёнными, умели наблюдать за миром и видеть больше других.  Одним из таких людей был Жорж де Местраль – создатель всемирно известной застёжки «липучка», запатентованной под брендом «VELCRO». Швейцарский инженер без капитала и связей больше 10 лет пытался убедить фабрикантов в перспективах своей идеи, всюду сталкиваясь с непониманием и отсутствием поддержки. Но в итоге его усилия увенчались успехом: липучка VELCRO обрела мировую популярность, а её создатель включён в Национальный зал славы изобретателей США как человек, внёсший значительный вклад в развитие технологий. С чего всё начиналось Жорж де Местраль не был случайным человеком в изобретательской среде. С детства он проявлял склонность к математике и конструированию, а в 12 лет разработал и запатентовал свою первую разработку - игрушечный самолёт. Позже талантливый юноша окончил Политехническую школу Лозанны и начал работать в инженерной компании. Однако идея застёжки-липучки пришла в голову де Местраля случайно. Возвращаясь после лесных прогулок с собакой, он снимал с её шерсти репейник. И однажды задумался: что заставляет колючки держаться на шерсти так крепко?  Изобретатель рассмотрел репейник под микроскопом и понял, что причина – мельчайшие крючочки, из которых состоит соцветие. Тогда у него и возникла идея использовать это свойство для создания текстильной застёжки. Оставалось только продумать техническую реализацию, а этот этап оказался гораздо более долгим, чем рассчитывал Жорж. Жорж де Местраль. Фото с сайта  velcro.com Непростой путь к признанию Чтобы подобрать подходящий для создания застёжки материал, де Местраль отправился в город Лион – признанную столицу тканей. Владельцы текстильных фабрик, к которым обращался инженер, не воспринимали идею всерьёз. Но, несмотря на это, Жоржу удалось с помощью ткача из Лиона и ткацкого станочника из Базеля создать задуманную «липучку».  Первая застёжка была далека от того, чтобы стать востребованным продуктом. Прототип был сделан из хлопка и состоял из двух полосок: одной с крючками, второй с петлями. Однако хлопок из-за мягкости не выдерживал многократных открываний и закрываний, поэтому этот вариант не мог быть запущен в массовое производство.  Де Местраль перебрал много материалов, прежде чем добился нужного размера петель, прочного прилипания и износостойкости. В итоге для производства «липучки» был выбран нейлон, который после специальной обработки лучше других подходил для решения задачи.  При доработке идеи возникали и другие затруднения. Текстиль с петлями изготавливался сравнительно легко, а вот изготовление ткани с крючками оказалось более сложным. Тогда де Местраль изобрёл устройство, которое могло разрезать легко изготавливаемые петли, превращая их в крючки. В 1951 году застёжка была представлена в патентное бюро Швейцарии под названием VELCRO, а первый патент изобретатель получил только в 1954 году.  С идеи, возникшей после судьбоносной прогулки с собакой, до официального оформления прав на неё прошло 13 лет.  \\xa0 Полученный патент. Фото с сайта velcro.com Из бытовой идеи в глобальный бизнес Дальнейшие события развивались гораздо быстрее. Уже спустя два года после получения патента начались коммерческие продажи VELCRO, а к концу 1950-х годов производство застёжки-липучки наладили в Европе, США и Канаде.  В 1961 году разработкой заинтересовалось NASA. В рамках программы «Аполлон» застёжку начали применять для крепления элементов экипировки космонавтов и оборудования. Сегодня «липучка» VELCRO используется в самых разных сферах, например: при пошиве одежды, обуви, сумок, в том числе специального назначения; как решение для бескаркасных креплений в строительстве, промышленности и других сферах; в производстве медицинской продукции и средств защиты; как бесклеевое решение для фиксации подгузников и других средств гигиены; в качестве альтернативы проволоке и проволочным кольцам для крепления обивки автомобильных сидений. Технология, придуманная благодаря репейнику, сделала де Местраля богатым человеком. Он основал компанию по производству застёжек Velcro SA, которая работает до сих пор под названием Velcro Companies. А торговая марка VELCRO зарегистрирована в 130 странах мира. \\xa0 Первый логотип бренда VELCRO ®. Фото с сайта velcro.com. VELCRO сегодня. Фото с сайта velcro.com. Факторы успеха В чём секрет мирового успеха «липучки» VELCRO? В первую очередь, в настойчивости Жоржа де Местраля и его вере в результат.  Но не последнюю роль сыграли и другие обстоятельства: Универсальная идея:  изобретатель придумал технологию, одинаково пригодную для изготовления разнообразной продукции, от одежды и спортивных сумок до космического оборудования. Юридическая защита:  Жорж де Местраль вовремя запатентовал новое решение, защитив его от конкурентов. Работающая бизнес-модель:  все права на торговую марку VELCRO ® принадлежат Velcro Companies, которая постоянно совершенствует линейку продукции и расширяет географию производства, а также следит за законным использованием бренда.  Эта история – одно из многих подтверждений того, что даже простая на первый взгляд идея может покорить мир и принести её создателю миллионы.  С тех пор как Жорж де Местраль придумал свою «липучку», прошло больше 80 лет. Но подход, который помог ему достичь успеха, применим и сегодня: не оставляйте без внимания перспективные идеи, смело воплощайте их в жизнь и не забывайте о юридической защите. Возможно, именно ваша разработка станет очередным шагом на пути технического прогресса. А если вам интересны другие истории изобретателей и практические советы по защите интеллектуальной собственности, подписывайтесь и следите за новыми публикациями.', hub='брендинг'), Page(id='945196', title='Что делать интроверту на конференциях?', content='И зачем туда вообще идти — как участнику или как представителю компании на стенде. Когда вы слышите слово «конференция», что приходит в голову? Толпы людей, шумный зал, кофе-брейки, анонсы докладов, стикеры, носки и человек в костюме банана возле стенда партнёра? Каждый воспринимает конференции по-своему. Для кого-то это праздник общения, для кого-то — ценный нетворкинг, для кого-то — бесплатные стикеры и лекции уровня «ну ничего себе». А что, если ты интроверт? Ты хочешь поучаствовать в подготовке к конференции, тебе интересны темы докладов, ты бы хотел пообщаться со спикерами — но сама мысль о большом количестве людей и незнакомцах вызывает ступор. Ты и рад поговорить с интересным тебе спикером, но вокруг десятки других людей, шум суета и вот это все.  Типичная картинка конференций А может быть, ты работаешь в компании, которая постоянно участвует в конференциях: у вас есть стенд, команда все время штурмит идеями, делится впечатлениями, ездит в командировки. А ты смотришь на это все со стороны и думаешь: я, может, и хотел бы, но мне не по себе даже от мысли быть на стенде и проводить всякие активности. Если тебе знакомо хоть что-то из этого — ты по адресу. В этой статье расскажу, как найти свой формат участия в конференциях и даже почувствовать себя на них в своей тарелке на сколько это вообще возможно.  Интроверт ≠ не подходит для конференций Момент относительной \"тишины\" на стенде Важно сразу убрать сомнения: то, что ты интроверт и тебе не место на конференции это заблуждение. Интроверсия или социофобия не делает человека плохим участником конференции. Просто наш способ восприятия мира чуть иначе в отличие «экстравертного» большинства. И для нас есть свои форматы участия: 1. Быть участником, но по своим правилам Планируй день заранее.  Выбери доклады, которые тебе действительно интересны, и оставь слоты для перерывов. Чтобы у тебя всегда было понимание: когда ты в потоке, а когда — пора переходить в режим энергосбережения. И когда у тебя появится окошко перехватить того самого спикера, с которым ты хотел бы пообщаться. Поверь, он и сам рад похоливарить или пообщаться на тему своего доклада и ответить на вопросы\\xa0 Не пытайся обойти все стенды.  Ходи туда, где действительно хочешь узнать больше. Лучше два интересных диалога, чем двадцать неловких бесед. Хотя, конечно, бесплатные стикеры никто не отменял 🙂 Лови момент тишины.  У стендов бывает время, когда толпы участников нет, и можно спокойно пообщаться с кем-то из стендистов. Найди тихие зоны.  Многие  организаторы конференций создают лаунж-зоны или просто места, где можно отдохнуть. Иногда лучший доклад — это 10 минут тишины с чашкой чая или кофе и наедине с самим собой. Если ты хочешь просто получить мерч,  но принимать участие в активностях рядом с толпой других участников не хочется, то вариант есть. На стендах компаний всегда есть чат-боты, в которых можно пройти задания как на логику, так и решить технические задачки. Это не занимаем много времени, достаточно отсканировать qr-код и пройти в нем задания, после чего получить у стендистов полагающийся тебе мерч. Пример того, что можно получить на стенде 2. Нетворкинг — это не только small talk Не обязательно общаться со всеми на конференции. Достаточно выбрать одну-две цели: задать вопрос спикеру, поговорить с человеком из интересующей компании, или на худой конец, обменяться мнением с соседом в зале. И всё, миссия выполнена. Уже повод гордиться собой (и съесть десерт на фуршете без угрызений совести). Если ты хотел бы быть стендистом, но думал что роль на стенде — это только про «зазывать на стенд» и проводить активности.  Быть на стенде — это не обязательно про бесконечное общение и проведение активностей. Есть брейншторм идей на конференцию, разработка задач и активностей, создание чат бота, расчет и планирование мерча, помощь команде в момент проведения активностей,\\xa0шпионский десант на стенды других партнеров конференций. Более того, есть важная роль эксперта - рассказчика — к которому всегда можно обратиться по сложных техническим, архитектурным или холиварным вопросам. И это ценно, когда на стенде есть такой человек, с которым можно свободно пообщаться на эти темы. Личный опыт (и немного честных признаний) Я сама из тех, кто на конференциях первое время тущуюсь, смущаюсь и совсем не \"рыба в воде\". Первое что я делаю, это сканирую ближайший выход, потом стенд своей компании, потом — место, где можно немного перевести дух. А потом — кофемашину и стол с печеньками. После этого нахожу стенд с расписанием, нахожу интересные для меня доклады, составляю мысленно план задач на сегодня, и мне становится спокойнее и комфортнее)  Но все это было далеко не сразу.\\xa0 В первый раз на конференции, максимум который я могла это стоять на стенде и просто помогать всем, чем могла —  короче была на подхвате. Мои более общительные коллеги взяли на себя коммуникацию с участниками конференции. Я почти не общалась ни с кем — но команда знала, что на меня можно положиться почти по всем остальным вопросам. Я следила, кому чего не хватает, где что поправить, к кому кого можно направить, где чего не достает. Контролировала остатки мерча, вовремя выкладывала его на витрину, в общем — была вне бесед, но при этом оставалась на страже порядка стенда и внутреннего спокойствия команды. И уже на второй день конференции, когда я немного освоилась, именно ко мне начали подходить за «продолжительными разговорами».  С тех пор я пробовала себя в разных ролях: придумывала идеи для стендов, выступала с докладами, сопровождала спикеров, наблюдала со стороны. И каждый раз находила свою зону комфорта — а иногда и выходила за её пределы. Но уже по своему желанию и своим правилам. Почему это вообще важно Потому что мир айти-конференций часто выглядит как праздник для экстравертов. Но на самом деле он нуждается в людях, которые умеют слушать, замечать детали, видеть суть. И такие люди — среди нас, интровертов. Если вы думаете, что вам там не место — это не так. Просто найдите свой способ участия. Он точно существует. PS  Бывали в такой ситуации? Напишите в комментах, как справились. Поделимся опытом — интроверты интровертам 💙', hub='управление персоналом')]","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:17.405777","level":"info","event":"В цикле: 17","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:17.405892","level":"info","event":"URL: https://habr.com/ru/articles/page17","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:18.186471","level":"info","event":"Result: <Response [200]>","logger":"pipeline_tools.parsers"}
{"timestamp":"2025-09-13T10:00:23.024408","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"HubNotFound","exc_value":"На странице не найден первый хаб","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1215,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":397,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":216,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":239,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/parse_habr_dag.py","lineno":28,"name":"get_feeds"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pipeline_tools/parsers.py","lineno":111,"name":"parse_with_offset"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pipeline_tools/parsers.py","lineno":211,"name":"_parse_raw_result"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pipeline_tools/parsers.py","lineno":161,"name":"_parse_page"}],"is_group":false,"exceptions":[]}]}
