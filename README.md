# Habr Article Hub Classification

Это проект по классификации статей с Habr по хабам.

Его суть в сборе данных с Habr, обучении и сравнении моделей машинного обучения, которые далее используются в Backend-сервисе.

# Технологии

## Парсинг

Для парсинга была написана библиотека, которая используется внутри **Apache Airflow**. <br>
Основные зависимости - `requests` и `beautifulsoup`.

Для Aiflow написаны DAG'и, срабатывающие каждые 5 минут и парсящие 5 хабов Habr:
1. `artificial_intelligence`
2. `it-infrastructure`
3. `infosecurity`
4. `hr_management`
5. `maths`

Для хранения данных использовалась база данных **Clickhouse**.

В итоге было собрано 17 тысяч статей.

## Обучение и сравнение моделей

Для обучения и сравнения моделей, осмотра данных и их преобразования был использовать `jupyter notebook.`

## Backend

Backend был написан на **FastAPI**, в качестве модели классификации был использован baseline.

## Frontend

Для небольшой проверки и демонстрации был написан Frontend на `streamlit`.

Всё было упаковано в docker контейнеры.

# Изначальная идея и проблемы

Изначально была идея парсить ленту новостей Habr, однако вскоре я столкнулся с проблемой: доступно лишь 50 страниц. Из-за этого данных оказывалось слишком мало, а метки были разнородны и несбалансированы.

Заметив хабы, я решил парсить именно их, получив лучший резульат.
